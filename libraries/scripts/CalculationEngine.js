/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
var Modellus;
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://Modellus/./node_modules/events/events.js?");

/***/ }),

/***/ "./CalculationEngine/Branch.ts":
/*!*************************************!*\
  !*** ./CalculationEngine/Branch.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Branch: () => (/* binding */ Branch)\n/* harmony export */ });\nclass Branch {\n    constructor(text, calculate, ...children) {\n        this.children = [];\n        this.text = text;\n        this.calculate = calculate;\n        this.children.push(...children);\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Branch.ts?");

/***/ }),

/***/ "./CalculationEngine/Engine.ts":
/*!*************************************!*\
  !*** ./CalculationEngine/Engine.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Engine: () => (/* binding */ Engine)\n/* harmony export */ });\n/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! events */ \"./node_modules/events/events.js\");\n/* harmony import */ var events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(events__WEBPACK_IMPORTED_MODULE_0__);\n\nclass Engine extends events__WEBPACK_IMPORTED_MODULE_0__.EventEmitter {\n    constructor(system) {\n        super();\n        this.system = system;\n    }\n    iterateInternal(last, factor = 0, k) {\n        const values = {};\n        const termNames = this.system.getTermsNames();\n        // Copy last values and advance differentials if applicable\n        for (let i = 0; i < termNames.length; i++) {\n            const t = termNames[i];\n            values[t] = last[t];\n        }\n        if (k && factor !== 0) {\n            const diffs = this.system.getDifferentialTermsNames();\n            for (let i = 0; i < diffs.length; i++) {\n                const name = diffs[i];\n                values[name] = last[name] + k[name] * factor;\n            }\n        }\n        values[this.system.independent.name] = last[this.system.independent.name] + this.system.step * factor;\n        values[this.system.iterationTerm.name] = this.system.iteration;\n        const calculatedValues = this.system.calculate(values);\n        const diffs = this.system.getDifferentialTermsNames();\n        for (let i = 0; i < diffs.length; i++) {\n            const name = diffs[i];\n            if (calculatedValues[name] !== undefined)\n                calculatedValues[name] *= this.system.step;\n        }\n        return calculatedValues;\n    }\n    iterate() {\n        const last = this.system.get();\n        const current = {};\n        const termNames = this.system.getTermsNames();\n        for (let i = 0; i < termNames.length; i++) {\n            const name = termNames[i];\n            current[name] = last[name];\n        }\n        this.system.iteration = this.system.lastIteration + 1;\n        const k1 = this.iterateInternal(last);\n        const k2 = this.iterateInternal(last, 0.5, k1);\n        const k3 = this.iterateInternal(last, 0.5, k2);\n        const k4 = this.iterateInternal(last, 1, k3);\n        const diffs = this.system.getDifferentialTermsNames();\n        for (let i = 0; i < diffs.length; i++) {\n            const name = diffs[i];\n            current[name] = last[name] + (k1[name] + 2 * k2[name] + 2 * k3[name] + k4[name]) / 6;\n        }\n        current[this.system.independent.name] = last[this.system.independent.name] + this.system.step;\n        current[this.system.iterationTerm.name] = this.system.iteration;\n        this.system.addValues(current);\n        this.system.calculateFunctions();\n        this.emit(\"iterate\", this);\n    }\n    reset() {\n        this.system.reset();\n    }\n    onIterate(listener) {\n        this.on(\"iterate\", listener);\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Engine.ts?");

/***/ }),

/***/ "./CalculationEngine/Expression.ts":
/*!*****************************************!*\
  !*** ./CalculationEngine/Expression.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Expression: () => (/* binding */ Expression)\n/* harmony export */ });\n/* harmony import */ var _TermType__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TermType */ \"./CalculationEngine/TermType.ts\");\n\nclass Expression {\n    constructor(name, calculate, type = _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.DIFFERENTIAL, condition = null) {\n        this.name = name;\n        this.calculate = calculate;\n        this.type = type;\n        this.condition = condition;\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Expression.ts?");

/***/ }),

/***/ "./CalculationEngine/Parser.ts":
/*!*************************************!*\
  !*** ./CalculationEngine/Parser.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Parser: () => (/* binding */ Parser)\n/* harmony export */ });\n/* harmony import */ var antlr4ng__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4ng */ \"./node_modules/antlr4ng/dist/index.mjs\");\n/* harmony import */ var _Parser_LatexMathLexer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Parser/LatexMathLexer */ \"./Parser/LatexMathLexer.ts\");\n/* harmony import */ var _Parser_LatexMathParser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Parser/LatexMathParser */ \"./Parser/LatexMathParser.ts\");\n/* harmony import */ var _Visitor__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Visitor */ \"./CalculationEngine/Visitor.ts\");\n/* harmony import */ var _ParserErrorListener__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ParserErrorListener */ \"./CalculationEngine/ParserErrorListener.ts\");\n\n\n\n\n\nclass Parser {\n    constructor(system) {\n        this.hasErrors = false;\n        this.errors = [];\n        this.system = system;\n    }\n    parse(expressions) {\n        var text = expressions.replace(/\\s+/g, \"\");\n        const lexer = new _Parser_LatexMathLexer__WEBPACK_IMPORTED_MODULE_1__.LatexMathLexer(antlr4ng__WEBPACK_IMPORTED_MODULE_0__.CharStream.fromString(expressions));\n        const parser = new _Parser_LatexMathParser__WEBPACK_IMPORTED_MODULE_2__.LatexMathParser(new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.CommonTokenStream(lexer));\n        lexer.removeErrorListeners();\n        parser.removeErrorListeners();\n        const errorListener = new _ParserErrorListener__WEBPACK_IMPORTED_MODULE_4__.ParserErrorListener();\n        parser.addErrorListener(errorListener);\n        const tree = parser.statement();\n        this.hasErrors = errorListener.hasErrors();\n        this.errors = errorListener.getErrors();\n        if (this.hasErrors)\n            return null;\n        const visitor = new _Visitor__WEBPACK_IMPORTED_MODULE_3__.Visitor(this.system);\n        return visitor.visit(tree);\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Parser.ts?");

/***/ }),

/***/ "./CalculationEngine/ParserErrorListener.ts":
/*!**************************************************!*\
  !*** ./CalculationEngine/ParserErrorListener.ts ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ParserErrorListener: () => (/* binding */ ParserErrorListener)\n/* harmony export */ });\n/* harmony import */ var antlr4ng__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4ng */ \"./node_modules/antlr4ng/dist/index.mjs\");\n\nclass ParserErrorListener extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.BaseErrorListener {\n    constructor() {\n        super(...arguments);\n        this._hasErrors = false;\n        this._errors = [];\n    }\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        this._hasErrors = true;\n        const errorMessage = `Syntax error at line ${line}, column ${column}: ${msg}`;\n        this._errors.push(errorMessage);\n    }\n    hasErrors() {\n        return this._hasErrors;\n    }\n    getErrors() {\n        return this._errors;\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/ParserErrorListener.ts?");

/***/ }),

/***/ "./CalculationEngine/System.ts":
/*!*************************************!*\
  !*** ./CalculationEngine/System.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   System: () => (/* binding */ System)\n/* harmony export */ });\n/* harmony import */ var _TermType__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TermType */ \"./CalculationEngine/TermType.ts\");\n/* harmony import */ var _Term__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Term */ \"./CalculationEngine/Term.ts\");\n\n\nclass System {\n    constructor(independent = \"t\", iterationTerm = \"n\") {\n        this._independent = new _Term__WEBPACK_IMPORTED_MODULE_1__.Term(\"t\", _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.INDEPENDENT);\n        this._iterationTerm = new _Term__WEBPACK_IMPORTED_MODULE_1__.Term(\"n\", _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.PARAMETER);\n        this.terms = {};\n        this.expressions = [];\n        this.values = [{ iteration: 1 }];\n        this.iteration = 1;\n        this.step = 0.1;\n        this.expressionsByName = {};\n        this.termNames = [];\n        this.differentialNames = [];\n        this.functionExpressionsWithCondition = [];\n        this.functionExpressionsWithoutCondition = [];\n        this.independent = independent;\n        this.iterationTerm = iterationTerm;\n        this.reset();\n    }\n    get independent() {\n        return this._independent;\n    }\n    set independent(name) {\n        this._independent = new _Term__WEBPACK_IMPORTED_MODULE_1__.Term(name, _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.INDEPENDENT);\n        this.terms[name] = this.independent;\n        if (!this.termNames.includes(name))\n            this.termNames.push(name);\n    }\n    get iterationTerm() {\n        return this._iterationTerm;\n    }\n    set iterationTerm(name) {\n        this._iterationTerm = new _Term__WEBPACK_IMPORTED_MODULE_1__.Term(name, _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.PARAMETER);\n        this.terms[name] = this.iterationTerm;\n        if (!this.termNames.includes(name))\n            this.termNames.push(name);\n    }\n    get lastIteration() {\n        return this.values.length;\n    }\n    get() {\n        return this.values[this.lastIteration - 1];\n    }\n    getIteration(iteration) {\n        if (iteration > 0 && iteration <= this.values.length)\n            return this.values[iteration - 1];\n        var values = { iteration: iteration };\n        Object.keys(this.terms).forEach(name => {\n            values[name] = NaN;\n        });\n        return values;\n    }\n    getByName(name) {\n        return this.getByNameOnIteration(this.lastIteration, name);\n    }\n    getByNameOnIteration(iteration, name) {\n        if (iteration < 1 || iteration > this.values.length)\n            return NaN;\n        if (this.terms[name] == undefined)\n            return undefined;\n        return this.values[iteration - 1][name];\n    }\n    getIndependentOnIteration(iteration, name) {\n        if (iteration < 1 || iteration > this.values.length)\n            return NaN;\n        return this.values[iteration - 1][this._independent.name];\n    }\n    getByExpression(expression) {\n        return this.getByName(expression.name);\n    }\n    getByTerm(term) {\n        return this.getByName(term.name);\n    }\n    addExpression(expression, termType = _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.DIFFERENTIAL) {\n        this.expressions.push(expression);\n        this.expressionsByName[expression.name] = expression;\n        // Maintain fast lookup groups\n        if (expression.type === _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.DIFFERENTIAL) {\n            if (!this.differentialNames.includes(expression.name))\n                this.differentialNames.push(expression.name);\n        }\n        else if (expression.type === _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.FUNCTION) {\n            if (expression.condition)\n                this.functionExpressionsWithCondition.push(expression);\n            else\n                this.functionExpressionsWithoutCondition.push(expression);\n        }\n        this.addTermByName(expression.name, termType);\n    }\n    addTerm(term) {\n        const priority = [_TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.INDEPENDENT, _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.FUNCTION, _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.DIFFERENTIAL, _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.PARAMETER];\n        const existing = this.terms[term.name];\n        if (!existing)\n            this.terms[term.name] = term;\n        else {\n            const existingPriority = priority.indexOf(existing.type);\n            const termPriority = priority.indexOf(term.type);\n            existing.type = existingPriority < termPriority ? existing.type : term.type;\n        }\n        if (!this.termNames.includes(term.name))\n            this.termNames.push(term.name);\n        if (term.type === _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.DIFFERENTIAL && !this.differentialNames.includes(term.name))\n            this.differentialNames.push(term.name);\n    }\n    addTermByName(term, type) {\n        this.addTerm(new _Term__WEBPACK_IMPORTED_MODULE_1__.Term(term, type));\n    }\n    reset() {\n        this.values.length = 1;\n        this.iteration = 1;\n        Object.keys(this.terms).forEach(name => {\n            if (this.terms[name].type !== _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.FUNCTION)\n                this.values[0][name] = this.terms[name].initialValue;\n        });\n        this.values[0][this._independent.name] = this.terms[this._independent.name].initialValue;\n        this.values[0][this._iterationTerm.name] = this.iteration;\n        this.calculateFunctions();\n    }\n    clear() {\n        this.expressions = [];\n        this.expressionsByName = {};\n        this.functionExpressionsWithCondition = [];\n        this.functionExpressionsWithoutCondition = [];\n        this.terms = {};\n        this.termNames = [];\n        this.differentialNames = [];\n        this.values.length = 1;\n        this.independent = this._independent.name;\n        this.iterationTerm = this._iterationTerm.name;\n        this.reset();\n    }\n    calculateFunctions() {\n        const calculated = new Set();\n        const values = this.getIteration(this.lastIteration);\n        // Conditional function expressions first\n        for (let i = 0; i < this.functionExpressionsWithCondition.length; i++) {\n            const e = this.functionExpressionsWithCondition[i];\n            if (e.condition && !calculated.has(e.name) && e.condition(values)) {\n                this.values[this.lastIteration - 1][e.name] = e.calculate(values);\n                calculated.add(e.name);\n            }\n        }\n        // Non-conditional function expressions\n        for (let i = 0; i < this.functionExpressionsWithoutCondition.length; i++) {\n            const e = this.functionExpressionsWithoutCondition[i];\n            if (!calculated.has(e.name))\n                this.values[this.lastIteration - 1][e.name] = e.calculate(values);\n        }\n    }\n    addValues(values) {\n        values.iteration = this.lastIteration + 1;\n        this.values.push(values);\n        this.iteration = this.lastIteration;\n    }\n    calculate(values) {\n        const results = {};\n        for (let i = 0; i < this.expressions.length; i++) {\n            const expression = this.expressions[i];\n            if (results[expression.name] === undefined && (expression.condition == null || expression.condition(values))) {\n                results[expression.name] = expression.calculate(values);\n            }\n        }\n        return results;\n    }\n    getIndependent() {\n        return this.get()[this._independent.name];\n    }\n    setInitialIndependent(value) {\n        this.terms[this._independent.name].initialValue = value;\n    }\n    isEditable(term) {\n        var _a;\n        const type = (_a = this.terms[term.name]) === null || _a === void 0 ? void 0 : _a.type;\n        return type !== _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.INDEPENDENT && type !== _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.FUNCTION;\n    }\n    set(term, value) {\n        if (!this.isEditable(term))\n            return;\n        this.values[this.lastIteration - 1][term.name] = value;\n    }\n    setByExpression(expression, value) {\n        this.values[this.lastIteration - 1][expression.name] = value;\n    }\n    getExpression(name) {\n        return this.expressionsByName[name];\n    }\n    getTerm(name) {\n        return this.terms[name];\n    }\n    isTerm(name) {\n        return this.terms[name] !== undefined;\n    }\n    setInitialByTerm(term, value) {\n        this.terms[term.name].initialValue = value;\n    }\n    setInitialByName(name, value) {\n        this.terms[name].initialValue = value;\n    }\n    getValue(values, term) {\n        return values[term];\n    }\n    getValueAtIteration(iteration, term) {\n        return this.getValue(this.values[iteration - 1], term);\n    }\n    getValueAtIndependent(value, term) {\n        const iteration = Math.round((value - this.values[0][this._independent.name]) / this.step) + 1;\n        if (iteration < 0 || iteration > this.values.length)\n            return NaN;\n        return this.getValue(this.values[iteration - 1], term);\n    }\n    getInitialByExpression(expression) {\n        return this.terms[expression.name].initialValue;\n    }\n    getTermsNames() {\n        return this.termNames;\n    }\n    getDifferentialTermsNames() {\n        return this.differentialNames;\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/System.ts?");

/***/ }),

/***/ "./CalculationEngine/Term.ts":
/*!***********************************!*\
  !*** ./CalculationEngine/Term.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Term: () => (/* binding */ Term)\n/* harmony export */ });\n/* harmony import */ var _TermType__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TermType */ \"./CalculationEngine/TermType.ts\");\n\nclass Term {\n    constructor(name, type = _TermType__WEBPACK_IMPORTED_MODULE_0__.TermType.PARAMETER) {\n        this.initialValue = 0;\n        this.name = name;\n        this.type = type;\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Term.ts?");

/***/ }),

/***/ "./CalculationEngine/TermType.ts":
/*!***************************************!*\
  !*** ./CalculationEngine/TermType.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   TermType: () => (/* binding */ TermType)\n/* harmony export */ });\nvar TermType;\n(function (TermType) {\n    TermType[TermType[\"DIFFERENTIAL\"] = 0] = \"DIFFERENTIAL\";\n    TermType[TermType[\"FUNCTION\"] = 1] = \"FUNCTION\";\n    TermType[TermType[\"INDEPENDENT\"] = 2] = \"INDEPENDENT\";\n    TermType[TermType[\"PARAMETER\"] = 3] = \"PARAMETER\";\n})(TermType || (TermType = {}));\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/TermType.ts?");

/***/ }),

/***/ "./CalculationEngine/Visitor.ts":
/*!**************************************!*\
  !*** ./CalculationEngine/Visitor.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Visitor: () => (/* binding */ Visitor)\n/* harmony export */ });\n/* harmony import */ var _Parser_LatexMathVisitor__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Parser/LatexMathVisitor */ \"./Parser/LatexMathVisitor.ts\");\n/* harmony import */ var _TermType__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TermType */ \"./CalculationEngine/TermType.ts\");\n/* harmony import */ var _Branch__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Branch */ \"./CalculationEngine/Branch.ts\");\n/* harmony import */ var _Expression__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Expression */ \"./CalculationEngine/Expression.ts\");\n\n\n\n\nclass Visitor extends _Parser_LatexMathVisitor__WEBPACK_IMPORTED_MODULE_0__.LatexMathVisitor {\n    constructor(system) {\n        super();\n        this.visitFractionDigits = (context) => {\n            var number = context.DIGIT(0).getText();\n            var dividend = parseFloat(number);\n            const left = new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(number, () => dividend);\n            number = context.DIGIT(1).getText();\n            var divisor = parseFloat(number);\n            const right = new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(number, () => divisor);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) / right.calculate(values), left, right);\n        };\n        this.visitFraction = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) / right.calculate(values), left, right);\n        };\n        this.visitVariable = (context) => {\n            const variable = context.getText();\n            this.system.addTermByName(variable, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.PARAMETER);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(variable, (values) => this.system.getValue(values, variable));\n        };\n        this.visitName = (context) => {\n            const variable = context.getText();\n            this.system.addTermByName(variable, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.PARAMETER);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(variable, (values) => this.system.getValue(values, variable));\n        };\n        this.visitDecimal = (context) => {\n            const number = context.getText();\n            const value = parseFloat(number);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(number, () => value);\n        };\n        this.visitNumber = (context) => {\n            const number = context.getText();\n            const value = parseFloat(number);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(number, () => value);\n        };\n        this.visitConstant = (context) => {\n            var _a, _b;\n            const constants = [\n                { name: \"\\\\pi\", value: Math.PI },\n                { name: \"\\\\e\", value: Math.E }\n            ];\n            const constant = context.getText().toLowerCase();\n            const value = (_b = (_a = constants.find(c => c.name === constant)) === null || _a === void 0 ? void 0 : _a.value) !== null && _b !== void 0 ? _b : 0;\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(constant, () => value);\n        };\n        this.visitFunction = (context) => {\n            const variable = this.visit(context.name());\n            const value = this.visit(context.expression());\n            const calculate = (value === null || value === void 0 ? void 0 : value.calculate) || (() => NaN);\n            const expression = new _Expression__WEBPACK_IMPORTED_MODULE_3__.Expression(variable.text, calculate, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION);\n            this.system.addExpression(expression, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), calculate);\n        };\n        this.visitFunctionSubscript = (context) => {\n            const variable = this.visit(context.name());\n            const value = this.visit(context.expression(1));\n            var index = this.visit(context.expression(0));\n            const calculate = (value === null || value === void 0 ? void 0 : value.calculate) || (() => NaN);\n            const expression = new _Expression__WEBPACK_IMPORTED_MODULE_3__.Expression(variable.text, calculate, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION, (values) => Math.floor(index.calculate(values)) == this.system.iteration);\n            this.system.addExpression(expression, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), calculate);\n        };\n        this.visitFunctionSubscriptDigit = (context) => {\n            const variable = this.visit(context.name());\n            const value = this.visit(context.expression());\n            var number = context.DIGIT().getText();\n            var index = parseInt(number);\n            const calculate = (value === null || value === void 0 ? void 0 : value.calculate) || (() => NaN);\n            const expression = new _Expression__WEBPACK_IMPORTED_MODULE_3__.Expression(variable.text, calculate, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION, _ => index == this.system.iteration);\n            this.system.addExpression(expression, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.FUNCTION);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), calculate);\n        };\n        this.visitPower = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.pow(left.calculate(values), right.calculate(values)), left, right);\n        };\n        this.visitDivision = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) / right.calculate(values), left, right);\n        };\n        this.visitMultiplication = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) * right.calculate(values), left, right);\n        };\n        this.visitMultiplicationDigit = (context) => {\n            const left = this.visit(context.expression());\n            const right = this.visit(context.decimal());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) * right.calculate(values), left, right);\n        };\n        this.visitSubtraction = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) - right.calculate(values), left, right);\n        };\n        this.visitAddition = (context) => {\n            const left = this.visit(context.expression(0));\n            const right = this.visit(context.expression(1));\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => left.calculate(values) + right.calculate(values), left, right);\n        };\n        this.visitParenthesis = (context) => {\n            return this.visit(context.expression());\n        };\n        this.visitDifferential = (context) => {\n            const variable = this.visit(context.name(0));\n            const value = this.visit(context.expression());\n            const expression = new _Expression__WEBPACK_IMPORTED_MODULE_3__.Expression(variable.text, value.calculate, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.DIFFERENTIAL);\n            this.system.addExpression(expression);\n            return value;\n        };\n        this.visitSine = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.sin(value.calculate(values)), value);\n        };\n        this.visitCosine = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.cos(value.calculate(values)), value);\n        };\n        this.visitTangent = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.tan(value.calculate(values)), value);\n        };\n        this.visitCotangent = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => 1 / Math.tan(value.calculate(values)), value);\n        };\n        this.visitSecant = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => 1 / Math.cos(value.calculate(values)), value);\n        };\n        this.visitCosecant = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => 1 / Math.sin(value.calculate(values)), value);\n        };\n        this.visitSquareRoot = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.sqrt(value.calculate(values)), value);\n        };\n        this.visitNegation = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => -value.calculate(values), value);\n        };\n        this.visitLogarithm = (context) => {\n            const value = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => Math.log10(value.calculate(values)), value);\n        };\n        this.visitSubscript = (context) => {\n            const variable = context.name().getText();\n            this.system.addTermByName(variable, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.PARAMETER);\n            var expression = this.visit(context.expression());\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), (values) => this.system.getValueAtIteration(expression.calculate(values), variable));\n        };\n        this.visitSubscriptDigit = (context) => {\n            const variable = context.name().getText();\n            this.system.addTermByName(variable, _TermType__WEBPACK_IMPORTED_MODULE_1__.TermType.PARAMETER);\n            var number = context.DIGIT().getText();\n            var index = parseFloat(number);\n            return new _Branch__WEBPACK_IMPORTED_MODULE_2__.Branch(context.getText(), _ => this.system.getValueAtIteration(index, variable));\n        };\n        this.system = system;\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./CalculationEngine/Visitor.ts?");

/***/ }),

/***/ "./Parser/LatexMathLexer.ts":
/*!**********************************!*\
  !*** ./Parser/LatexMathLexer.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LatexMathLexer: () => (/* binding */ LatexMathLexer)\n/* harmony export */ });\n/* harmony import */ var antlr4ng__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4ng */ \"./node_modules/antlr4ng/dist/index.mjs\");\n// Generated from /Users/jpdv/Documents/Modellus/CoreTypeScript/Parser/LatexMath.g4 by ANTLR 4.13.1\n\nclass LatexMathLexer extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.Lexer {\n    constructor(input) {\n        super(input);\n        this.interpreter = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.LexerATNSimulator(this, LatexMathLexer._ATN, LatexMathLexer.decisionsToDFA, new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.PredictionContextCache());\n    }\n    get grammarFileName() { return \"LatexMath.g4\"; }\n    get literalNames() { return LatexMathLexer.literalNames; }\n    get symbolicNames() { return LatexMathLexer.symbolicNames; }\n    get ruleNames() { return LatexMathLexer.ruleNames; }\n    get serializedATN() { return LatexMathLexer._serializedATN; }\n    get channelNames() { return LatexMathLexer.channelNames; }\n    get modeNames() { return LatexMathLexer.modeNames; }\n    static get _ATN() {\n        if (!LatexMathLexer.__ATN) {\n            LatexMathLexer.__ATN = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ATNDeserializer().deserialize(LatexMathLexer._serializedATN);\n        }\n        return LatexMathLexer.__ATN;\n    }\n    get vocabulary() {\n        return LatexMathLexer.vocabulary;\n    }\n}\nLatexMathLexer.T__0 = 1;\nLatexMathLexer.T__1 = 2;\nLatexMathLexer.T__2 = 3;\nLatexMathLexer.T__3 = 4;\nLatexMathLexer.T__4 = 5;\nLatexMathLexer.T__5 = 6;\nLatexMathLexer.T__6 = 7;\nLatexMathLexer.T__7 = 8;\nLatexMathLexer.T__8 = 9;\nLatexMathLexer.T__9 = 10;\nLatexMathLexer.T__10 = 11;\nLatexMathLexer.T__11 = 12;\nLatexMathLexer.T__12 = 13;\nLatexMathLexer.T__13 = 14;\nLatexMathLexer.T__14 = 15;\nLatexMathLexer.T__15 = 16;\nLatexMathLexer.T__16 = 17;\nLatexMathLexer.T__17 = 18;\nLatexMathLexer.T__18 = 19;\nLatexMathLexer.T__19 = 20;\nLatexMathLexer.T__20 = 21;\nLatexMathLexer.T__21 = 22;\nLatexMathLexer.T__22 = 23;\nLatexMathLexer.PLUS = 24;\nLatexMathLexer.MINUS = 25;\nLatexMathLexer.DIGIT = 26;\nLatexMathLexer.DOT = 27;\nLatexMathLexer.ID = 28;\nLatexMathLexer.SPECIAL = 29;\nLatexMathLexer.LETTER = 30;\nLatexMathLexer.channelNames = [\n    \"DEFAULT_TOKEN_CHANNEL\", \"HIDDEN\"\n];\nLatexMathLexer.literalNames = [\n    null, \"'\\\\frac'\", \"'{d'\", \"'}'\", \"'='\", \"'_'\", \"'{'\", \"'^'\", \"'/'\",\n    \"'\\\\cdot'\", \"'\\\\sin'\", \"'\\\\left('\", \"'\\\\right)'\", \"'\\\\cos'\", \"'\\\\tan'\",\n    \"'\\\\cosec'\", \"'\\\\sec'\", \"'\\\\cot'\", \"'\\\\sqrt'\", \"'\\\\log'\", \"'\\\\PI'\",\n    \"'\\\\pi'\", \"'\\\\E'\", \"'\\\\e'\", \"'+'\", \"'-'\", null, \"'.'\"\n];\nLatexMathLexer.symbolicNames = [\n    null, null, null, null, null, null, null, null, null, null, null,\n    null, null, null, null, null, null, null, null, null, null, null,\n    null, null, \"PLUS\", \"MINUS\", \"DIGIT\", \"DOT\", \"ID\", \"SPECIAL\", \"LETTER\"\n];\nLatexMathLexer.modeNames = [\n    \"DEFAULT_MODE\",\n];\nLatexMathLexer.ruleNames = [\n    \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \"T__5\", \"T__6\", \"T__7\",\n    \"T__8\", \"T__9\", \"T__10\", \"T__11\", \"T__12\", \"T__13\", \"T__14\", \"T__15\",\n    \"T__16\", \"T__17\", \"T__18\", \"T__19\", \"T__20\", \"T__21\", \"T__22\", \"PLUS\",\n    \"MINUS\", \"SIGN\", \"DIGIT\", \"DOT\", \"ID\", \"SPECIAL\", \"LETTER\",\n];\nLatexMathLexer._serializedATN = [\n    4, 0, 30, 190, 6, -1, 2, 0, 7, 0, 2, 1, 7, 1, 2, 2, 7, 2, 2, 3, 7, 3, 2, 4, 7, 4, 2, 5, 7, 5,\n    2, 6, 7, 6, 2, 7, 7, 7, 2, 8, 7, 8, 2, 9, 7, 9, 2, 10, 7, 10, 2, 11, 7, 11, 2, 12, 7, 12, 2,\n    13, 7, 13, 2, 14, 7, 14, 2, 15, 7, 15, 2, 16, 7, 16, 2, 17, 7, 17, 2, 18, 7, 18, 2, 19, 7,\n    19, 2, 20, 7, 20, 2, 21, 7, 21, 2, 22, 7, 22, 2, 23, 7, 23, 2, 24, 7, 24, 2, 25, 7, 25, 2,\n    26, 7, 26, 2, 27, 7, 27, 2, 28, 7, 28, 2, 29, 7, 29, 2, 30, 7, 30, 1, 0, 1, 0, 1, 0, 1, 0,\n    1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 3, 1, 3, 1, 4, 1, 4, 1, 5, 1, 5, 1, 6, 1, 6, 1, 7,\n    1, 7, 1, 8, 1, 8, 1, 8, 1, 8, 1, 8, 1, 8, 1, 9, 1, 9, 1, 9, 1, 9, 1, 9, 1, 10, 1, 10, 1, 10, 1,\n    10, 1, 10, 1, 10, 1, 10, 1, 11, 1, 11, 1, 11, 1, 11, 1, 11, 1, 11, 1, 11, 1, 11, 1, 12, 1,\n    12, 1, 12, 1, 12, 1, 12, 1, 13, 1, 13, 1, 13, 1, 13, 1, 13, 1, 14, 1, 14, 1, 14, 1, 14, 1,\n    14, 1, 14, 1, 14, 1, 15, 1, 15, 1, 15, 1, 15, 1, 15, 1, 16, 1, 16, 1, 16, 1, 16, 1, 16, 1,\n    17, 1, 17, 1, 17, 1, 17, 1, 17, 1, 17, 1, 18, 1, 18, 1, 18, 1, 18, 1, 18, 1, 19, 1, 19, 1,\n    19, 1, 19, 1, 20, 1, 20, 1, 20, 1, 20, 1, 21, 1, 21, 1, 21, 1, 22, 1, 22, 1, 22, 1, 23, 1,\n    23, 1, 24, 1, 24, 1, 25, 1, 25, 1, 26, 1, 26, 1, 27, 1, 27, 1, 28, 1, 28, 1, 28, 5, 28, 176,\n    8, 28, 10, 28, 12, 28, 179, 9, 28, 1, 29, 1, 29, 1, 29, 5, 29, 184, 8, 29, 10, 29, 12,\n    29, 187, 9, 29, 1, 30, 1, 30, 0, 0, 31, 1, 1, 3, 2, 5, 3, 7, 4, 9, 5, 11, 6, 13, 7, 15, 8,\n    17, 9, 19, 10, 21, 11, 23, 12, 25, 13, 27, 14, 29, 15, 31, 16, 33, 17, 35, 18, 37, 19,\n    39, 20, 41, 21, 43, 22, 45, 23, 47, 24, 49, 25, 51, 0, 53, 26, 55, 27, 57, 28, 59, 29,\n    61, 30, 1, 0, 2, 2, 0, 43, 43, 45, 45, 2, 0, 65, 90, 97, 122, 191, 0, 1, 1, 0, 0, 0, 0, 3,\n    1, 0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 9, 1, 0, 0, 0, 0, 11, 1, 0, 0, 0, 0, 13, 1,\n    0, 0, 0, 0, 15, 1, 0, 0, 0, 0, 17, 1, 0, 0, 0, 0, 19, 1, 0, 0, 0, 0, 21, 1, 0, 0, 0, 0, 23, 1,\n    0, 0, 0, 0, 25, 1, 0, 0, 0, 0, 27, 1, 0, 0, 0, 0, 29, 1, 0, 0, 0, 0, 31, 1, 0, 0, 0, 0, 33, 1,\n    0, 0, 0, 0, 35, 1, 0, 0, 0, 0, 37, 1, 0, 0, 0, 0, 39, 1, 0, 0, 0, 0, 41, 1, 0, 0, 0, 0, 43, 1,\n    0, 0, 0, 0, 45, 1, 0, 0, 0, 0, 47, 1, 0, 0, 0, 0, 49, 1, 0, 0, 0, 0, 53, 1, 0, 0, 0, 0, 55, 1,\n    0, 0, 0, 0, 57, 1, 0, 0, 0, 0, 59, 1, 0, 0, 0, 0, 61, 1, 0, 0, 0, 1, 63, 1, 0, 0, 0, 3, 69, 1,\n    0, 0, 0, 5, 72, 1, 0, 0, 0, 7, 74, 1, 0, 0, 0, 9, 76, 1, 0, 0, 0, 11, 78, 1, 0, 0, 0, 13, 80,\n    1, 0, 0, 0, 15, 82, 1, 0, 0, 0, 17, 84, 1, 0, 0, 0, 19, 90, 1, 0, 0, 0, 21, 95, 1, 0, 0, 0,\n    23, 102, 1, 0, 0, 0, 25, 110, 1, 0, 0, 0, 27, 115, 1, 0, 0, 0, 29, 120, 1, 0, 0, 0, 31, 127,\n    1, 0, 0, 0, 33, 132, 1, 0, 0, 0, 35, 137, 1, 0, 0, 0, 37, 143, 1, 0, 0, 0, 39, 148, 1, 0,\n    0, 0, 41, 152, 1, 0, 0, 0, 43, 156, 1, 0, 0, 0, 45, 159, 1, 0, 0, 0, 47, 162, 1, 0, 0, 0,\n    49, 164, 1, 0, 0, 0, 51, 166, 1, 0, 0, 0, 53, 168, 1, 0, 0, 0, 55, 170, 1, 0, 0, 0, 57, 172,\n    1, 0, 0, 0, 59, 180, 1, 0, 0, 0, 61, 188, 1, 0, 0, 0, 63, 64, 5, 92, 0, 0, 64, 65, 5, 102,\n    0, 0, 65, 66, 5, 114, 0, 0, 66, 67, 5, 97, 0, 0, 67, 68, 5, 99, 0, 0, 68, 2, 1, 0, 0, 0, 69,\n    70, 5, 123, 0, 0, 70, 71, 5, 100, 0, 0, 71, 4, 1, 0, 0, 0, 72, 73, 5, 125, 0, 0, 73, 6, 1,\n    0, 0, 0, 74, 75, 5, 61, 0, 0, 75, 8, 1, 0, 0, 0, 76, 77, 5, 95, 0, 0, 77, 10, 1, 0, 0, 0, 78,\n    79, 5, 123, 0, 0, 79, 12, 1, 0, 0, 0, 80, 81, 5, 94, 0, 0, 81, 14, 1, 0, 0, 0, 82, 83, 5,\n    47, 0, 0, 83, 16, 1, 0, 0, 0, 84, 85, 5, 92, 0, 0, 85, 86, 5, 99, 0, 0, 86, 87, 5, 100, 0,\n    0, 87, 88, 5, 111, 0, 0, 88, 89, 5, 116, 0, 0, 89, 18, 1, 0, 0, 0, 90, 91, 5, 92, 0, 0, 91,\n    92, 5, 115, 0, 0, 92, 93, 5, 105, 0, 0, 93, 94, 5, 110, 0, 0, 94, 20, 1, 0, 0, 0, 95, 96,\n    5, 92, 0, 0, 96, 97, 5, 108, 0, 0, 97, 98, 5, 101, 0, 0, 98, 99, 5, 102, 0, 0, 99, 100,\n    5, 116, 0, 0, 100, 101, 5, 40, 0, 0, 101, 22, 1, 0, 0, 0, 102, 103, 5, 92, 0, 0, 103, 104,\n    5, 114, 0, 0, 104, 105, 5, 105, 0, 0, 105, 106, 5, 103, 0, 0, 106, 107, 5, 104, 0, 0,\n    107, 108, 5, 116, 0, 0, 108, 109, 5, 41, 0, 0, 109, 24, 1, 0, 0, 0, 110, 111, 5, 92, 0,\n    0, 111, 112, 5, 99, 0, 0, 112, 113, 5, 111, 0, 0, 113, 114, 5, 115, 0, 0, 114, 26, 1,\n    0, 0, 0, 115, 116, 5, 92, 0, 0, 116, 117, 5, 116, 0, 0, 117, 118, 5, 97, 0, 0, 118, 119,\n    5, 110, 0, 0, 119, 28, 1, 0, 0, 0, 120, 121, 5, 92, 0, 0, 121, 122, 5, 99, 0, 0, 122, 123,\n    5, 111, 0, 0, 123, 124, 5, 115, 0, 0, 124, 125, 5, 101, 0, 0, 125, 126, 5, 99, 0, 0, 126,\n    30, 1, 0, 0, 0, 127, 128, 5, 92, 0, 0, 128, 129, 5, 115, 0, 0, 129, 130, 5, 101, 0, 0,\n    130, 131, 5, 99, 0, 0, 131, 32, 1, 0, 0, 0, 132, 133, 5, 92, 0, 0, 133, 134, 5, 99, 0,\n    0, 134, 135, 5, 111, 0, 0, 135, 136, 5, 116, 0, 0, 136, 34, 1, 0, 0, 0, 137, 138, 5, 92,\n    0, 0, 138, 139, 5, 115, 0, 0, 139, 140, 5, 113, 0, 0, 140, 141, 5, 114, 0, 0, 141, 142,\n    5, 116, 0, 0, 142, 36, 1, 0, 0, 0, 143, 144, 5, 92, 0, 0, 144, 145, 5, 108, 0, 0, 145,\n    146, 5, 111, 0, 0, 146, 147, 5, 103, 0, 0, 147, 38, 1, 0, 0, 0, 148, 149, 5, 92, 0, 0,\n    149, 150, 5, 80, 0, 0, 150, 151, 5, 73, 0, 0, 151, 40, 1, 0, 0, 0, 152, 153, 5, 92, 0,\n    0, 153, 154, 5, 112, 0, 0, 154, 155, 5, 105, 0, 0, 155, 42, 1, 0, 0, 0, 156, 157, 5, 92,\n    0, 0, 157, 158, 5, 69, 0, 0, 158, 44, 1, 0, 0, 0, 159, 160, 5, 92, 0, 0, 160, 161, 5, 101,\n    0, 0, 161, 46, 1, 0, 0, 0, 162, 163, 5, 43, 0, 0, 163, 48, 1, 0, 0, 0, 164, 165, 5, 45,\n    0, 0, 165, 50, 1, 0, 0, 0, 166, 167, 7, 0, 0, 0, 167, 52, 1, 0, 0, 0, 168, 169, 2, 48, 57,\n    0, 169, 54, 1, 0, 0, 0, 170, 171, 5, 46, 0, 0, 171, 56, 1, 0, 0, 0, 172, 177, 3, 61, 30,\n    0, 173, 176, 3, 61, 30, 0, 174, 176, 3, 53, 26, 0, 175, 173, 1, 0, 0, 0, 175, 174, 1,\n    0, 0, 0, 176, 179, 1, 0, 0, 0, 177, 175, 1, 0, 0, 0, 177, 178, 1, 0, 0, 0, 178, 58, 1, 0,\n    0, 0, 179, 177, 1, 0, 0, 0, 180, 181, 5, 92, 0, 0, 181, 185, 3, 61, 30, 0, 182, 184, 3,\n    61, 30, 0, 183, 182, 1, 0, 0, 0, 184, 187, 1, 0, 0, 0, 185, 183, 1, 0, 0, 0, 185, 186,\n    1, 0, 0, 0, 186, 60, 1, 0, 0, 0, 187, 185, 1, 0, 0, 0, 188, 189, 7, 1, 0, 0, 189, 62, 1,\n    0, 0, 0, 4, 0, 175, 177, 185, 0\n];\nLatexMathLexer.vocabulary = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.Vocabulary(LatexMathLexer.literalNames, LatexMathLexer.symbolicNames, []);\nLatexMathLexer.decisionsToDFA = LatexMathLexer._ATN.decisionToState.map((ds, index) => new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.DFA(ds, index));\n\n\n//# sourceURL=webpack://Modellus/./Parser/LatexMathLexer.ts?");

/***/ }),

/***/ "./Parser/LatexMathParser.ts":
/*!***********************************!*\
  !*** ./Parser/LatexMathParser.ts ***!
  \***********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AdditionContext: () => (/* binding */ AdditionContext),\n/* harmony export */   AssignmentContext: () => (/* binding */ AssignmentContext),\n/* harmony export */   ConstantContext: () => (/* binding */ ConstantContext),\n/* harmony export */   CosecantContext: () => (/* binding */ CosecantContext),\n/* harmony export */   CosineContext: () => (/* binding */ CosineContext),\n/* harmony export */   CotangentContext: () => (/* binding */ CotangentContext),\n/* harmony export */   DecimalContext: () => (/* binding */ DecimalContext),\n/* harmony export */   DifferentialContext: () => (/* binding */ DifferentialContext),\n/* harmony export */   DivisionContext: () => (/* binding */ DivisionContext),\n/* harmony export */   ExpressionContext: () => (/* binding */ ExpressionContext),\n/* harmony export */   FractionContext: () => (/* binding */ FractionContext),\n/* harmony export */   FractionDigitsContext: () => (/* binding */ FractionDigitsContext),\n/* harmony export */   FunctionContext: () => (/* binding */ FunctionContext),\n/* harmony export */   FunctionSubscriptContext: () => (/* binding */ FunctionSubscriptContext),\n/* harmony export */   FunctionSubscriptDigitContext: () => (/* binding */ FunctionSubscriptDigitContext),\n/* harmony export */   LatexMathParser: () => (/* binding */ LatexMathParser),\n/* harmony export */   LogarithmContext: () => (/* binding */ LogarithmContext),\n/* harmony export */   MultiplicationContext: () => (/* binding */ MultiplicationContext),\n/* harmony export */   MultiplicationDigitContext: () => (/* binding */ MultiplicationDigitContext),\n/* harmony export */   NameContext: () => (/* binding */ NameContext),\n/* harmony export */   NegationContext: () => (/* binding */ NegationContext),\n/* harmony export */   NumberContext: () => (/* binding */ NumberContext),\n/* harmony export */   ParenthesisContext: () => (/* binding */ ParenthesisContext),\n/* harmony export */   PowerContext: () => (/* binding */ PowerContext),\n/* harmony export */   ProgramContext: () => (/* binding */ ProgramContext),\n/* harmony export */   ReservedContext: () => (/* binding */ ReservedContext),\n/* harmony export */   SecantContext: () => (/* binding */ SecantContext),\n/* harmony export */   SineContext: () => (/* binding */ SineContext),\n/* harmony export */   SquareRootContext: () => (/* binding */ SquareRootContext),\n/* harmony export */   StatementContext: () => (/* binding */ StatementContext),\n/* harmony export */   SubscriptContext: () => (/* binding */ SubscriptContext),\n/* harmony export */   SubscriptDigitContext: () => (/* binding */ SubscriptDigitContext),\n/* harmony export */   SubtractionContext: () => (/* binding */ SubtractionContext),\n/* harmony export */   TangentContext: () => (/* binding */ TangentContext),\n/* harmony export */   VariableContext: () => (/* binding */ VariableContext)\n/* harmony export */ });\n/* harmony import */ var antlr4ng__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4ng */ \"./node_modules/antlr4ng/dist/index.mjs\");\n// Generated from /Users/jpdv/Documents/Modellus/CoreTypeScript/Parser/LatexMath.g4 by ANTLR 4.13.1\n\nclass LatexMathParser extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.Parser {\n    get grammarFileName() { return \"LatexMath.g4\"; }\n    get literalNames() { return LatexMathParser.literalNames; }\n    get symbolicNames() { return LatexMathParser.symbolicNames; }\n    get ruleNames() { return LatexMathParser.ruleNames; }\n    get serializedATN() { return LatexMathParser._serializedATN; }\n    createFailedPredicateException(predicate, message) {\n        return new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.FailedPredicateException(this, predicate, message);\n    }\n    constructor(input) {\n        super(input);\n        this.interpreter = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserATNSimulator(this, LatexMathParser._ATN, LatexMathParser.decisionsToDFA, new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.PredictionContextCache());\n    }\n    program() {\n        let localContext = new ProgramContext(this.context, this.state);\n        this.enterRule(localContext, 0, LatexMathParser.RULE_program);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 16;\n                this.statement();\n                this.state = 17;\n                this.match(LatexMathParser.EOF);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    statement() {\n        let localContext = new StatementContext(this.context, this.state);\n        this.enterRule(localContext, 2, LatexMathParser.RULE_statement);\n        try {\n            this.state = 22;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 0, this.context)) {\n                case 1:\n                    this.enterOuterAlt(localContext, 1);\n                    {\n                        this.state = 19;\n                        this.differential();\n                    }\n                    break;\n                case 2:\n                    this.enterOuterAlt(localContext, 2);\n                    {\n                        this.state = 20;\n                        this.assignment();\n                    }\n                    break;\n                case 3:\n                    this.enterOuterAlt(localContext, 3);\n                    {\n                        this.state = 21;\n                        this.expression(0);\n                    }\n                    break;\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    differential() {\n        let localContext = new DifferentialContext(this.context, this.state);\n        this.enterRule(localContext, 4, LatexMathParser.RULE_differential);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 24;\n                this.match(LatexMathParser.T__0);\n                this.state = 25;\n                this.match(LatexMathParser.T__1);\n                this.state = 26;\n                this.name();\n                this.state = 27;\n                this.match(LatexMathParser.T__2);\n                this.state = 28;\n                this.match(LatexMathParser.T__1);\n                this.state = 29;\n                this.name();\n                this.state = 30;\n                this.match(LatexMathParser.T__2);\n                this.state = 31;\n                this.match(LatexMathParser.T__3);\n                this.state = 32;\n                this.expression(0);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    assignment() {\n        let localContext = new AssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 6, LatexMathParser.RULE_assignment);\n        try {\n            this.state = 52;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 1, this.context)) {\n                case 1:\n                    localContext = new FunctionContext(localContext);\n                    this.enterOuterAlt(localContext, 1);\n                    {\n                        this.state = 34;\n                        this.name();\n                        this.state = 35;\n                        this.match(LatexMathParser.T__3);\n                        this.state = 36;\n                        this.expression(0);\n                    }\n                    break;\n                case 2:\n                    localContext = new FunctionSubscriptContext(localContext);\n                    this.enterOuterAlt(localContext, 2);\n                    {\n                        this.state = 38;\n                        this.name();\n                        this.state = 39;\n                        this.match(LatexMathParser.T__4);\n                        this.state = 40;\n                        this.match(LatexMathParser.T__5);\n                        this.state = 41;\n                        this.expression(0);\n                        this.state = 42;\n                        this.match(LatexMathParser.T__2);\n                        this.state = 43;\n                        this.match(LatexMathParser.T__3);\n                        this.state = 44;\n                        this.expression(0);\n                    }\n                    break;\n                case 3:\n                    localContext = new FunctionSubscriptDigitContext(localContext);\n                    this.enterOuterAlt(localContext, 3);\n                    {\n                        this.state = 46;\n                        this.name();\n                        this.state = 47;\n                        this.match(LatexMathParser.T__4);\n                        this.state = 48;\n                        this.match(LatexMathParser.DIGIT);\n                        this.state = 49;\n                        this.match(LatexMathParser.T__3);\n                        this.state = 50;\n                        this.expression(0);\n                    }\n                    break;\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    expression(_p) {\n        if (_p === undefined) {\n            _p = 0;\n        }\n        let parentContext = this.context;\n        let parentState = this.state;\n        let localContext = new ExpressionContext(this.context, parentState);\n        let previousContext = localContext;\n        let _startState = 8;\n        this.enterRecursionRule(localContext, 8, LatexMathParser.RULE_expression, _p);\n        try {\n            let alternative;\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 125;\n                this.errorHandler.sync(this);\n                switch (this.interpreter.adaptivePredict(this.tokenStream, 2, this.context)) {\n                    case 1:\n                        {\n                            localContext = new NegationContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 55;\n                            this.match(LatexMathParser.MINUS);\n                            this.state = 56;\n                            this.expression(22);\n                        }\n                        break;\n                    case 2:\n                        {\n                            localContext = new SubscriptContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 57;\n                            this.name();\n                            this.state = 58;\n                            this.match(LatexMathParser.T__4);\n                            this.state = 59;\n                            this.match(LatexMathParser.T__5);\n                            this.state = 60;\n                            this.expression(0);\n                            this.state = 61;\n                            this.match(LatexMathParser.T__2);\n                        }\n                        break;\n                    case 3:\n                        {\n                            localContext = new SubscriptDigitContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 63;\n                            this.name();\n                            this.state = 64;\n                            this.match(LatexMathParser.T__4);\n                            this.state = 65;\n                            this.match(LatexMathParser.DIGIT);\n                        }\n                        break;\n                    case 4:\n                        {\n                            localContext = new FractionContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 67;\n                            this.match(LatexMathParser.T__0);\n                            this.state = 68;\n                            this.match(LatexMathParser.T__5);\n                            this.state = 69;\n                            this.expression(0);\n                            this.state = 70;\n                            this.match(LatexMathParser.T__2);\n                            this.state = 71;\n                            this.match(LatexMathParser.T__5);\n                            this.state = 72;\n                            this.expression(0);\n                            this.state = 73;\n                            this.match(LatexMathParser.T__2);\n                        }\n                        break;\n                    case 5:\n                        {\n                            localContext = new FractionDigitsContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 75;\n                            this.match(LatexMathParser.T__0);\n                            this.state = 76;\n                            this.match(LatexMathParser.DIGIT);\n                            this.state = 77;\n                            this.match(LatexMathParser.DIGIT);\n                        }\n                        break;\n                    case 6:\n                        {\n                            localContext = new SineContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 78;\n                            this.match(LatexMathParser.T__9);\n                            this.state = 79;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 80;\n                            this.expression(0);\n                            this.state = 81;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 7:\n                        {\n                            localContext = new CosineContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 83;\n                            this.match(LatexMathParser.T__12);\n                            this.state = 84;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 85;\n                            this.expression(0);\n                            this.state = 86;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 8:\n                        {\n                            localContext = new TangentContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 88;\n                            this.match(LatexMathParser.T__13);\n                            this.state = 89;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 90;\n                            this.expression(0);\n                            this.state = 91;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 9:\n                        {\n                            localContext = new CosecantContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 93;\n                            this.match(LatexMathParser.T__14);\n                            this.state = 94;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 95;\n                            this.expression(0);\n                            this.state = 96;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 10:\n                        {\n                            localContext = new SecantContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 98;\n                            this.match(LatexMathParser.T__15);\n                            this.state = 99;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 100;\n                            this.expression(0);\n                            this.state = 101;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 11:\n                        {\n                            localContext = new CotangentContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 103;\n                            this.match(LatexMathParser.T__16);\n                            this.state = 104;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 105;\n                            this.expression(0);\n                            this.state = 106;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 12:\n                        {\n                            localContext = new SquareRootContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 108;\n                            this.match(LatexMathParser.T__17);\n                            this.state = 109;\n                            this.match(LatexMathParser.T__5);\n                            this.state = 110;\n                            this.expression(0);\n                            this.state = 111;\n                            this.match(LatexMathParser.T__2);\n                        }\n                        break;\n                    case 13:\n                        {\n                            localContext = new LogarithmContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 113;\n                            this.match(LatexMathParser.T__18);\n                            this.state = 114;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 115;\n                            this.expression(0);\n                            this.state = 116;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                    case 14:\n                        {\n                            localContext = new ConstantContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 118;\n                            this.reserved();\n                        }\n                        break;\n                    case 15:\n                        {\n                            localContext = new NumberContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 119;\n                            this.decimal();\n                        }\n                        break;\n                    case 16:\n                        {\n                            localContext = new VariableContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 120;\n                            this.name();\n                        }\n                        break;\n                    case 17:\n                        {\n                            localContext = new ParenthesisContext(localContext);\n                            this.context = localContext;\n                            previousContext = localContext;\n                            this.state = 121;\n                            this.match(LatexMathParser.T__10);\n                            this.state = 122;\n                            this.expression(0);\n                            this.state = 123;\n                            this.match(LatexMathParser.T__11);\n                        }\n                        break;\n                }\n                this.context.stop = this.tokenStream.LT(-1);\n                this.state = 147;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 4, this.context);\n                while (alternative !== 2 && alternative !== antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ATN.INVALID_ALT_NUMBER) {\n                    if (alternative === 1) {\n                        if (this.parseListeners != null) {\n                            this.triggerExitRuleEvent();\n                        }\n                        previousContext = localContext;\n                        {\n                            this.state = 145;\n                            this.errorHandler.sync(this);\n                            switch (this.interpreter.adaptivePredict(this.tokenStream, 3, this.context)) {\n                                case 1:\n                                    {\n                                        localContext = new PowerContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 127;\n                                        if (!(this.precpred(this.context, 23))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 23)\");\n                                        }\n                                        this.state = 128;\n                                        this.match(LatexMathParser.T__6);\n                                        this.state = 129;\n                                        this.expression(24);\n                                    }\n                                    break;\n                                case 2:\n                                    {\n                                        localContext = new DivisionContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 130;\n                                        if (!(this.precpred(this.context, 21))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 21)\");\n                                        }\n                                        this.state = 131;\n                                        this.match(LatexMathParser.T__7);\n                                        this.state = 132;\n                                        this.expression(22);\n                                    }\n                                    break;\n                                case 3:\n                                    {\n                                        localContext = new MultiplicationContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 133;\n                                        if (!(this.precpred(this.context, 20))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 20)\");\n                                        }\n                                        this.state = 134;\n                                        this.match(LatexMathParser.T__8);\n                                        this.state = 135;\n                                        this.expression(21);\n                                    }\n                                    break;\n                                case 4:\n                                    {\n                                        localContext = new AdditionContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 136;\n                                        if (!(this.precpred(this.context, 18))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 18)\");\n                                        }\n                                        this.state = 137;\n                                        this.match(LatexMathParser.PLUS);\n                                        this.state = 138;\n                                        this.expression(19);\n                                    }\n                                    break;\n                                case 5:\n                                    {\n                                        localContext = new SubtractionContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 139;\n                                        if (!(this.precpred(this.context, 17))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 17)\");\n                                        }\n                                        this.state = 140;\n                                        this.match(LatexMathParser.MINUS);\n                                        this.state = 141;\n                                        this.expression(18);\n                                    }\n                                    break;\n                                case 6:\n                                    {\n                                        localContext = new MultiplicationDigitContext(new ExpressionContext(parentContext, parentState));\n                                        this.pushNewRecursionContext(localContext, _startState, LatexMathParser.RULE_expression);\n                                        this.state = 142;\n                                        if (!(this.precpred(this.context, 19))) {\n                                            throw this.createFailedPredicateException(\"this.precpred(this.context, 19)\");\n                                        }\n                                        this.state = 143;\n                                        this.match(LatexMathParser.T__8);\n                                        this.state = 144;\n                                        this.decimal();\n                                    }\n                                    break;\n                            }\n                        }\n                    }\n                    this.state = 149;\n                    this.errorHandler.sync(this);\n                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 4, this.context);\n                }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.unrollRecursionContexts(parentContext);\n        }\n        return localContext;\n    }\n    reserved() {\n        let localContext = new ReservedContext(this.context, this.state);\n        this.enterRule(localContext, 10, LatexMathParser.RULE_reserved);\n        let _la;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 150;\n                _la = this.tokenStream.LA(1);\n                if (!((((_la) & ~0x1F) === 0 && ((1 << _la) & 15728640) !== 0))) {\n                    this.errorHandler.recoverInline(this);\n                }\n                else {\n                    this.errorHandler.reportMatch(this);\n                    this.consume();\n                }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    decimal() {\n        let localContext = new DecimalContext(this.context, this.state);\n        this.enterRule(localContext, 12, LatexMathParser.RULE_decimal);\n        let _la;\n        try {\n            let alternative;\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 153;\n                this.errorHandler.sync(this);\n                _la = this.tokenStream.LA(1);\n                if (_la === 24 || _la === 25) {\n                    {\n                        this.state = 152;\n                        _la = this.tokenStream.LA(1);\n                        if (!(_la === 24 || _la === 25)) {\n                            this.errorHandler.recoverInline(this);\n                        }\n                        else {\n                            this.errorHandler.reportMatch(this);\n                            this.consume();\n                        }\n                    }\n                }\n                this.state = 156;\n                this.errorHandler.sync(this);\n                alternative = 1;\n                do {\n                    switch (alternative) {\n                        case 1:\n                            {\n                                {\n                                    this.state = 155;\n                                    this.match(LatexMathParser.DIGIT);\n                                }\n                            }\n                            break;\n                        default:\n                            throw new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.NoViableAltException(this);\n                    }\n                    this.state = 158;\n                    this.errorHandler.sync(this);\n                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 6, this.context);\n                } while (alternative !== 2 && alternative !== antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ATN.INVALID_ALT_NUMBER);\n                this.state = 166;\n                this.errorHandler.sync(this);\n                switch (this.interpreter.adaptivePredict(this.tokenStream, 8, this.context)) {\n                    case 1:\n                        {\n                            this.state = 160;\n                            this.match(LatexMathParser.DOT);\n                            this.state = 162;\n                            this.errorHandler.sync(this);\n                            alternative = 1;\n                            do {\n                                switch (alternative) {\n                                    case 1:\n                                        {\n                                            {\n                                                this.state = 161;\n                                                this.match(LatexMathParser.DIGIT);\n                                            }\n                                        }\n                                        break;\n                                    default:\n                                        throw new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.NoViableAltException(this);\n                                }\n                                this.state = 164;\n                                this.errorHandler.sync(this);\n                                alternative = this.interpreter.adaptivePredict(this.tokenStream, 7, this.context);\n                            } while (alternative !== 2 && alternative !== antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ATN.INVALID_ALT_NUMBER);\n                        }\n                        break;\n                }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    name() {\n        let localContext = new NameContext(this.context, this.state);\n        this.enterRule(localContext, 14, LatexMathParser.RULE_name);\n        let _la;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n                this.state = 168;\n                _la = this.tokenStream.LA(1);\n                if (!(_la === 28 || _la === 29)) {\n                    this.errorHandler.recoverInline(this);\n                }\n                else {\n                    this.errorHandler.reportMatch(this);\n                    this.consume();\n                }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr4ng__WEBPACK_IMPORTED_MODULE_0__.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            }\n            else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    sempred(localContext, ruleIndex, predIndex) {\n        switch (ruleIndex) {\n            case 4:\n                return this.expression_sempred(localContext, predIndex);\n        }\n        return true;\n    }\n    expression_sempred(localContext, predIndex) {\n        switch (predIndex) {\n            case 0:\n                return this.precpred(this.context, 23);\n            case 1:\n                return this.precpred(this.context, 21);\n            case 2:\n                return this.precpred(this.context, 20);\n            case 3:\n                return this.precpred(this.context, 18);\n            case 4:\n                return this.precpred(this.context, 17);\n            case 5:\n                return this.precpred(this.context, 19);\n        }\n        return true;\n    }\n    static get _ATN() {\n        if (!LatexMathParser.__ATN) {\n            LatexMathParser.__ATN = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ATNDeserializer().deserialize(LatexMathParser._serializedATN);\n        }\n        return LatexMathParser.__ATN;\n    }\n    get vocabulary() {\n        return LatexMathParser.vocabulary;\n    }\n}\nLatexMathParser.T__0 = 1;\nLatexMathParser.T__1 = 2;\nLatexMathParser.T__2 = 3;\nLatexMathParser.T__3 = 4;\nLatexMathParser.T__4 = 5;\nLatexMathParser.T__5 = 6;\nLatexMathParser.T__6 = 7;\nLatexMathParser.T__7 = 8;\nLatexMathParser.T__8 = 9;\nLatexMathParser.T__9 = 10;\nLatexMathParser.T__10 = 11;\nLatexMathParser.T__11 = 12;\nLatexMathParser.T__12 = 13;\nLatexMathParser.T__13 = 14;\nLatexMathParser.T__14 = 15;\nLatexMathParser.T__15 = 16;\nLatexMathParser.T__16 = 17;\nLatexMathParser.T__17 = 18;\nLatexMathParser.T__18 = 19;\nLatexMathParser.T__19 = 20;\nLatexMathParser.T__20 = 21;\nLatexMathParser.T__21 = 22;\nLatexMathParser.T__22 = 23;\nLatexMathParser.PLUS = 24;\nLatexMathParser.MINUS = 25;\nLatexMathParser.DIGIT = 26;\nLatexMathParser.DOT = 27;\nLatexMathParser.ID = 28;\nLatexMathParser.SPECIAL = 29;\nLatexMathParser.LETTER = 30;\nLatexMathParser.RULE_program = 0;\nLatexMathParser.RULE_statement = 1;\nLatexMathParser.RULE_differential = 2;\nLatexMathParser.RULE_assignment = 3;\nLatexMathParser.RULE_expression = 4;\nLatexMathParser.RULE_reserved = 5;\nLatexMathParser.RULE_decimal = 6;\nLatexMathParser.RULE_name = 7;\nLatexMathParser.literalNames = [\n    null, \"'\\\\frac'\", \"'{d'\", \"'}'\", \"'='\", \"'_'\", \"'{'\", \"'^'\", \"'/'\",\n    \"'\\\\cdot'\", \"'\\\\sin'\", \"'\\\\left('\", \"'\\\\right)'\", \"'\\\\cos'\", \"'\\\\tan'\",\n    \"'\\\\cosec'\", \"'\\\\sec'\", \"'\\\\cot'\", \"'\\\\sqrt'\", \"'\\\\log'\", \"'\\\\PI'\",\n    \"'\\\\pi'\", \"'\\\\E'\", \"'\\\\e'\", \"'+'\", \"'-'\", null, \"'.'\"\n];\nLatexMathParser.symbolicNames = [\n    null, null, null, null, null, null, null, null, null, null, null,\n    null, null, null, null, null, null, null, null, null, null, null,\n    null, null, \"PLUS\", \"MINUS\", \"DIGIT\", \"DOT\", \"ID\", \"SPECIAL\", \"LETTER\"\n];\nLatexMathParser.ruleNames = [\n    \"program\", \"statement\", \"differential\", \"assignment\", \"expression\",\n    \"reserved\", \"decimal\", \"name\",\n];\nLatexMathParser._serializedATN = [\n    4, 1, 30, 171, 2, 0, 7, 0, 2, 1, 7, 1, 2, 2, 7, 2, 2, 3, 7, 3, 2, 4, 7, 4, 2, 5, 7, 5, 2, 6, 7,\n    6, 2, 7, 7, 7, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 3, 1, 23, 8, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,\n    1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3,\n    1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 3, 3, 53, 8, 3, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 3, 4, 126, 8, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n    4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 5, 4, 146, 8, 4, 10, 4, 12, 4, 149, 9, 4, 1, 5, 1, 5, 1, 6,\n    3, 6, 154, 8, 6, 1, 6, 4, 6, 157, 8, 6, 11, 6, 12, 6, 158, 1, 6, 1, 6, 4, 6, 163, 8, 6, 11,\n    6, 12, 6, 164, 3, 6, 167, 8, 6, 1, 7, 1, 7, 1, 7, 0, 1, 8, 8, 0, 2, 4, 6, 8, 10, 12, 14, 0,\n    3, 1, 0, 20, 23, 1, 0, 24, 25, 1, 0, 28, 29, 192, 0, 16, 1, 0, 0, 0, 2, 22, 1, 0, 0, 0, 4,\n    24, 1, 0, 0, 0, 6, 52, 1, 0, 0, 0, 8, 125, 1, 0, 0, 0, 10, 150, 1, 0, 0, 0, 12, 153, 1, 0,\n    0, 0, 14, 168, 1, 0, 0, 0, 16, 17, 3, 2, 1, 0, 17, 18, 5, 0, 0, 1, 18, 1, 1, 0, 0, 0, 19, 23,\n    3, 4, 2, 0, 20, 23, 3, 6, 3, 0, 21, 23, 3, 8, 4, 0, 22, 19, 1, 0, 0, 0, 22, 20, 1, 0, 0, 0,\n    22, 21, 1, 0, 0, 0, 23, 3, 1, 0, 0, 0, 24, 25, 5, 1, 0, 0, 25, 26, 5, 2, 0, 0, 26, 27, 3, 14,\n    7, 0, 27, 28, 5, 3, 0, 0, 28, 29, 5, 2, 0, 0, 29, 30, 3, 14, 7, 0, 30, 31, 5, 3, 0, 0, 31,\n    32, 5, 4, 0, 0, 32, 33, 3, 8, 4, 0, 33, 5, 1, 0, 0, 0, 34, 35, 3, 14, 7, 0, 35, 36, 5, 4, 0,\n    0, 36, 37, 3, 8, 4, 0, 37, 53, 1, 0, 0, 0, 38, 39, 3, 14, 7, 0, 39, 40, 5, 5, 0, 0, 40, 41,\n    5, 6, 0, 0, 41, 42, 3, 8, 4, 0, 42, 43, 5, 3, 0, 0, 43, 44, 5, 4, 0, 0, 44, 45, 3, 8, 4, 0,\n    45, 53, 1, 0, 0, 0, 46, 47, 3, 14, 7, 0, 47, 48, 5, 5, 0, 0, 48, 49, 5, 26, 0, 0, 49, 50,\n    5, 4, 0, 0, 50, 51, 3, 8, 4, 0, 51, 53, 1, 0, 0, 0, 52, 34, 1, 0, 0, 0, 52, 38, 1, 0, 0, 0,\n    52, 46, 1, 0, 0, 0, 53, 7, 1, 0, 0, 0, 54, 55, 6, 4, -1, 0, 55, 56, 5, 25, 0, 0, 56, 126,\n    3, 8, 4, 22, 57, 58, 3, 14, 7, 0, 58, 59, 5, 5, 0, 0, 59, 60, 5, 6, 0, 0, 60, 61, 3, 8, 4,\n    0, 61, 62, 5, 3, 0, 0, 62, 126, 1, 0, 0, 0, 63, 64, 3, 14, 7, 0, 64, 65, 5, 5, 0, 0, 65, 66,\n    5, 26, 0, 0, 66, 126, 1, 0, 0, 0, 67, 68, 5, 1, 0, 0, 68, 69, 5, 6, 0, 0, 69, 70, 3, 8, 4,\n    0, 70, 71, 5, 3, 0, 0, 71, 72, 5, 6, 0, 0, 72, 73, 3, 8, 4, 0, 73, 74, 5, 3, 0, 0, 74, 126,\n    1, 0, 0, 0, 75, 76, 5, 1, 0, 0, 76, 77, 5, 26, 0, 0, 77, 126, 5, 26, 0, 0, 78, 79, 5, 10,\n    0, 0, 79, 80, 5, 11, 0, 0, 80, 81, 3, 8, 4, 0, 81, 82, 5, 12, 0, 0, 82, 126, 1, 0, 0, 0, 83,\n    84, 5, 13, 0, 0, 84, 85, 5, 11, 0, 0, 85, 86, 3, 8, 4, 0, 86, 87, 5, 12, 0, 0, 87, 126, 1,\n    0, 0, 0, 88, 89, 5, 14, 0, 0, 89, 90, 5, 11, 0, 0, 90, 91, 3, 8, 4, 0, 91, 92, 5, 12, 0, 0,\n    92, 126, 1, 0, 0, 0, 93, 94, 5, 15, 0, 0, 94, 95, 5, 11, 0, 0, 95, 96, 3, 8, 4, 0, 96, 97,\n    5, 12, 0, 0, 97, 126, 1, 0, 0, 0, 98, 99, 5, 16, 0, 0, 99, 100, 5, 11, 0, 0, 100, 101, 3,\n    8, 4, 0, 101, 102, 5, 12, 0, 0, 102, 126, 1, 0, 0, 0, 103, 104, 5, 17, 0, 0, 104, 105,\n    5, 11, 0, 0, 105, 106, 3, 8, 4, 0, 106, 107, 5, 12, 0, 0, 107, 126, 1, 0, 0, 0, 108, 109,\n    5, 18, 0, 0, 109, 110, 5, 6, 0, 0, 110, 111, 3, 8, 4, 0, 111, 112, 5, 3, 0, 0, 112, 126,\n    1, 0, 0, 0, 113, 114, 5, 19, 0, 0, 114, 115, 5, 11, 0, 0, 115, 116, 3, 8, 4, 0, 116, 117,\n    5, 12, 0, 0, 117, 126, 1, 0, 0, 0, 118, 126, 3, 10, 5, 0, 119, 126, 3, 12, 6, 0, 120, 126,\n    3, 14, 7, 0, 121, 122, 5, 11, 0, 0, 122, 123, 3, 8, 4, 0, 123, 124, 5, 12, 0, 0, 124, 126,\n    1, 0, 0, 0, 125, 54, 1, 0, 0, 0, 125, 57, 1, 0, 0, 0, 125, 63, 1, 0, 0, 0, 125, 67, 1, 0,\n    0, 0, 125, 75, 1, 0, 0, 0, 125, 78, 1, 0, 0, 0, 125, 83, 1, 0, 0, 0, 125, 88, 1, 0, 0, 0,\n    125, 93, 1, 0, 0, 0, 125, 98, 1, 0, 0, 0, 125, 103, 1, 0, 0, 0, 125, 108, 1, 0, 0, 0, 125,\n    113, 1, 0, 0, 0, 125, 118, 1, 0, 0, 0, 125, 119, 1, 0, 0, 0, 125, 120, 1, 0, 0, 0, 125,\n    121, 1, 0, 0, 0, 126, 147, 1, 0, 0, 0, 127, 128, 10, 23, 0, 0, 128, 129, 5, 7, 0, 0, 129,\n    146, 3, 8, 4, 24, 130, 131, 10, 21, 0, 0, 131, 132, 5, 8, 0, 0, 132, 146, 3, 8, 4, 22,\n    133, 134, 10, 20, 0, 0, 134, 135, 5, 9, 0, 0, 135, 146, 3, 8, 4, 21, 136, 137, 10, 18,\n    0, 0, 137, 138, 5, 24, 0, 0, 138, 146, 3, 8, 4, 19, 139, 140, 10, 17, 0, 0, 140, 141,\n    5, 25, 0, 0, 141, 146, 3, 8, 4, 18, 142, 143, 10, 19, 0, 0, 143, 144, 5, 9, 0, 0, 144,\n    146, 3, 12, 6, 0, 145, 127, 1, 0, 0, 0, 145, 130, 1, 0, 0, 0, 145, 133, 1, 0, 0, 0, 145,\n    136, 1, 0, 0, 0, 145, 139, 1, 0, 0, 0, 145, 142, 1, 0, 0, 0, 146, 149, 1, 0, 0, 0, 147,\n    145, 1, 0, 0, 0, 147, 148, 1, 0, 0, 0, 148, 9, 1, 0, 0, 0, 149, 147, 1, 0, 0, 0, 150, 151,\n    7, 0, 0, 0, 151, 11, 1, 0, 0, 0, 152, 154, 7, 1, 0, 0, 153, 152, 1, 0, 0, 0, 153, 154, 1,\n    0, 0, 0, 154, 156, 1, 0, 0, 0, 155, 157, 5, 26, 0, 0, 156, 155, 1, 0, 0, 0, 157, 158, 1,\n    0, 0, 0, 158, 156, 1, 0, 0, 0, 158, 159, 1, 0, 0, 0, 159, 166, 1, 0, 0, 0, 160, 162, 5,\n    27, 0, 0, 161, 163, 5, 26, 0, 0, 162, 161, 1, 0, 0, 0, 163, 164, 1, 0, 0, 0, 164, 162,\n    1, 0, 0, 0, 164, 165, 1, 0, 0, 0, 165, 167, 1, 0, 0, 0, 166, 160, 1, 0, 0, 0, 166, 167,\n    1, 0, 0, 0, 167, 13, 1, 0, 0, 0, 168, 169, 7, 2, 0, 0, 169, 15, 1, 0, 0, 0, 9, 22, 52, 125,\n    145, 147, 153, 158, 164, 166\n];\nLatexMathParser.vocabulary = new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.Vocabulary(LatexMathParser.literalNames, LatexMathParser.symbolicNames, []);\nLatexMathParser.decisionsToDFA = LatexMathParser._ATN.decisionToState.map((ds, index) => new antlr4ng__WEBPACK_IMPORTED_MODULE_0__.DFA(ds, index));\nclass ProgramContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    statement() {\n        return this.getRuleContext(0, StatementContext);\n    }\n    EOF() {\n        return this.getToken(LatexMathParser.EOF, 0);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_program;\n    }\n    enterRule(listener) {\n        if (listener.enterProgram) {\n            listener.enterProgram(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitProgram) {\n            listener.exitProgram(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitProgram) {\n            return visitor.visitProgram(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass StatementContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    differential() {\n        return this.getRuleContext(0, DifferentialContext);\n    }\n    assignment() {\n        return this.getRuleContext(0, AssignmentContext);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_statement;\n    }\n    enterRule(listener) {\n        if (listener.enterStatement) {\n            listener.enterStatement(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitStatement) {\n            listener.exitStatement(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitStatement) {\n            return visitor.visitStatement(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass DifferentialContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    name(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(NameContext);\n        }\n        return this.getRuleContext(i, NameContext);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_differential;\n    }\n    enterRule(listener) {\n        if (listener.enterDifferential) {\n            listener.enterDifferential(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitDifferential) {\n            listener.exitDifferential(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitDifferential) {\n            return visitor.visitDifferential(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass AssignmentContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_assignment;\n    }\n    copyFrom(ctx) {\n        super.copyFrom(ctx);\n    }\n}\nclass FunctionContext extends AssignmentContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterFunction) {\n            listener.enterFunction(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitFunction) {\n            listener.exitFunction(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitFunction) {\n            return visitor.visitFunction(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass FunctionSubscriptDigitContext extends AssignmentContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    DIGIT() {\n        return this.getToken(LatexMathParser.DIGIT, 0);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterFunctionSubscriptDigit) {\n            listener.enterFunctionSubscriptDigit(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitFunctionSubscriptDigit) {\n            listener.exitFunctionSubscriptDigit(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitFunctionSubscriptDigit) {\n            return visitor.visitFunctionSubscriptDigit(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass FunctionSubscriptContext extends AssignmentContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterFunctionSubscript) {\n            listener.enterFunctionSubscript(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitFunctionSubscript) {\n            listener.exitFunctionSubscript(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitFunctionSubscript) {\n            return visitor.visitFunctionSubscript(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass ExpressionContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_expression;\n    }\n    copyFrom(ctx) {\n        super.copyFrom(ctx);\n    }\n}\nclass FractionDigitsContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    DIGIT(i) {\n        if (i === undefined) {\n            return this.getTokens(LatexMathParser.DIGIT);\n        }\n        else {\n            return this.getToken(LatexMathParser.DIGIT, i);\n        }\n    }\n    enterRule(listener) {\n        if (listener.enterFractionDigits) {\n            listener.enterFractionDigits(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitFractionDigits) {\n            listener.exitFractionDigits(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitFractionDigits) {\n            return visitor.visitFractionDigits(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass MultiplicationContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterMultiplication) {\n            listener.enterMultiplication(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitMultiplication) {\n            listener.exitMultiplication(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitMultiplication) {\n            return visitor.visitMultiplication(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass AdditionContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    PLUS() {\n        return this.getToken(LatexMathParser.PLUS, 0);\n    }\n    enterRule(listener) {\n        if (listener.enterAddition) {\n            listener.enterAddition(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitAddition) {\n            listener.exitAddition(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitAddition) {\n            return visitor.visitAddition(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass VariableContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    enterRule(listener) {\n        if (listener.enterVariable) {\n            listener.enterVariable(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitVariable) {\n            listener.exitVariable(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitVariable) {\n            return visitor.visitVariable(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass NegationContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    MINUS() {\n        return this.getToken(LatexMathParser.MINUS, 0);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterNegation) {\n            listener.enterNegation(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitNegation) {\n            listener.exitNegation(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitNegation) {\n            return visitor.visitNegation(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass ConstantContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    reserved() {\n        return this.getRuleContext(0, ReservedContext);\n    }\n    enterRule(listener) {\n        if (listener.enterConstant) {\n            listener.enterConstant(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitConstant) {\n            listener.exitConstant(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitConstant) {\n            return visitor.visitConstant(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SecantContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterSecant) {\n            listener.enterSecant(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSecant) {\n            listener.exitSecant(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSecant) {\n            return visitor.visitSecant(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SubscriptContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterSubscript) {\n            listener.enterSubscript(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSubscript) {\n            listener.exitSubscript(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSubscript) {\n            return visitor.visitSubscript(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass FractionContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterFraction) {\n            listener.enterFraction(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitFraction) {\n            listener.exitFraction(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitFraction) {\n            return visitor.visitFraction(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SineContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterSine) {\n            listener.enterSine(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSine) {\n            listener.exitSine(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSine) {\n            return visitor.visitSine(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass TangentContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterTangent) {\n            listener.enterTangent(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitTangent) {\n            listener.exitTangent(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitTangent) {\n            return visitor.visitTangent(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass ParenthesisContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterParenthesis) {\n            listener.enterParenthesis(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitParenthesis) {\n            listener.exitParenthesis(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitParenthesis) {\n            return visitor.visitParenthesis(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SubtractionContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    MINUS() {\n        return this.getToken(LatexMathParser.MINUS, 0);\n    }\n    enterRule(listener) {\n        if (listener.enterSubtraction) {\n            listener.enterSubtraction(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSubtraction) {\n            listener.exitSubtraction(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSubtraction) {\n            return visitor.visitSubtraction(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass NumberContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    decimal() {\n        return this.getRuleContext(0, DecimalContext);\n    }\n    enterRule(listener) {\n        if (listener.enterNumber) {\n            listener.enterNumber(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitNumber) {\n            listener.exitNumber(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitNumber) {\n            return visitor.visitNumber(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass MultiplicationDigitContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    decimal() {\n        return this.getRuleContext(0, DecimalContext);\n    }\n    enterRule(listener) {\n        if (listener.enterMultiplicationDigit) {\n            listener.enterMultiplicationDigit(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitMultiplicationDigit) {\n            listener.exitMultiplicationDigit(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitMultiplicationDigit) {\n            return visitor.visitMultiplicationDigit(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SquareRootContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterSquareRoot) {\n            listener.enterSquareRoot(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSquareRoot) {\n            listener.exitSquareRoot(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSquareRoot) {\n            return visitor.visitSquareRoot(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass LogarithmContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterLogarithm) {\n            listener.enterLogarithm(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitLogarithm) {\n            listener.exitLogarithm(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitLogarithm) {\n            return visitor.visitLogarithm(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass DivisionContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterDivision) {\n            listener.enterDivision(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitDivision) {\n            listener.exitDivision(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitDivision) {\n            return visitor.visitDivision(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass CotangentContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterCotangent) {\n            listener.enterCotangent(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitCotangent) {\n            listener.exitCotangent(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitCotangent) {\n            return visitor.visitCotangent(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass SubscriptDigitContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    name() {\n        return this.getRuleContext(0, NameContext);\n    }\n    DIGIT() {\n        return this.getToken(LatexMathParser.DIGIT, 0);\n    }\n    enterRule(listener) {\n        if (listener.enterSubscriptDigit) {\n            listener.enterSubscriptDigit(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitSubscriptDigit) {\n            listener.exitSubscriptDigit(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitSubscriptDigit) {\n            return visitor.visitSubscriptDigit(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass PowerContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression(i) {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterPower) {\n            listener.enterPower(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitPower) {\n            listener.exitPower(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitPower) {\n            return visitor.visitPower(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass CosineContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterCosine) {\n            listener.enterCosine(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitCosine) {\n            listener.exitCosine(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitCosine) {\n            return visitor.visitCosine(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass CosecantContext extends ExpressionContext {\n    constructor(ctx) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    expression() {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    enterRule(listener) {\n        if (listener.enterCosecant) {\n            listener.enterCosecant(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitCosecant) {\n            listener.exitCosecant(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitCosecant) {\n            return visitor.visitCosecant(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass ReservedContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_reserved;\n    }\n    enterRule(listener) {\n        if (listener.enterReserved) {\n            listener.enterReserved(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitReserved) {\n            listener.exitReserved(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitReserved) {\n            return visitor.visitReserved(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass DecimalContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    DIGIT(i) {\n        if (i === undefined) {\n            return this.getTokens(LatexMathParser.DIGIT);\n        }\n        else {\n            return this.getToken(LatexMathParser.DIGIT, i);\n        }\n    }\n    DOT() {\n        return this.getToken(LatexMathParser.DOT, 0);\n    }\n    PLUS() {\n        return this.getToken(LatexMathParser.PLUS, 0);\n    }\n    MINUS() {\n        return this.getToken(LatexMathParser.MINUS, 0);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_decimal;\n    }\n    enterRule(listener) {\n        if (listener.enterDecimal) {\n            listener.enterDecimal(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitDecimal) {\n            listener.exitDecimal(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitDecimal) {\n            return visitor.visitDecimal(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nclass NameContext extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.ParserRuleContext {\n    constructor(parent, invokingState) {\n        super(parent, invokingState);\n    }\n    ID() {\n        return this.getToken(LatexMathParser.ID, 0);\n    }\n    SPECIAL() {\n        return this.getToken(LatexMathParser.SPECIAL, 0);\n    }\n    get ruleIndex() {\n        return LatexMathParser.RULE_name;\n    }\n    enterRule(listener) {\n        if (listener.enterName) {\n            listener.enterName(this);\n        }\n    }\n    exitRule(listener) {\n        if (listener.exitName) {\n            listener.exitName(this);\n        }\n    }\n    accept(visitor) {\n        if (visitor.visitName) {\n            return visitor.visitName(this);\n        }\n        else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\n//# sourceURL=webpack://Modellus/./Parser/LatexMathParser.ts?");

/***/ }),

/***/ "./Parser/LatexMathVisitor.ts":
/*!************************************!*\
  !*** ./Parser/LatexMathVisitor.ts ***!
  \************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LatexMathVisitor: () => (/* binding */ LatexMathVisitor)\n/* harmony export */ });\n/* harmony import */ var antlr4ng__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! antlr4ng */ \"./node_modules/antlr4ng/dist/index.mjs\");\n// Generated from /Users/jpdv/Documents/Modellus/CoreTypeScript/Parser/LatexMath.g4 by ANTLR 4.13.1\n\n/**\n * This interface defines a complete generic visitor for a parse tree produced\n * by `LatexMathParser`.\n *\n * @param <Result> The return type of the visit operation. Use `void` for\n * operations with no return type.\n */\nclass LatexMathVisitor extends antlr4ng__WEBPACK_IMPORTED_MODULE_0__.AbstractParseTreeVisitor {\n}\n\n\n//# sourceURL=webpack://Modellus/./Parser/LatexMathVisitor.ts?");

/***/ }),

/***/ "./index.ts":
/*!******************!*\
  !*** ./index.ts ***!
  \******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Branch: () => (/* reexport safe */ _CalculationEngine_Branch__WEBPACK_IMPORTED_MODULE_0__.Branch),\n/* harmony export */   Engine: () => (/* reexport safe */ _CalculationEngine_Engine__WEBPACK_IMPORTED_MODULE_1__.Engine),\n/* harmony export */   Expression: () => (/* reexport safe */ _CalculationEngine_Expression__WEBPACK_IMPORTED_MODULE_2__.Expression),\n/* harmony export */   Parser: () => (/* reexport safe */ _CalculationEngine_Parser__WEBPACK_IMPORTED_MODULE_3__.Parser),\n/* harmony export */   System: () => (/* reexport safe */ _CalculationEngine_System__WEBPACK_IMPORTED_MODULE_4__.System),\n/* harmony export */   Term: () => (/* reexport safe */ _CalculationEngine_Term__WEBPACK_IMPORTED_MODULE_5__.Term),\n/* harmony export */   TermType: () => (/* reexport safe */ _CalculationEngine_TermType__WEBPACK_IMPORTED_MODULE_6__.TermType),\n/* harmony export */   Visitor: () => (/* reexport safe */ _CalculationEngine_Visitor__WEBPACK_IMPORTED_MODULE_7__.Visitor)\n/* harmony export */ });\n/* harmony import */ var _CalculationEngine_Branch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CalculationEngine/Branch */ \"./CalculationEngine/Branch.ts\");\n/* harmony import */ var _CalculationEngine_Engine__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CalculationEngine/Engine */ \"./CalculationEngine/Engine.ts\");\n/* harmony import */ var _CalculationEngine_Expression__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./CalculationEngine/Expression */ \"./CalculationEngine/Expression.ts\");\n/* harmony import */ var _CalculationEngine_Parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./CalculationEngine/Parser */ \"./CalculationEngine/Parser.ts\");\n/* harmony import */ var _CalculationEngine_System__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./CalculationEngine/System */ \"./CalculationEngine/System.ts\");\n/* harmony import */ var _CalculationEngine_Term__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./CalculationEngine/Term */ \"./CalculationEngine/Term.ts\");\n/* harmony import */ var _CalculationEngine_TermType__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./CalculationEngine/TermType */ \"./CalculationEngine/TermType.ts\");\n/* harmony import */ var _CalculationEngine_Visitor__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./CalculationEngine/Visitor */ \"./CalculationEngine/Visitor.ts\");\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack://Modellus/./index.ts?");

/***/ }),

/***/ "./node_modules/antlr4ng/dist/index.mjs":
/*!**********************************************!*\
  !*** ./node_modules/antlr4ng/dist/index.mjs ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ATN: () => (/* binding */ ATN),\n/* harmony export */   ATNConfig: () => (/* binding */ ATNConfig),\n/* harmony export */   ATNConfigSet: () => (/* binding */ ATNConfigSet),\n/* harmony export */   ATNDeserializer: () => (/* binding */ ATNDeserializer),\n/* harmony export */   ATNSerializer: () => (/* binding */ ATNSerializer),\n/* harmony export */   ATNSimulator: () => (/* binding */ ATNSimulator),\n/* harmony export */   ATNState: () => (/* binding */ ATNState),\n/* harmony export */   AbstractParseTreeVisitor: () => (/* binding */ AbstractParseTreeVisitor),\n/* harmony export */   AbstractPredicateTransition: () => (/* binding */ AbstractPredicateTransition),\n/* harmony export */   ActionTransition: () => (/* binding */ ActionTransition),\n/* harmony export */   ArrayPredictionContext: () => (/* binding */ ArrayPredictionContext),\n/* harmony export */   AtomTransition: () => (/* binding */ AtomTransition),\n/* harmony export */   BailErrorStrategy: () => (/* binding */ BailErrorStrategy),\n/* harmony export */   BaseErrorListener: () => (/* binding */ BaseErrorListener),\n/* harmony export */   BasicBlockStartState: () => (/* binding */ BasicBlockStartState),\n/* harmony export */   BasicState: () => (/* binding */ BasicState),\n/* harmony export */   BitSet: () => (/* binding */ BitSet),\n/* harmony export */   BlockEndState: () => (/* binding */ BlockEndState),\n/* harmony export */   BlockStartState: () => (/* binding */ BlockStartState),\n/* harmony export */   BufferedTokenStream: () => (/* binding */ BufferedTokenStream),\n/* harmony export */   CannotInvokeStartRuleError: () => (/* binding */ CannotInvokeStartRuleError),\n/* harmony export */   CharStream: () => (/* binding */ CharStream),\n/* harmony export */   CharStreamImpl: () => (/* binding */ CharStreamImpl),\n/* harmony export */   Chunk: () => (/* binding */ Chunk),\n/* harmony export */   CodePointTransitions: () => (/* binding */ CodePointTransitions),\n/* harmony export */   CommonToken: () => (/* binding */ CommonToken),\n/* harmony export */   CommonTokenFactory: () => (/* binding */ CommonTokenFactory),\n/* harmony export */   CommonTokenStream: () => (/* binding */ CommonTokenStream),\n/* harmony export */   ConsoleErrorListener: () => (/* binding */ ConsoleErrorListener),\n/* harmony export */   DFA: () => (/* binding */ DFA),\n/* harmony export */   DFASerializer: () => (/* binding */ DFASerializer),\n/* harmony export */   DFAState: () => (/* binding */ DFAState),\n/* harmony export */   DecisionInfo: () => (/* binding */ DecisionInfo),\n/* harmony export */   DecisionState: () => (/* binding */ DecisionState),\n/* harmony export */   DefaultErrorStrategy: () => (/* binding */ DefaultErrorStrategy),\n/* harmony export */   DiagnosticErrorListener: () => (/* binding */ DiagnosticErrorListener),\n/* harmony export */   DoubleDict: () => (/* binding */ DoubleDict),\n/* harmony export */   EmptyPredictionContext: () => (/* binding */ EmptyPredictionContext),\n/* harmony export */   EpsilonTransition: () => (/* binding */ EpsilonTransition),\n/* harmony export */   ErrorNode: () => (/* binding */ ErrorNode),\n/* harmony export */   FailedPredicateException: () => (/* binding */ FailedPredicateException),\n/* harmony export */   HashMap: () => (/* binding */ HashMap),\n/* harmony export */   HashSet: () => (/* binding */ HashSet),\n/* harmony export */   InputMismatchException: () => (/* binding */ InputMismatchException),\n/* harmony export */   IntStream: () => (/* binding */ IntStream),\n/* harmony export */   InterpreterDataReader: () => (/* binding */ InterpreterDataReader),\n/* harmony export */   InterpreterRuleContext: () => (/* binding */ InterpreterRuleContext),\n/* harmony export */   Interval: () => (/* binding */ Interval),\n/* harmony export */   IntervalSet: () => (/* binding */ IntervalSet),\n/* harmony export */   LL1Analyzer: () => (/* binding */ LL1Analyzer),\n/* harmony export */   Lexer: () => (/* binding */ Lexer),\n/* harmony export */   LexerATNConfig: () => (/* binding */ LexerATNConfig),\n/* harmony export */   LexerATNSimulator: () => (/* binding */ LexerATNSimulator),\n/* harmony export */   LexerActionExecutor: () => (/* binding */ LexerActionExecutor),\n/* harmony export */   LexerActionType: () => (/* binding */ LexerActionType),\n/* harmony export */   LexerChannelAction: () => (/* binding */ LexerChannelAction),\n/* harmony export */   LexerCustomAction: () => (/* binding */ LexerCustomAction),\n/* harmony export */   LexerDFASerializer: () => (/* binding */ LexerDFASerializer),\n/* harmony export */   LexerIndexedCustomAction: () => (/* binding */ LexerIndexedCustomAction),\n/* harmony export */   LexerInterpreter: () => (/* binding */ LexerInterpreter),\n/* harmony export */   LexerModeAction: () => (/* binding */ LexerModeAction),\n/* harmony export */   LexerMoreAction: () => (/* binding */ LexerMoreAction),\n/* harmony export */   LexerNoViableAltException: () => (/* binding */ LexerNoViableAltException),\n/* harmony export */   LexerPopModeAction: () => (/* binding */ LexerPopModeAction),\n/* harmony export */   LexerPushModeAction: () => (/* binding */ LexerPushModeAction),\n/* harmony export */   LexerSkipAction: () => (/* binding */ LexerSkipAction),\n/* harmony export */   LexerTypeAction: () => (/* binding */ LexerTypeAction),\n/* harmony export */   ListTokenSource: () => (/* binding */ ListTokenSource),\n/* harmony export */   LoopEndState: () => (/* binding */ LoopEndState),\n/* harmony export */   MurmurHash: () => (/* binding */ MurmurHash),\n/* harmony export */   NoViableAltException: () => (/* binding */ NoViableAltException),\n/* harmony export */   NotSetTransition: () => (/* binding */ NotSetTransition),\n/* harmony export */   OrderedATNConfigSet: () => (/* binding */ OrderedATNConfigSet),\n/* harmony export */   OrderedHashMap: () => (/* binding */ OrderedHashMap),\n/* harmony export */   OrderedHashSet: () => (/* binding */ OrderedHashSet),\n/* harmony export */   ParseCancellationException: () => (/* binding */ ParseCancellationException),\n/* harmony export */   ParseInfo: () => (/* binding */ ParseInfo),\n/* harmony export */   ParseTreeMatch: () => (/* binding */ ParseTreeMatch),\n/* harmony export */   ParseTreePattern: () => (/* binding */ ParseTreePattern),\n/* harmony export */   ParseTreePatternMatcher: () => (/* binding */ ParseTreePatternMatcher),\n/* harmony export */   ParseTreeWalker: () => (/* binding */ ParseTreeWalker),\n/* harmony export */   Parser: () => (/* binding */ Parser),\n/* harmony export */   ParserATNSimulator: () => (/* binding */ ParserATNSimulator),\n/* harmony export */   ParserInterpreter: () => (/* binding */ ParserInterpreter),\n/* harmony export */   ParserRuleContext: () => (/* binding */ ParserRuleContext),\n/* harmony export */   PlusBlockStartState: () => (/* binding */ PlusBlockStartState),\n/* harmony export */   PlusLoopbackState: () => (/* binding */ PlusLoopbackState),\n/* harmony export */   PrecedencePredicateTransition: () => (/* binding */ PrecedencePredicateTransition),\n/* harmony export */   PredPrediction: () => (/* binding */ PredPrediction),\n/* harmony export */   PredicateTransition: () => (/* binding */ PredicateTransition),\n/* harmony export */   PredictionContext: () => (/* binding */ PredictionContext),\n/* harmony export */   PredictionContextCache: () => (/* binding */ PredictionContextCache),\n/* harmony export */   PredictionMode: () => (/* binding */ PredictionMode),\n/* harmony export */   ProfilingATNSimulator: () => (/* binding */ ProfilingATNSimulator),\n/* harmony export */   ProxyErrorListener: () => (/* binding */ ProxyErrorListener),\n/* harmony export */   RangeTransition: () => (/* binding */ RangeTransition),\n/* harmony export */   RecognitionException: () => (/* binding */ RecognitionException),\n/* harmony export */   Recognizer: () => (/* binding */ Recognizer),\n/* harmony export */   RuleStartState: () => (/* binding */ RuleStartState),\n/* harmony export */   RuleStopState: () => (/* binding */ RuleStopState),\n/* harmony export */   RuleTagToken: () => (/* binding */ RuleTagToken),\n/* harmony export */   RuleTransition: () => (/* binding */ RuleTransition),\n/* harmony export */   RuntimeMetaData: () => (/* binding */ RuntimeMetaData),\n/* harmony export */   SemanticContext: () => (/* binding */ SemanticContext),\n/* harmony export */   SetTransition: () => (/* binding */ SetTransition),\n/* harmony export */   SingletonPredictionContext: () => (/* binding */ SingletonPredictionContext),\n/* harmony export */   StarBlockStartState: () => (/* binding */ StarBlockStartState),\n/* harmony export */   StarLoopEntryState: () => (/* binding */ StarLoopEntryState),\n/* harmony export */   StarLoopbackState: () => (/* binding */ StarLoopbackState),\n/* harmony export */   StartRuleDoesNotConsumeFullPatternError: () => (/* binding */ StartRuleDoesNotConsumeFullPatternError),\n/* harmony export */   TagChunk: () => (/* binding */ TagChunk),\n/* harmony export */   TerminalNode: () => (/* binding */ TerminalNode),\n/* harmony export */   TextChunk: () => (/* binding */ TextChunk),\n/* harmony export */   Token: () => (/* binding */ Token),\n/* harmony export */   TokenStreamRewriter: () => (/* binding */ TokenStreamRewriter),\n/* harmony export */   TokenTagToken: () => (/* binding */ TokenTagToken),\n/* harmony export */   TokensStartState: () => (/* binding */ TokensStartState),\n/* harmony export */   TraceListener: () => (/* binding */ TraceListener),\n/* harmony export */   Transition: () => (/* binding */ Transition),\n/* harmony export */   Trees: () => (/* binding */ Trees),\n/* harmony export */   UnbufferedTokenStream: () => (/* binding */ UnbufferedTokenStream),\n/* harmony export */   Vocabulary: () => (/* binding */ Vocabulary),\n/* harmony export */   WildcardTransition: () => (/* binding */ WildcardTransition),\n/* harmony export */   XPath: () => (/* binding */ XPath),\n/* harmony export */   XPathElement: () => (/* binding */ XPathElement),\n/* harmony export */   XPathLexer: () => (/* binding */ XPathLexer),\n/* harmony export */   XPathLexerErrorListener: () => (/* binding */ XPathLexerErrorListener),\n/* harmony export */   XPathRuleAnywhereElement: () => (/* binding */ XPathRuleAnywhereElement),\n/* harmony export */   XPathRuleElement: () => (/* binding */ XPathRuleElement),\n/* harmony export */   XPathTokenAnywhereElement: () => (/* binding */ XPathTokenAnywhereElement),\n/* harmony export */   XPathTokenElement: () => (/* binding */ XPathTokenElement),\n/* harmony export */   XPathWildcardAnywhereElement: () => (/* binding */ XPathWildcardAnywhereElement),\n/* harmony export */   XPathWildcardElement: () => (/* binding */ XPathWildcardElement),\n/* harmony export */   arrayToString: () => (/* binding */ arrayToString),\n/* harmony export */   combineCommonParents: () => (/* binding */ combineCommonParents),\n/* harmony export */   equalArrays: () => (/* binding */ equalArrays),\n/* harmony export */   equalNumberArrays: () => (/* binding */ equalNumberArrays),\n/* harmony export */   escapeWhitespace: () => (/* binding */ escapeWhitespace),\n/* harmony export */   getCachedPredictionContext: () => (/* binding */ getCachedPredictionContext),\n/* harmony export */   isComparable: () => (/* binding */ isComparable),\n/* harmony export */   isToken: () => (/* binding */ isToken),\n/* harmony export */   isWritableToken: () => (/* binding */ isWritableToken),\n/* harmony export */   merge: () => (/* binding */ merge),\n/* harmony export */   mergeRoot: () => (/* binding */ mergeRoot),\n/* harmony export */   mergeSingletons: () => (/* binding */ mergeSingletons),\n/* harmony export */   predictionContextFromRuleContext: () => (/* binding */ predictionContextFromRuleContext)\n/* harmony export */ });\nvar __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/IntStream.ts\nvar IntStream;\n((IntStream2) => {\n  IntStream2.EOF = -1;\n  IntStream2.UNKNOWN_SOURCE_NAME = \"<unknown>\";\n})(IntStream || (IntStream = {}));\n\n// src/Token.ts\nvar Token;\n((Token2) => {\n  Token2.INVALID_TYPE = 0;\n  Token2.EPSILON = -2;\n  Token2.MIN_USER_TOKEN_TYPE = 1;\n  Token2.EOF = IntStream.EOF;\n  Token2.DEFAULT_CHANNEL = 0;\n  Token2.HIDDEN_CHANNEL = 1;\n  Token2.MIN_USER_CHANNEL_VALUE = 2;\n})(Token || (Token = {}));\nvar isToken = /* @__PURE__ */ __name((candidate) => {\n  const token = candidate;\n  return token.tokenSource !== void 0 && token.channel !== void 0;\n}, \"isToken\");\n\n// src/misc/Interval.ts\nvar Interval = class _Interval {\n  static {\n    __name(this, \"Interval\");\n  }\n  static INVALID_INTERVAL = new _Interval(-1, -2);\n  static INTERVAL_POOL_MAX_VALUE = 1e3;\n  start;\n  stop;\n  static #cache = [];\n  #cachedHashCode;\n  constructor(start, stop) {\n    this.start = start;\n    this.stop = stop;\n    this.#cachedHashCode = Math.imul(651 + start, 31) + stop;\n  }\n  /**\n   * Creates a new interval from the given values.\n   *\n   * Interval objects are used readonly so share all with the\n   * same single value a==b up to some max size. Use an array as a perfect hash.\n   * Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new\n   * Interval object with a..a in it.  On Java.g4, 218623 IntervalSets\n   * have a..a (set with 1 element).\n   *\n   * @param a The start of the interval.\n   * @param b The end of the interval (inclusive).\n   *\n   * @returns A cached or new interval.\n   */\n  static of(a, b) {\n    if (a !== b || a < 0 || a > _Interval.INTERVAL_POOL_MAX_VALUE) {\n      return new _Interval(a, b);\n    }\n    if (!_Interval.#cache[a]) {\n      _Interval.#cache[a] = new _Interval(a, a);\n    }\n    return _Interval.#cache[a];\n  }\n  equals(o) {\n    return this.start === o.start && this.stop === o.stop;\n  }\n  hashCode() {\n    return this.#cachedHashCode;\n  }\n  /** Does this start completely before other? Disjoint */\n  startsBeforeDisjoint(other) {\n    return this.start < other.start && this.stop < other.start;\n  }\n  /** Does this start at or before other? Nondisjoint */\n  startsBeforeNonDisjoint(other) {\n    return this.start <= other.start && this.stop >= other.start;\n  }\n  /** Does this.start start after other.stop? May or may not be disjoint */\n  startsAfter(other) {\n    return this.start > other.start;\n  }\n  /** Does this start completely after other? Disjoint */\n  startsAfterDisjoint(other) {\n    return this.start > other.stop;\n  }\n  /** Does this start after other? NonDisjoint */\n  startsAfterNonDisjoint(other) {\n    return this.start > other.start && this.start <= other.stop;\n  }\n  /** Are both ranges disjoint? I.e., no overlap? */\n  disjoint(other) {\n    return this.startsBeforeDisjoint(other) || this.startsAfterDisjoint(other);\n  }\n  /** Are two intervals adjacent such as 0..41 and 42..42? */\n  adjacent(other) {\n    return this.start === other.stop + 1 || this.stop === other.start - 1;\n  }\n  properlyContains(other) {\n    return other.start >= this.start && other.stop <= this.stop;\n  }\n  /** Return the interval computed from combining this and other */\n  union(other) {\n    return _Interval.of(Math.min(this.start, other.start), Math.max(this.stop, other.stop));\n  }\n  /** Return the interval in common between this and o */\n  intersection(other) {\n    return _Interval.of(Math.max(this.start, other.start), Math.min(this.stop, other.stop));\n  }\n  /**\n   * Return the interval with elements from this not in other;\n   *  other must not be totally enclosed (properly contained)\n   *  within this, which would result in two disjoint intervals\n   *  instead of the single one returned by this method.\n   */\n  differenceNotProperlyContained(other) {\n    let diff = null;\n    if (other.startsBeforeNonDisjoint(this)) {\n      diff = _Interval.of(Math.max(this.start, other.stop + 1), this.stop);\n    } else if (other.startsAfterNonDisjoint(this)) {\n      diff = _Interval.of(this.start, other.start - 1);\n    }\n    return diff;\n  }\n  toString() {\n    if (this.start === this.stop) {\n      return this.start.toString();\n    } else {\n      return this.start.toString() + \"..\" + this.stop.toString();\n    }\n  }\n  get length() {\n    if (this.stop < this.start) {\n      return 0;\n    }\n    return this.stop - this.start + 1;\n  }\n};\n\n// src/Vocabulary.ts\nvar Vocabulary = class _Vocabulary {\n  static {\n    __name(this, \"Vocabulary\");\n  }\n  static EMPTY_NAMES = [];\n  /**\n   * Gets an empty {@link Vocabulary} instance.\n   *\n   *\n   * No literal or symbol names are assigned to token types, so\n   * {@link #getDisplayName(int)} returns the numeric value for all tokens\n   * except {@link Token#EOF}.\n   */\n  static EMPTY_VOCABULARY = new _Vocabulary(_Vocabulary.EMPTY_NAMES, _Vocabulary.EMPTY_NAMES, _Vocabulary.EMPTY_NAMES);\n  maxTokenType;\n  literalNames;\n  symbolicNames;\n  displayNames;\n  /**\n   * Constructs a new instance of {@link Vocabulary} from the specified\n   * literal, symbolic, and display token names.\n   *\n   * @param literalNames The literal names assigned to tokens, or `null`\n   * if no literal names are assigned.\n   * @param symbolicNames The symbolic names assigned to tokens, or\n   * `null` if no symbolic names are assigned.\n   * @param displayNames The display names assigned to tokens, or `null`\n   * to use the values in `literalNames` and `symbolicNames` as\n   * the source of display names, as described in\n   * {@link #getDisplayName(int)}.\n   */\n  constructor(literalNames, symbolicNames, displayNames) {\n    this.literalNames = literalNames ?? _Vocabulary.EMPTY_NAMES;\n    this.symbolicNames = symbolicNames ?? _Vocabulary.EMPTY_NAMES;\n    this.displayNames = displayNames ?? _Vocabulary.EMPTY_NAMES;\n    this.maxTokenType = Math.max(this.displayNames.length, Math.max(\n      this.literalNames.length,\n      this.symbolicNames.length\n    )) - 1;\n  }\n  /**\n   * Returns a {@link Vocabulary} instance from the specified set of token\n   * names. This method acts as a compatibility layer for the single\n   * `tokenNames` array generated by previous releases of ANTLR.\n   *\n   * The resulting vocabulary instance returns `null` for\n   * {@link getLiteralName getLiteralName(int)} and {@link getSymbolicName getSymbolicName(int)}, and the\n   * value from `tokenNames` for the display names.\n   *\n   * @param tokenNames The token names, or `null` if no token names are\n   * available.\n   * @returns A {@link Vocabulary} instance which uses `tokenNames` for\n   * the display names of tokens.\n   */\n  static fromTokenNames(tokenNames) {\n    if (tokenNames == null || tokenNames.length === 0) {\n      return _Vocabulary.EMPTY_VOCABULARY;\n    }\n    const literalNames = [...tokenNames];\n    const symbolicNames = [...tokenNames];\n    for (let i = 0; i < tokenNames.length; i++) {\n      const tokenName = tokenNames[i];\n      if (tokenName == null) {\n        continue;\n      }\n      if (tokenName?.length > 0) {\n        const firstChar = tokenName.charAt(0);\n        if (firstChar === \"'\") {\n          symbolicNames[i] = null;\n          continue;\n        } else if (firstChar.toUpperCase() === firstChar) {\n          literalNames[i] = null;\n          continue;\n        }\n      }\n      literalNames[i] = null;\n      symbolicNames[i] = null;\n    }\n    return new _Vocabulary(literalNames, symbolicNames, tokenNames);\n  }\n  getMaxTokenType() {\n    return this.maxTokenType;\n  }\n  getLiteralName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.literalNames.length) {\n      return this.literalNames[tokenType];\n    }\n    return null;\n  }\n  getSymbolicName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.symbolicNames.length) {\n      return this.symbolicNames[tokenType];\n    }\n    if (tokenType === Token.EOF) {\n      return \"EOF\";\n    }\n    return null;\n  }\n  getDisplayName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.displayNames.length) {\n      const displayName = this.displayNames[tokenType];\n      if (displayName != null) {\n        return displayName;\n      }\n    }\n    const literalName = this.getLiteralName(tokenType);\n    if (literalName != null) {\n      return literalName;\n    }\n    const symbolicName = this.getSymbolicName(tokenType);\n    if (symbolicName != null) {\n      return symbolicName;\n    }\n    return `${tokenType}`;\n  }\n  getLiteralNames() {\n    return this.literalNames;\n  }\n  getSymbolicNames() {\n    return this.symbolicNames;\n  }\n  getDisplayNames() {\n    return this.displayNames;\n  }\n};\n\n// src/utils/MurmurHash.ts\nvar c1 = 3432918353;\nvar c2 = 461845907;\nvar r1 = 15;\nvar r2 = 13;\nvar m = 5;\nvar n = 3864292196;\nvar MurmurHash = class _MurmurHash {\n  static {\n    __name(this, \"MurmurHash\");\n  }\n  static #defaultSeed = 701;\n  constructor() {\n  }\n  /**\n   * Initialize the hash using the specified {@code seed}.\n   *\n   * @param seed the seed\n   *\n   * @returns the intermediate hash value\n   */\n  static initialize(seed = _MurmurHash.#defaultSeed) {\n    return seed;\n  }\n  static updateFromComparable(hash, value) {\n    return this.update(hash, value?.hashCode() ?? 0);\n  }\n  /**\n   * Update the intermediate hash value for the next input {@code value}.\n   *\n   * @param hash The intermediate hash value.\n   * @param value the value to add to the current hash.\n   *\n   * @returns the updated intermediate hash value\n   */\n  static update(hash, value) {\n    value = Math.imul(value, c1);\n    value = value << r1 | value >>> 32 - r1;\n    value = Math.imul(value, c2);\n    hash = hash ^ value;\n    hash = hash << r2 | hash >>> 32 - r2;\n    hash = Math.imul(hash, m) + n;\n    return hash;\n  }\n  /**\n   * Apply the final computation steps to the intermediate value {@code hash}\n   * to form the final result of the MurmurHash 3 hash function.\n   *\n   * @param hash The intermediate hash value.\n   * @param entryCount The number of values added to the hash.\n   *\n   * @returns the final hash result\n   */\n  static finish(hash, entryCount) {\n    hash ^= entryCount * 4;\n    hash ^= hash >>> 16;\n    hash = Math.imul(hash, 2246822507);\n    hash ^= hash >>> 13;\n    hash = Math.imul(hash, 3266489909);\n    hash ^= hash >>> 16;\n    return hash;\n  }\n  /**\n   * An all-in-one convenience method to compute a hash for a single value.\n   *\n   * @param value The value to hash.\n   * @param seed The seed for the hash value.\n   *\n   * @returns The computed hash.\n   */\n  static hashCode(value, seed) {\n    return _MurmurHash.finish(_MurmurHash.update(seed ?? _MurmurHash.#defaultSeed, value), 1);\n  }\n};\n\n// src/misc/IntervalSet.ts\nvar IntervalSet = class _IntervalSet {\n  static {\n    __name(this, \"IntervalSet\");\n  }\n  /** The list of sorted, disjoint intervals. */\n  #intervals = [];\n  #cachedHashCode;\n  constructor(set) {\n    if (set) {\n      this.addSet(set);\n    }\n  }\n  /** Create a set with all ints within range [a..b] (inclusive) */\n  static of(a, b) {\n    const s = new _IntervalSet();\n    s.addRange(a, b);\n    return s;\n  }\n  /** Combine all sets in the array and return the union of them */\n  static or(sets) {\n    const result = new _IntervalSet();\n    for (const set of sets) {\n      result.addSet(set);\n    }\n    return result;\n  }\n  [Symbol.iterator]() {\n    return this.#intervals[Symbol.iterator]();\n  }\n  get(index) {\n    return this.#intervals[index];\n  }\n  /**\n   * Returns the minimum value contained in the set if not isNil().\n   *\n   * @returns the minimum value contained in the set.\n   */\n  get minElement() {\n    if (this.#intervals.length === 0) {\n      return Token.INVALID_TYPE;\n    }\n    return this.#intervals[0].start;\n  }\n  /**\n   * Returns the maximum value contained in the set if not isNil().\n   *\n   * @returns the maximum value contained in the set.\n   */\n  get maxElement() {\n    if (this.#intervals.length === 0) {\n      return Token.INVALID_TYPE;\n    }\n    return this.#intervals[this.#intervals.length - 1].stop;\n  }\n  clear() {\n    this.#cachedHashCode = void 0;\n    this.#intervals = [];\n  }\n  /**\n   * Add a single element to the set.  An isolated element is stored\n   *  as a range el..el.\n   */\n  addOne(v) {\n    this.addInterval(new Interval(v, v));\n  }\n  /**\n   * Add interval; i.e., add all integers from a to b to set.\n   *  If b < a, do nothing.\n   *  Keep list in sorted order (by left range value).\n   *  If overlap, combine ranges. For example,\n   *  If this is {1..5, 10..20}, adding 6..7 yields\n   *  {1..5, 6..7, 10..20}. Adding 4..8 yields {1..8, 10..20}.\n   */\n  addRange(l, h) {\n    this.addInterval(new Interval(l, h));\n  }\n  addInterval(addition) {\n    this.#cachedHashCode = void 0;\n    if (this.#intervals.length === 0) {\n      this.#intervals.push(addition);\n    } else {\n      for (let pos = 0; pos < this.#intervals.length; pos++) {\n        const existing = this.#intervals[pos];\n        if (addition.equals(existing)) {\n          return;\n        }\n        if (addition.adjacent(existing) || !addition.disjoint(existing)) {\n          const bigger = addition.union(existing);\n          this.#intervals[pos] = bigger;\n          for (let sub = pos + 1; sub < this.#intervals.length; ) {\n            const next = this.#intervals[sub];\n            if (!bigger.adjacent(next) && bigger.disjoint(next)) {\n              break;\n            }\n            this.#intervals.splice(sub, 1);\n            this.#intervals[pos] = bigger.union(next);\n          }\n          return;\n        }\n        if (addition.startsBeforeDisjoint(existing)) {\n          this.#intervals.splice(pos, 0, addition);\n          return;\n        }\n      }\n      this.#intervals.push(addition);\n    }\n  }\n  addSet(other) {\n    other.#intervals.forEach((toAdd) => {\n      return this.addInterval(toAdd);\n    }, this);\n    return this;\n  }\n  complementWithVocabulary(vocabulary) {\n    const result = new _IntervalSet();\n    if (!vocabulary) {\n      return result;\n    }\n    if (vocabulary.length === 0) {\n      return result;\n    }\n    result.addSet(vocabulary);\n    return result.subtract(this);\n  }\n  complement(minElement, maxElement) {\n    const result = new _IntervalSet();\n    result.addInterval(new Interval(minElement, maxElement));\n    return result.subtract(this);\n  }\n  /** combine all sets in the array returned the or'd value */\n  or(sets) {\n    const result = new _IntervalSet();\n    result.addSet(this);\n    sets.forEach((set) => {\n      return result.addSet(set);\n    });\n    return result;\n  }\n  and(other) {\n    if (other.length === 0) {\n      return new _IntervalSet();\n    }\n    const myIntervals = this.#intervals;\n    const theirIntervals = other.#intervals;\n    let intersection;\n    const mySize = myIntervals.length;\n    const theirSize = theirIntervals.length;\n    let i = 0;\n    let j = 0;\n    while (i < mySize && j < theirSize) {\n      const mine = myIntervals[i];\n      const theirs = theirIntervals[j];\n      if (mine.startsBeforeDisjoint(theirs)) {\n        i++;\n      } else if (theirs.startsBeforeDisjoint(mine)) {\n        j++;\n      } else if (mine.properlyContains(theirs)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        j++;\n      } else if (theirs.properlyContains(mine)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        i++;\n      } else if (!mine.disjoint(theirs)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        if (mine.startsAfterNonDisjoint(theirs)) {\n          j++;\n        } else if (theirs.startsAfterNonDisjoint(mine)) {\n          i++;\n        }\n      }\n    }\n    if (!intersection) {\n      return new _IntervalSet();\n    }\n    return intersection;\n  }\n  /**\n   * Compute the set difference between two interval sets. The specific\n   * operation is `left - right`. If either of the input sets is\n   * `null`, it is treated as though it was an empty set.\n   */\n  subtract(other) {\n    if (this.length === 0) {\n      return new _IntervalSet();\n    }\n    const result = new _IntervalSet(this);\n    if (other.length === 0) {\n      return result;\n    }\n    let resultI = 0;\n    let rightI = 0;\n    while (resultI < result.#intervals.length && rightI < other.#intervals.length) {\n      const resultInterval = result.#intervals[resultI];\n      const rightInterval = other.#intervals[rightI];\n      if (rightInterval.stop < resultInterval.start) {\n        rightI++;\n        continue;\n      }\n      if (rightInterval.start > resultInterval.stop) {\n        resultI++;\n        continue;\n      }\n      let beforeCurrent;\n      let afterCurrent;\n      if (rightInterval.start > resultInterval.start) {\n        beforeCurrent = new Interval(resultInterval.start, rightInterval.start - 1);\n      }\n      if (rightInterval.stop < resultInterval.stop) {\n        afterCurrent = new Interval(rightInterval.stop + 1, resultInterval.stop);\n      }\n      if (beforeCurrent) {\n        if (afterCurrent) {\n          result.#intervals[resultI] = beforeCurrent;\n          result.#intervals.splice(resultI + 1, 0, afterCurrent);\n          resultI++;\n          rightI++;\n        } else {\n          result.#intervals[resultI] = beforeCurrent;\n          resultI++;\n        }\n      } else {\n        if (afterCurrent) {\n          result.#intervals[resultI] = afterCurrent;\n          rightI++;\n        } else {\n          result.#intervals.splice(resultI, 1);\n        }\n      }\n    }\n    return result;\n  }\n  contains(el) {\n    const n2 = this.#intervals.length;\n    let l = 0;\n    let r = n2 - 1;\n    while (l <= r) {\n      const m2 = Math.floor((l + r) / 2);\n      const interval = this.#intervals[m2];\n      if (interval.stop < el) {\n        l = m2 + 1;\n      } else if (interval.start > el) {\n        r = m2 - 1;\n      } else {\n        return true;\n      }\n    }\n    return false;\n  }\n  removeRange(toRemove) {\n    this.#cachedHashCode = void 0;\n    if (toRemove.start === toRemove.stop) {\n      this.removeOne(toRemove.start);\n    } else if (this.#intervals !== null) {\n      let pos = 0;\n      for (const existing of this.#intervals) {\n        if (toRemove.stop <= existing.start) {\n          return;\n        } else if (toRemove.start > existing.start && toRemove.stop < existing.stop) {\n          this.#intervals[pos] = new Interval(existing.start, toRemove.start);\n          const x = new Interval(toRemove.stop, existing.stop);\n          this.#intervals.splice(pos, 0, x);\n          return;\n        } else if (toRemove.start <= existing.start && toRemove.stop >= existing.stop) {\n          this.#intervals.splice(pos, 1);\n          pos = pos - 1;\n        } else if (toRemove.start < existing.stop) {\n          this.#intervals[pos] = new Interval(existing.start, toRemove.start);\n        } else if (toRemove.stop < existing.stop) {\n          this.#intervals[pos] = new Interval(toRemove.stop, existing.stop);\n        }\n        pos += 1;\n      }\n    }\n  }\n  removeOne(value) {\n    this.#cachedHashCode = void 0;\n    for (let i = 0; i < this.#intervals.length; i++) {\n      const existing = this.#intervals[i];\n      if (value < existing.start) {\n        return;\n      } else if (value === existing.start && value === existing.stop) {\n        this.#intervals.splice(i, 1);\n        return;\n      } else if (value === existing.start) {\n        this.#intervals[i] = new Interval(existing.start + 1, existing.stop);\n        return;\n      } else if (value === existing.stop) {\n        this.#intervals[i] = new Interval(existing.start, existing.stop);\n        return;\n      } else if (value < existing.stop) {\n        const replace = new Interval(existing.start, value);\n        this.#intervals[i] = new Interval(value + 1, existing.stop);\n        this.#intervals.splice(i, 0, replace);\n        return;\n      }\n    }\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const interval of this.#intervals) {\n        hash = MurmurHash.update(hash, interval.start);\n        hash = MurmurHash.update(hash, interval.stop);\n      }\n      this.#cachedHashCode = MurmurHash.finish(hash, this.#intervals.length * 2);\n    }\n    return this.#cachedHashCode;\n  }\n  /**\n   * Are two IntervalSets equal? Because all intervals are sorted and disjoint, equals is a simple linear walk over\n   * both lists to make sure they are the same. Interval.equals() is used by the List.equals() method to check\n   * the ranges.\n   */\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.#intervals.length !== other.#intervals.length) {\n      return false;\n    }\n    for (let i = 0; i < this.#intervals.length; i++) {\n      if (!this.#intervals[i].equals(other.#intervals[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  toString(elementsAreChar) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else if (elementsAreChar) {\n          result += \"'\" + String.fromCodePoint(start) + \"'\";\n        } else {\n          result += start;\n        }\n      } else {\n        if (elementsAreChar) {\n          result += \"'\" + String.fromCodePoint(start) + \"'..'\" + String.fromCodePoint(stop) + \"'\";\n        } else {\n          result += start + \"..\" + stop;\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toStringWithVocabulary(vocabulary) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else {\n          result += this.elementName(vocabulary, start);\n        }\n      } else {\n        for (let i2 = start; i2 <= stop; ++i2) {\n          if (i2 > start) {\n            result += \", \";\n          }\n          result += this.elementName(vocabulary, i2);\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toStringWithRuleNames(ruleNames) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    const vocabulary = Vocabulary.fromTokenNames(ruleNames);\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else {\n          result += this.elementName(vocabulary, start);\n        }\n      } else {\n        for (let i2 = start; i2 <= stop; ++i2) {\n          if (i2 > start) {\n            result += \", \";\n          }\n          result += this.elementName(vocabulary, i2);\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toArray() {\n    const data = [];\n    for (const interval of this.#intervals) {\n      for (let j = interval.start; j <= interval.stop; j++) {\n        data.push(j);\n      }\n    }\n    return data;\n  }\n  /** @returns the number of elements in this set. */\n  get length() {\n    let result = 0;\n    for (const interval of this.#intervals) {\n      result += interval.length;\n    }\n    return result;\n  }\n  elementName(vocabulary, token) {\n    if (token === Token.EOF) {\n      return \"<EOF>\";\n    }\n    if (token === Token.EPSILON) {\n      return \"<EPSILON>\";\n    }\n    return vocabulary.getDisplayName(token);\n  }\n};\n\n// src/atn/Transition.ts\nvar Transition = class {\n  static {\n    __name(this, \"Transition\");\n  }\n  static INVALID = 0;\n  static EPSILON = 1;\n  static RANGE = 2;\n  static RULE = 3;\n  static PREDICATE = 4;\n  // e.g., {isType(input.LT(1))}\n  static ATOM = 5;\n  static ACTION = 6;\n  static SET = 7;\n  // ~(A|B) or ~atom, wildcard, which convert to next\n  static NOT_SET = 8;\n  static WILDCARD = 9;\n  static PRECEDENCE = 10;\n  /** The target of this transition. */\n  target;\n  constructor(target) {\n    this.target = target;\n  }\n  /**\n   * Determines if the transition is an \"epsilon\" transition.\n   *\n   * The default implementation returns `false`.\n   *\n   * @returns `true` if traversing this transition in the ATN does not\n   * consume an input symbol; otherwise, `false` if traversing this\n   * transition consumes (matches) an input symbol.\n   */\n  get isEpsilon() {\n    return false;\n  }\n  get label() {\n    return null;\n  }\n};\n\n// src/atn/SetTransition.ts\nvar SetTransition = class extends Transition {\n  static {\n    __name(this, \"SetTransition\");\n  }\n  set;\n  constructor(target, set) {\n    super(target);\n    if (set) {\n      this.set = set;\n    } else {\n      this.set = IntervalSet.of(Token.INVALID_TYPE, Token.INVALID_TYPE);\n    }\n  }\n  get transitionType() {\n    return Transition.SET;\n  }\n  get label() {\n    return this.set;\n  }\n  matches(symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return this.set.contains(symbol);\n  }\n  toString() {\n    return this.set.toString();\n  }\n};\n\n// src/atn/NotSetTransition.ts\nvar NotSetTransition = class extends SetTransition {\n  static {\n    __name(this, \"NotSetTransition\");\n  }\n  get transitionType() {\n    return Transition.NOT_SET;\n  }\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= minVocabSymbol && symbol <= maxVocabSymbol && !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n  }\n  toString() {\n    return \"~\" + super.toString();\n  }\n};\n\n// src/atn/PredictionContext.ts\nvar PredictionContext = class _PredictionContext {\n  static {\n    __name(this, \"PredictionContext\");\n  }\n  /**\n   * Represents `$` in an array in full context mode, when `$`\n   * doesn't mean wildcard: `$ + x = [$,x]`. Here,\n   * `$` = {@link EMPTY_RETURN_STATE}.\n   */\n  static EMPTY_RETURN_STATE = 2147483647;\n  // TODO: Temporarily here. Should be moved to EmptyPredictionContext. It's initialized in that context class.\n  static EMPTY;\n  static traceATNSimulator = false;\n  #cachedHashCode;\n  constructor(cachedHashCode) {\n    this.#cachedHashCode = cachedHashCode;\n  }\n  static calculateEmptyHashCode() {\n    let hash = MurmurHash.initialize(31);\n    hash = MurmurHash.finish(hash, 0);\n    return hash;\n  }\n  static calculateHashCodeSingle(parent, returnState) {\n    let hash = MurmurHash.initialize(31);\n    hash = MurmurHash.updateFromComparable(hash, parent);\n    hash = MurmurHash.update(hash, returnState);\n    hash = MurmurHash.finish(hash, 2);\n    return hash;\n  }\n  static calculateHashCodeList(parents, returnStates) {\n    let hash = MurmurHash.initialize(31);\n    for (const parent of parents) {\n      hash = MurmurHash.updateFromComparable(hash, parent);\n    }\n    for (const returnState of returnStates) {\n      hash = MurmurHash.update(hash, returnState);\n    }\n    hash = MurmurHash.finish(hash, 2 * parents.length);\n    return hash;\n  }\n  isEmpty() {\n    return false;\n  }\n  hasEmptyPath() {\n    return this.getReturnState(this.length - 1) === _PredictionContext.EMPTY_RETURN_STATE;\n  }\n  hashCode() {\n    return this.#cachedHashCode;\n  }\n  toString(_recog) {\n    return \"\";\n  }\n};\n\n// src/utils/helpers.ts\nvar isComparable = /* @__PURE__ */ __name((candidate) => {\n  return typeof candidate.equals === \"function\";\n}, \"isComparable\");\nvar valueToString = /* @__PURE__ */ __name((v) => {\n  return v === null ? \"null\" : v;\n}, \"valueToString\");\nvar arrayToString = /* @__PURE__ */ __name((value) => {\n  return Array.isArray(value) ? \"[\" + value.map(valueToString).join(\", \") + \"]\" : \"null\";\n}, \"arrayToString\");\nvar equalArrays = /* @__PURE__ */ __name((a, b) => {\n  if (a === b) {\n    return true;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0; i < a.length; i++) {\n    const left = a[i];\n    const right = b[i];\n    if (left === right) {\n      continue;\n    }\n    if (!left || !left.equals(right)) {\n      return false;\n    }\n  }\n  return true;\n}, \"equalArrays\");\nvar equalNumberArrays = /* @__PURE__ */ __name((a, b) => {\n  if (a === b) {\n    return true;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n  return true;\n}, \"equalNumberArrays\");\nvar escapeWhitespace = /* @__PURE__ */ __name((s, escapeSpaces = false) => {\n  s = s.replace(/\\t/g, \"\\\\t\").replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\");\n  if (escapeSpaces) {\n    s = s.replace(/ /g, \"\\xB7\");\n  }\n  return s;\n}, \"escapeWhitespace\");\n\n// src/atn/ArrayPredictionContext.ts\nvar ArrayPredictionContext = class _ArrayPredictionContext extends PredictionContext {\n  static {\n    __name(this, \"ArrayPredictionContext\");\n  }\n  parents = [];\n  returnStates = [];\n  constructor(parents, returnStates) {\n    super(PredictionContext.calculateHashCodeList(parents, returnStates));\n    this.parents = parents;\n    this.returnStates = returnStates;\n    return this;\n  }\n  isEmpty() {\n    return this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n  }\n  get length() {\n    return this.returnStates.length;\n  }\n  getParent(index) {\n    return this.parents[index];\n  }\n  getReturnState(index) {\n    return this.returnStates[index];\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _ArrayPredictionContext) || this.hashCode() !== other.hashCode()) {\n      return false;\n    }\n    return equalNumberArrays(this.returnStates, other.returnStates) && equalArrays(this.parents, other.parents);\n  }\n  toString() {\n    if (this.isEmpty()) {\n      return \"[]\";\n    }\n    const entries = [];\n    for (let i = 0; i < this.returnStates.length; i++) {\n      if (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n        entries.push(\"$\");\n        continue;\n      }\n      entries.push(this.returnStates[i].toString());\n      if (this.parents[i]) {\n        entries.push(this.parents[i].toString());\n      } else {\n        entries.push(\"null\");\n      }\n    }\n    return `[${entries.join(\", \")}]`;\n  }\n};\n\n// src/atn/SingletonPredictionContext.ts\nvar SingletonPredictionContext = class _SingletonPredictionContext extends PredictionContext {\n  static {\n    __name(this, \"SingletonPredictionContext\");\n  }\n  parent;\n  returnState;\n  constructor(parent, returnState) {\n    super(\n      parent ? PredictionContext.calculateHashCodeSingle(parent, returnState) : PredictionContext.calculateEmptyHashCode()\n    );\n    this.parent = parent ?? null;\n    this.returnState = returnState;\n  }\n  static create(parent, returnState) {\n    if (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n      return PredictionContext.EMPTY;\n    } else {\n      return new _SingletonPredictionContext(parent, returnState);\n    }\n  }\n  getParent(_index) {\n    return this.parent;\n  }\n  getReturnState(_index) {\n    return this.returnState;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _SingletonPredictionContext)) {\n      return false;\n    }\n    if (this.hashCode() !== other.hashCode()) {\n      return false;\n    }\n    if (this.returnState !== other.returnState) {\n      return false;\n    }\n    if (this.parent == null) {\n      return other.parent == null;\n    }\n    return this.parent.equals(other.parent);\n  }\n  toString() {\n    const up = this.parent === null ? \"\" : this.parent.toString();\n    if (up.length === 0) {\n      if (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n        return \"$\";\n      }\n      return \"\" + this.returnState;\n    } else {\n      return \"\" + this.returnState + \" \" + up;\n    }\n  }\n  get length() {\n    return 1;\n  }\n};\n\n// src/atn/EmptyPredictionContext.ts\nvar EmptyPredictionContext = class _EmptyPredictionContext extends SingletonPredictionContext {\n  static {\n    __name(this, \"EmptyPredictionContext\");\n  }\n  /**\n   * Represents `$` in local context prediction, which means wildcard.\n   * `*+x = *`.\n   */\n  static instance = new _EmptyPredictionContext();\n  constructor() {\n    super(void 0, PredictionContext.EMPTY_RETURN_STATE);\n  }\n  isEmpty() {\n    return true;\n  }\n  getParent() {\n    return null;\n  }\n  getReturnState() {\n    return this.returnState;\n  }\n  equals(other) {\n    return this === other;\n  }\n  toString() {\n    return \"$\";\n  }\n  static {\n    PredictionContext.EMPTY = new _EmptyPredictionContext();\n  }\n};\n\n// src/tree/TerminalNode.ts\nvar TerminalNode = class {\n  static {\n    __name(this, \"TerminalNode\");\n  }\n  parent = null;\n  symbol;\n  constructor(symbol) {\n    this.symbol = symbol;\n  }\n  getChild(_i) {\n    return null;\n  }\n  getSymbol() {\n    return this.symbol;\n  }\n  getPayload() {\n    return this.symbol;\n  }\n  getSourceInterval() {\n    if (this.symbol === null) {\n      return Interval.INVALID_INTERVAL;\n    }\n    const tokenIndex = this.symbol.tokenIndex;\n    return new Interval(tokenIndex, tokenIndex);\n  }\n  getChildCount() {\n    return 0;\n  }\n  accept(visitor) {\n    return visitor.visitTerminal(this);\n  }\n  getText() {\n    return this.symbol?.text ?? \"\";\n  }\n  toString() {\n    if (this.symbol?.type === Token.EOF) {\n      return \"<EOF>\";\n    } else {\n      return this.symbol?.text ?? \"\";\n    }\n  }\n  toStringTree() {\n    return this.toString();\n  }\n};\n\n// src/tree/ErrorNode.ts\nvar ErrorNode = class extends TerminalNode {\n  static {\n    __name(this, \"ErrorNode\");\n  }\n  accept(visitor) {\n    return visitor.visitErrorNode(this);\n  }\n};\n\n// src/CommonToken.ts\nvar CommonToken = class _CommonToken {\n  static {\n    __name(this, \"CommonToken\");\n  }\n  /**\n   * An empty tuple which is used as the default value of\n   * {@link source} for tokens that do not have a source.\n   */\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  static EMPTY_SOURCE = [null, null];\n  /**\n   * These properties share a field to reduce the memory footprint of\n   * {@link CommonToken}. Tokens created by a {@link CommonTokenFactory} from\n   * the same source and input stream share a reference to the same\n   * {@link Pair} containing these values.\n   */\n  source;\n  tokenIndex;\n  start;\n  stop;\n  /**\n   * This is the backing field for {@link #getType} and {@link #setType}.\n   */\n  type;\n  /**\n   * The (one-based) line number on which the 1st character of this token was.\n   */\n  line;\n  /**\n   * The zero-based index of the first character position in its line.\n   */\n  column;\n  /**\n   * The token's channel.\n   */\n  channel;\n  /**\n   * This is the backing field for {@link getText} when the token text is\n   * explicitly set in the constructor or via {@link setText}.\n   */\n  #text;\n  constructor(details) {\n    this.type = details.type;\n    this.source = details.source;\n    this.tokenIndex = details.tokenIndex ?? -1;\n    this.line = details.line ?? 0;\n    this.column = details.column ?? -1;\n    this.channel = details.channel ?? Token.DEFAULT_CHANNEL;\n    this.start = details.start ?? 0;\n    this.stop = details.stop ?? 0;\n    this.#text = details.text;\n    if (details.source[0] !== null) {\n      this.line = details.source[0].line;\n      this.column = details.source[0].column;\n    }\n  }\n  /**\n   * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n   *\n   * If `token` is also a {@link CommonToken} instance, the newly\n   * constructed token will share a reference to the {@link #text} field and\n   * the {@link Pair} stored in {@link source}. Otherwise, {@link text} will\n   * be assigned the result of calling {@link getText}, and {@link source}\n   * will be constructed from the result of {@link Token.getTokenSource} and\n   * {@link Token#getInputStream}.\n   *\n   * @param token The token to copy.\n   */\n  static fromToken(token) {\n    const source = [token.tokenSource, token.inputStream];\n    return new _CommonToken({\n      type: token.type,\n      line: token.line,\n      tokenIndex: token.tokenIndex,\n      column: token.column,\n      channel: token.channel,\n      start: token.start,\n      stop: token.stop,\n      text: token.text,\n      source\n    });\n  }\n  /**\n   * Constructs a new {@link CommonToken} with the specified token type and text.\n   *\n   * @param type The token type.\n   * @param text The text of the token.\n   */\n  static fromType(type, text) {\n    return new _CommonToken({ type, text, source: _CommonToken.EMPTY_SOURCE });\n  }\n  static fromSource(source, type, channel, start, stop) {\n    return new _CommonToken({ type, channel, start, stop, source });\n  }\n  get tokenSource() {\n    return this.source[0];\n  }\n  get inputStream() {\n    return this.source[1];\n  }\n  set inputStream(input) {\n    this.source[1] = input;\n  }\n  /**\n   * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n   *\n   * If `oldToken` is also a {@link CommonToken} instance, the newly\n   * constructed token will share a reference to the {@link text} field and\n   * the {@link Pair} stored in {@link source}. Otherwise, {@link text} will\n   * be assigned the result of calling {@link getText}, and {@link source}\n   * will be constructed from the result of {@link Token.getTokenSource} and\n   * {@link Token.getInputStream}.\n   */\n  clone() {\n    const t = new _CommonToken({\n      source: this.source,\n      type: this.type,\n      channel: this.channel,\n      start: this.start,\n      stop: this.stop,\n      tokenIndex: this.tokenIndex,\n      line: this.line,\n      column: this.column,\n      text: this.#text\n    });\n    return t;\n  }\n  toString(recognizer) {\n    let channelStr = \"\";\n    if (this.channel > 0) {\n      channelStr = \",channel=\" + this.channel;\n    }\n    let text = this.text;\n    if (text) {\n      text = text.replace(/\\n/g, \"\\\\n\");\n      text = text.replace(/\\r/g, \"\\\\r\");\n      text = text.replace(/\\t/g, \"\\\\t\");\n    } else {\n      text = \"<no text>\";\n    }\n    let typeString = String(this.type);\n    if (recognizer) {\n      typeString = recognizer.vocabulary.getDisplayName(this.type) ?? \"<unknown>\";\n    }\n    return \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" + text + \"',<\" + typeString + \">\" + channelStr + \",\" + this.line + \":\" + this.column + \"]\";\n  }\n  get text() {\n    if (this.#text !== void 0) {\n      return this.#text;\n    }\n    const input = this.inputStream;\n    if (!input) {\n      return void 0;\n    }\n    const n2 = input.size;\n    if (this.start < n2 && this.stop < n2) {\n      return input.getTextFromRange(this.start, this.stop);\n    }\n    return \"<EOF>\";\n  }\n  set text(text) {\n    this.#text = text;\n  }\n  // WritableToken implementation\n  setText(text) {\n    this.#text = text;\n  }\n  setType(ttype) {\n    this.type = ttype;\n  }\n  setLine(line) {\n    this.line = line;\n  }\n  setCharPositionInLine(pos) {\n    this.column = pos;\n  }\n  setChannel(channel) {\n    this.channel = channel;\n  }\n  setTokenIndex(index) {\n    this.tokenIndex = index;\n  }\n};\n\n// src/tree/Trees.ts\nvar Trees = class _Trees {\n  static {\n    __name(this, \"Trees\");\n  }\n  /**\n   * Print out a whole tree in LISP form. {@link getNodeText} is used on the\n   * node payloads to get the text for the nodes.  Detect\n   * parse trees and extract data appropriately.\n   */\n  static toStringTree(tree, ruleNames, recog) {\n    ruleNames = ruleNames ?? null;\n    if (recog) {\n      ruleNames = recog.ruleNames;\n    }\n    let s = _Trees.getNodeText(tree, ruleNames);\n    s = escapeWhitespace(s, false);\n    const c = tree.getChildCount();\n    if (c === 0) {\n      return s;\n    }\n    let res = \"(\" + s + \" \";\n    if (c > 0) {\n      s = _Trees.toStringTree(tree.getChild(0), ruleNames);\n      res = res.concat(s);\n    }\n    for (let i = 1; i < c; i++) {\n      s = _Trees.toStringTree(tree.getChild(i), ruleNames);\n      res = res.concat(\" \" + s);\n    }\n    res = res.concat(\")\");\n    return res;\n  }\n  static getNodeText(t, ruleNames, recog) {\n    ruleNames = ruleNames ?? null;\n    if (recog) {\n      ruleNames = recog.ruleNames;\n    }\n    if (ruleNames !== null) {\n      if (t instanceof ParserRuleContext) {\n        const context = t.ruleContext;\n        const altNumber = context.getAltNumber();\n        if (altNumber !== 0) {\n          return ruleNames[t.ruleIndex] + \":\" + altNumber;\n        }\n        return ruleNames[t.ruleIndex];\n      } else if (t instanceof ErrorNode) {\n        return t.toString();\n      } else if (t instanceof TerminalNode) {\n        return t.symbol.text;\n      }\n    }\n    const payload = t.getPayload();\n    if (isToken(payload)) {\n      return payload.text;\n    }\n    return String(t.getPayload());\n  }\n  /**\n   * Return ordered list of all children of this node\n   */\n  static getChildren(t) {\n    const list = [];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      list.push(t.getChild(i));\n    }\n    return list;\n  }\n  /**\n   * Return a list of all ancestors of this node.  The first node of\n   * list is the root and the last is the parent of this node.\n   */\n  static getAncestors(t) {\n    if (t.parent === null) {\n      return [];\n    }\n    let ancestors = [];\n    let p = t.parent;\n    while (p !== null) {\n      ancestors = [p].concat(ancestors);\n      p = p.parent;\n    }\n    return ancestors;\n  }\n  /**\n   * Return true if t is u's parent or a node on path to root from u.\n   */\n  static isAncestorOf(t, u) {\n    if (t === null || u === null || t.parent === null) {\n      return false;\n    }\n    let p = u.parent;\n    while (p !== null) {\n      if (t === p) {\n        return true;\n      }\n      p = p.parent;\n    }\n    return false;\n  }\n  static findAllTokenNodes(t, ttype) {\n    return _Trees.findAllNodes(t, ttype, true);\n  }\n  static findAllRuleNodes(t, ruleIndex) {\n    return _Trees.findAllNodes(t, ruleIndex, false);\n  }\n  static findAllNodes(t, index, findTokens) {\n    const nodes = [];\n    _Trees.doFindAllNodes(t, index, findTokens, nodes);\n    return nodes;\n  }\n  static descendants(t) {\n    let nodes = [t];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      nodes = nodes.concat(_Trees.descendants(t.getChild(i)));\n    }\n    return nodes;\n  }\n  /**\n   * Find smallest subtree of t enclosing range startTokenIndex..stopTokenIndex\n   * inclusively using post order traversal. Recursive depth-first-search.\n   */\n  static getRootOfSubtreeEnclosingRegion(t, startTokenIndex, stopTokenIndex) {\n    const n2 = t.getChildCount();\n    for (let i = 0; i < n2; i++) {\n      const child = t.getChild(i);\n      const r = this.getRootOfSubtreeEnclosingRegion(child, startTokenIndex, stopTokenIndex);\n      if (r !== null) {\n        return r;\n      }\n    }\n    if (t instanceof ParserRuleContext) {\n      if (startTokenIndex >= t.start.tokenIndex && // is range fully contained in t?\n      (t.stop === null || stopTokenIndex <= t.stop.tokenIndex)) {\n        return t;\n      }\n    }\n    return null;\n  }\n  /**\n   * Replace any subtree siblings of root that are completely to left\n   * or right of lookahead range with a CommonToken(Token.INVALID_TYPE,\"...\")\n   * node. The source interval for t is not altered to suit smaller range!\n   *\n   * WARNING: destructive to t.\n   */\n  static stripChildrenOutOfRange(t, root, startIndex, stopIndex) {\n    if (t === null) {\n      return;\n    }\n    for (let i = 0; i < t.getChildCount(); i++) {\n      const child = t.getChild(i);\n      const range = child.getSourceInterval();\n      if (t instanceof ParserRuleContext && (range.stop < startIndex || range.start > stopIndex)) {\n        if (this.isAncestorOf(child, root)) {\n          const abbrev = CommonToken.fromType(Token.INVALID_TYPE, \"...\");\n          t.children[i] = new TerminalNode(abbrev);\n        }\n      }\n    }\n  }\n  static doFindAllNodes(t, index, findTokens, nodes) {\n    if (findTokens && t instanceof TerminalNode) {\n      if (t.symbol?.type === index) {\n        nodes.push(t);\n      }\n    } else if (!findTokens && t instanceof ParserRuleContext) {\n      if (t.ruleIndex === index) {\n        nodes.push(t);\n      }\n    }\n    for (let i = 0; i < t.getChildCount(); i++) {\n      _Trees.doFindAllNodes(t.getChild(i), index, findTokens, nodes);\n    }\n  }\n};\n\n// src/ParserRuleContext.ts\nvar ParserRuleContext = class _ParserRuleContext {\n  static {\n    __name(this, \"ParserRuleContext\");\n  }\n  static empty = new _ParserRuleContext(null);\n  start = null;\n  stop = null;\n  children = [];\n  /**\n   * What state invoked the rule associated with this context?\n   *  The \"return address\" is the followState of invokingState\n   *  If parent is null, this should be -1 this context object represents\n   *  the start rule.\n   */\n  invokingState;\n  #parent;\n  /**\n   * A rule context is a record of a single rule invocation. It knows\n   * which context invoked it, if any. If there is no parent context, then\n   * naturally the invoking state is not valid.  The parent link\n   * provides a chain upwards from the current rule invocation to the root\n   * of the invocation tree, forming a stack. We actually carry no\n   * information about the rule associated with this context (except\n   * when parsing). We keep only the state number of the invoking state from\n   * the ATN submachine that invoked this. Contrast this with the s\n   * pointer inside ParserRuleContext that tracks the current state\n   * being \"executed\" for the current rule.\n   *\n   * The parent contexts are useful for computing lookahead sets and\n   * getting error information.\n   *\n   * These objects are used during parsing and prediction.\n   * For the special case of parsers, we use the subclass\n   * ParserRuleContext.\n   */\n  constructor(parent, invokingStateNumber = -1) {\n    this.#parent = parent;\n    this.invokingState = invokingStateNumber;\n  }\n  /** Copy a context */\n  copyFrom(ctx) {\n    this.#parent = ctx.#parent;\n    this.invokingState = ctx.invokingState;\n    this.children.slice(0, this.children.length);\n    this.start = ctx.start;\n    this.stop = ctx.stop;\n    if (ctx.children) {\n      ctx.children.forEach((child) => {\n        if (child instanceof ErrorNode) {\n          this.children.push(child);\n          child.parent = this;\n        }\n      });\n    }\n  }\n  // Double dispatch methods for listeners\n  enterRule(_listener) {\n  }\n  exitRule(_listener) {\n  }\n  addChild(child) {\n    this.children.push(child);\n    return child;\n  }\n  /**\n   * Used by enterOuterAlt to toss out a RuleContext previously added as\n   * we entered a rule. If we have label, we will need to remove\n   * generic ruleContext object.\n   */\n  removeLastChild() {\n    this.children.pop();\n  }\n  addTokenNode(token) {\n    const node = new TerminalNode(token);\n    this.children.push(node);\n    node.parent = this;\n    return node;\n  }\n  addErrorNode(errorNode) {\n    errorNode.parent = this;\n    this.children.push(errorNode);\n    return errorNode;\n  }\n  getChild(i, type) {\n    if (i < 0 || i >= this.children.length) {\n      return null;\n    }\n    if (!type) {\n      return this.children[i];\n    }\n    for (const child of this.children) {\n      if (child instanceof type) {\n        if (i === 0) {\n          return child;\n        } else {\n          i -= 1;\n        }\n      }\n    }\n    return null;\n  }\n  getToken(ttype, i) {\n    if (i < 0 || i >= this.children.length) {\n      return null;\n    }\n    for (const child of this.children) {\n      if (\"symbol\" in child) {\n        if (child.symbol?.type === ttype) {\n          if (i === 0) {\n            return child;\n          } else {\n            i -= 1;\n          }\n        }\n      }\n    }\n    return null;\n  }\n  getTokens(ttype) {\n    const tokens = [];\n    for (const child of this.children) {\n      if (\"symbol\" in child) {\n        if (child.symbol?.type === ttype) {\n          tokens.push(child);\n        }\n      }\n    }\n    return tokens;\n  }\n  // XXX: base the child type selection on the rule index, not the class.\n  getRuleContext(index, ctxType) {\n    return this.getChild(index, ctxType);\n  }\n  // XXX: base the child type selection on the rule index, not the class.\n  getRuleContexts(ctxType) {\n    const contexts = [];\n    for (const child of this.children) {\n      if (child instanceof ctxType) {\n        contexts.push(child);\n      }\n    }\n    return contexts;\n  }\n  getChildCount() {\n    return this.children.length;\n  }\n  getSourceInterval() {\n    if (this.start === null || this.stop === null) {\n      return Interval.INVALID_INTERVAL;\n    } else {\n      return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n    }\n  }\n  get parent() {\n    return this.#parent;\n  }\n  set parent(parent) {\n    this.#parent = parent;\n  }\n  depth() {\n    let n2 = 0;\n    let p = this;\n    while (p !== null) {\n      p = p.parent;\n      n2 += 1;\n    }\n    return n2;\n  }\n  /**\n   * A context is empty if there is no invoking state; meaning nobody call\n   * current context.\n   */\n  isEmpty() {\n    return this.invokingState === -1;\n  }\n  get ruleContext() {\n    return this;\n  }\n  get ruleIndex() {\n    return -1;\n  }\n  getPayload() {\n    return this;\n  }\n  getText() {\n    if (this.children.length === 0) {\n      return \"\";\n    }\n    return this.children.map((child) => {\n      return child.getText();\n    }).join(\"\");\n  }\n  /**\n   * For rule associated with this parse tree internal node, return\n   * the outer alternative number used to match the input. Default\n   * implementation does not compute nor store this alt num. Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   * to set it.\n   */\n  getAltNumber() {\n    return ATN.INVALID_ALT_NUMBER;\n  }\n  /**\n   * Set the outer alternative number for this context node. Default\n   * implementation does nothing to avoid backing field overhead for\n   * trees that don't need it.  Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   */\n  setAltNumber(_altNumber) {\n  }\n  accept(visitor) {\n    return visitor.visitChildren(this);\n  }\n  toStringTree(...args) {\n    if (args.length < 2) {\n      return Trees.toStringTree(this, null, args[0]);\n    }\n    return Trees.toStringTree(this, args[0], args[1]);\n  }\n  toString(ruleNames, stop) {\n    ruleNames = ruleNames ?? null;\n    stop = stop ?? null;\n    let p = this;\n    let s = \"[\";\n    while (p !== null && p !== stop) {\n      if (ruleNames === null) {\n        if (!p.isEmpty()) {\n          s += p.invokingState;\n        }\n      } else {\n        const ri = p.ruleIndex;\n        const ruleName = ri >= 0 && ri < ruleNames.length ? ruleNames[ri] : \"\" + ri;\n        s += ruleName;\n      }\n      if (p.parent !== null && (ruleNames !== null || !p.parent.isEmpty())) {\n        s += \" \";\n      }\n      p = p.parent;\n    }\n    s += \"]\";\n    return s;\n  }\n};\n\n// src/misc/ObjectEqualityComparator.ts\nvar ObjectEqualityComparator = class _ObjectEqualityComparator {\n  static {\n    __name(this, \"ObjectEqualityComparator\");\n  }\n  static instance = new _ObjectEqualityComparator();\n  hashCode(obj) {\n    if (obj == null) {\n      return 0;\n    }\n    return obj.hashCode();\n  }\n  equals(a, b) {\n    if (a == null) {\n      return b == null;\n    }\n    return a.equals(b);\n  }\n};\n\n// src/misc/DefaultEqualityComparator.ts\nvar DefaultEqualityComparator = class _DefaultEqualityComparator {\n  static {\n    __name(this, \"DefaultEqualityComparator\");\n  }\n  static instance = new _DefaultEqualityComparator();\n  hashCode(obj) {\n    if (obj == null) {\n      return 0;\n    }\n    return ObjectEqualityComparator.instance.hashCode(obj);\n  }\n  equals(a, b) {\n    if (a == null) {\n      return b == null;\n    }\n    if (typeof a === \"string\" || typeof a === \"number\") {\n      return a === b;\n    }\n    return ObjectEqualityComparator.instance.equals(a, b);\n  }\n};\n\n// src/misc/HashSet.ts\nvar HashSet = class _HashSet {\n  static {\n    __name(this, \"HashSet\");\n  }\n  static #defaultLoadFactor = 0.75;\n  static #initialCapacity = 16;\n  // must be power of 2\n  #comparator;\n  #buckets;\n  /** How many elements in set */\n  #itemCount = 0;\n  #threshold;\n  constructor(comparatorOrSet, initialCapacity = _HashSet.#initialCapacity) {\n    if (comparatorOrSet instanceof _HashSet) {\n      this.#comparator = comparatorOrSet.#comparator;\n      this.#buckets = comparatorOrSet.#buckets.slice(0);\n      for (let i = 0; i < this.#buckets.length; i++) {\n        const bucket = this.#buckets[i];\n        if (bucket) {\n          this.#buckets[i] = bucket.slice(0);\n        }\n      }\n      this.#itemCount = comparatorOrSet.#itemCount;\n      this.#threshold = comparatorOrSet.#threshold;\n    } else {\n      this.#comparator = comparatorOrSet ?? DefaultEqualityComparator.instance;\n      this.#buckets = this.createBuckets(initialCapacity);\n      this.#threshold = Math.floor(_HashSet.#initialCapacity * _HashSet.#defaultLoadFactor);\n    }\n  }\n  /**\n   * Add `o` to set if not there; return existing value if already\n   * there. This method performs the same operation as {@link #add} aside from\n   * the return value.\n   *\n   * @param o the object to add to the set.\n   *\n   * @returns An existing element that equals to `o` if already in set, otherwise `o`.\n   */\n  getOrAdd(o) {\n    if (this.#itemCount > this.#threshold) {\n      this.expand();\n    }\n    const b = this.getBucket(o);\n    let bucket = this.#buckets[b];\n    if (!bucket) {\n      bucket = [o];\n      this.#buckets[b] = bucket;\n      ++this.#itemCount;\n      return o;\n    }\n    for (const existing of bucket) {\n      if (this.#comparator.equals(existing, o)) {\n        return existing;\n      }\n    }\n    bucket.push(o);\n    ++this.#itemCount;\n    return o;\n  }\n  get(o) {\n    if (o == null) {\n      return o;\n    }\n    const b = this.getBucket(o);\n    const bucket = this.#buckets[b];\n    if (!bucket) {\n      return void 0;\n    }\n    for (const e of bucket) {\n      if (this.#comparator.equals(e, o)) {\n        return e;\n      }\n    }\n    return void 0;\n  }\n  /**\n   * Removes the specified element from this set if it is present.\n   *\n   * @param o object to be removed from this set, if present.\n   *\n   * @returns `true` if the set contained the specified element.\n   */\n  remove(o) {\n    if (o == null) {\n      return false;\n    }\n    const b = this.getBucket(o);\n    const bucket = this.#buckets[b];\n    if (!bucket) {\n      return false;\n    }\n    for (let i = 0; i < bucket.length; i++) {\n      const existing = bucket[i];\n      if (this.#comparator.equals(existing, o)) {\n        bucket.splice(i, 1);\n        --this.#itemCount;\n        return true;\n      }\n    }\n    return false;\n  }\n  hashCode() {\n    let hash = MurmurHash.initialize();\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        hash = MurmurHash.update(hash, this.#comparator.hashCode(o));\n      }\n    }\n    hash = MurmurHash.finish(hash, this.size);\n    return hash;\n  }\n  equals(o) {\n    if (o === this) {\n      return true;\n    }\n    if (!(o instanceof _HashSet)) {\n      return false;\n    }\n    if (o.size !== this.size) {\n      return false;\n    }\n    return this.containsAll(o);\n  }\n  add(t) {\n    const existing = this.getOrAdd(t);\n    return existing === t;\n  }\n  contains(o) {\n    return this.containsFast(o);\n  }\n  containsFast(obj) {\n    if (obj == null) {\n      return false;\n    }\n    return this.get(obj) !== void 0;\n  }\n  *[Symbol.iterator]() {\n    yield* this.toArray();\n  }\n  toArray() {\n    const a = new Array(this.size);\n    let i = 0;\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        a[i++] = o;\n      }\n    }\n    return a;\n  }\n  containsAll(collection) {\n    if (collection instanceof _HashSet) {\n      for (const bucket of collection.#buckets) {\n        if (bucket == null) {\n          continue;\n        }\n        for (const o of bucket) {\n          if (o == null) {\n            break;\n          }\n          if (!this.containsFast(o)) {\n            return false;\n          }\n        }\n      }\n    } else {\n      for (const o of collection) {\n        if (!this.containsFast(o)) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n  addAll(c) {\n    let changed = false;\n    for (const o of c) {\n      const existing = this.getOrAdd(o);\n      if (existing !== o) {\n        changed = true;\n      }\n    }\n    return changed;\n  }\n  clear() {\n    this.#buckets = this.createBuckets(_HashSet.#initialCapacity);\n    this.#itemCount = 0;\n    this.#threshold = Math.floor(_HashSet.#initialCapacity * _HashSet.#defaultLoadFactor);\n  }\n  toString() {\n    if (this.size === 0) {\n      return \"{}\";\n    }\n    let buf = \"{\";\n    let first = true;\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        if (first) {\n          first = false;\n        } else {\n          buf += \", \";\n        }\n        buf += o.toString();\n      }\n    }\n    buf += \"}\";\n    return buf;\n  }\n  toTableString() {\n    let buf = \"\";\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        buf += \"null\\n\";\n        continue;\n      }\n      buf += \"[\";\n      let first = true;\n      for (const o of bucket) {\n        if (first) {\n          first = false;\n        } else {\n          buf += \" \";\n        }\n        if (o == null) {\n          buf += \"_\";\n        } else {\n          buf += o.toString();\n        }\n      }\n      buf += \"]\\n\";\n    }\n    return buf;\n  }\n  getBucket(o) {\n    const hash = this.#comparator.hashCode(o);\n    const b = hash & this.#buckets.length - 1;\n    return b;\n  }\n  expand() {\n    const old = this.#buckets;\n    const newCapacity = this.#buckets.length * 2;\n    const newTable = this.createBuckets(newCapacity);\n    this.#buckets = newTable;\n    this.#threshold = Math.floor(newCapacity * _HashSet.#defaultLoadFactor);\n    for (const bucket of old) {\n      if (!bucket) {\n        continue;\n      }\n      for (const o of bucket) {\n        const b = this.getBucket(o);\n        let newBucket = this.#buckets[b];\n        if (!newBucket) {\n          newBucket = [];\n          this.#buckets[b] = newBucket;\n        }\n        newBucket.push(o);\n      }\n    }\n  }\n  get size() {\n    return this.#itemCount;\n  }\n  get isEmpty() {\n    return this.#itemCount === 0;\n  }\n  /**\n   * Return an array of `T[]` with length `capacity`.\n   *\n   * @param capacity the length of the array to return\n   * @returns the newly constructed array\n   */\n  createBuckets(capacity) {\n    return new Array(capacity);\n  }\n};\n\n// src/misc/MapKeyEqualityOperator.ts\nvar MapKeyEqualityComparator = class {\n  static {\n    __name(this, \"MapKeyEqualityComparator\");\n  }\n  keyComparator;\n  constructor(keyComparator) {\n    this.keyComparator = keyComparator;\n  }\n  hashCode(obj) {\n    return this.keyComparator.hashCode(obj.key);\n  }\n  equals(a, b) {\n    return this.keyComparator.equals(a.key, b.key);\n  }\n};\n\n// src/misc/HashMap.ts\nvar HashMap = class _HashMap {\n  static {\n    __name(this, \"HashMap\");\n  }\n  backingStore;\n  constructor(keyComparer) {\n    if (keyComparer instanceof _HashMap) {\n      this.backingStore = new HashSet(keyComparer.backingStore);\n    } else {\n      keyComparer = keyComparer ?? DefaultEqualityComparator.instance;\n      this.backingStore = new HashSet(new MapKeyEqualityComparator(keyComparer));\n    }\n  }\n  clear() {\n    this.backingStore.clear();\n  }\n  containsKey(key) {\n    return this.backingStore.contains({ key });\n  }\n  get(key) {\n    const bucket = this.backingStore.get({ key });\n    if (!bucket) {\n      return void 0;\n    }\n    return bucket.value;\n  }\n  get isEmpty() {\n    return this.backingStore.isEmpty;\n  }\n  /**\n   * Sets the value for a key in the map. If the key is not present in the map, it is added.\n   * If the key is present, the value is updated and the old value is returned.\n   *\n   * @param key The key to set.\n   * @param value The value to set.\n   *\n   * @returns The old value for the key, if present.\n   */\n  set(key, value) {\n    const element = this.backingStore.get({ key, value });\n    let result;\n    if (!element) {\n      this.backingStore.add({ key, value });\n    } else {\n      result = element.value;\n      element.value = value;\n    }\n    return result;\n  }\n  /**\n   * Sets the value for a key in the map if the key is not already present. Otherwise the value is not changed and\n   * the old value is returned.\n   *\n   * @param key The key to set.\n   * @param value The value to set.\n   *\n   * @returns The current value for the key, if present.\n   */\n  setIfAbsent(key, value) {\n    const element = this.backingStore.get({ key, value });\n    let result;\n    if (!element) {\n      this.backingStore.add({ key, value });\n    } else {\n      result = element.value;\n    }\n    return result;\n  }\n  values() {\n    return this.backingStore.toArray().map((bucket) => {\n      return bucket.value;\n    });\n  }\n  get size() {\n    return this.backingStore.size;\n  }\n  hashCode() {\n    return this.backingStore.hashCode();\n  }\n  equals(o) {\n    return this.backingStore.equals(o.backingStore);\n  }\n};\n\n// src/atn/PredictionContextUtils.ts\nvar predictionContextFromRuleContext = /* @__PURE__ */ __name((atn, outerContext) => {\n  if (!outerContext) {\n    outerContext = ParserRuleContext.empty;\n  }\n  if (!outerContext.parent || outerContext === ParserRuleContext.empty) {\n    return PredictionContext.EMPTY;\n  }\n  const parent = predictionContextFromRuleContext(atn, outerContext.parent);\n  const state = atn.states[outerContext.invokingState];\n  const transition = state.transitions[0];\n  return SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}, \"predictionContextFromRuleContext\");\nvar getCachedPredictionContext = /* @__PURE__ */ __name((context, contextCache, visited) => {\n  if (context.isEmpty()) {\n    return context;\n  }\n  let existing = visited.get(context);\n  if (existing) {\n    return existing;\n  }\n  existing = contextCache.get(context);\n  if (existing) {\n    visited.set(context, existing);\n    return existing;\n  }\n  let changed = false;\n  let parents = [];\n  for (let i = 0; i < parents.length; i++) {\n    const parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n    if (changed || parent !== context.getParent(i)) {\n      if (!changed) {\n        parents = [];\n        for (let j = 0; j < context.length; j++) {\n          parents[j] = context.getParent(j);\n        }\n        changed = true;\n      }\n      parents[i] = parent;\n    }\n  }\n  if (!changed) {\n    contextCache.add(context);\n    visited.set(context, context);\n    return context;\n  }\n  let updated;\n  if (parents.length === 0) {\n    updated = PredictionContext.EMPTY;\n  } else if (parents.length === 1) {\n    updated = SingletonPredictionContext.create(parents[0] ?? void 0, context.getReturnState(0));\n  } else {\n    updated = new ArrayPredictionContext(parents, context.returnStates);\n  }\n  contextCache.add(updated);\n  visited.set(updated, updated);\n  visited.set(context, updated);\n  return updated;\n}, \"getCachedPredictionContext\");\nvar merge = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (a === b) {\n    return a;\n  }\n  if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n    return mergeSingletons(a, b, rootIsWildcard, mergeCache);\n  }\n  if (rootIsWildcard) {\n    if (a instanceof EmptyPredictionContext) {\n      return a;\n    }\n    if (b instanceof EmptyPredictionContext) {\n      return b;\n    }\n  }\n  if (a instanceof SingletonPredictionContext) {\n    a = new ArrayPredictionContext([a.parent], [a.returnState]);\n  }\n  if (b instanceof SingletonPredictionContext) {\n    b = new ArrayPredictionContext([b.parent], [b.returnState]);\n  }\n  return mergeArrays(a, b, rootIsWildcard, mergeCache);\n}, \"merge\");\nvar mergeArrays = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (mergeCache) {\n    let previous = mergeCache.get(a, b);\n    if (previous) {\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous) {\n      return previous;\n    }\n  }\n  let i = 0;\n  let j = 0;\n  let k = 0;\n  let mergedReturnStates = new Array(a.returnStates.length + b.returnStates.length).fill(0);\n  let mergedParents = new Array(a.returnStates.length + b.returnStates.length).fill(null);\n  while (i < a.returnStates.length && j < b.returnStates.length) {\n    const aParent = a.parents[i];\n    const bParent = b.parents[j];\n    if (a.returnStates[i] === b.returnStates[j]) {\n      const payload = a.returnStates[i];\n      const bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE && aParent === null && bParent === null;\n      const axAx = aParent !== null && bParent !== null && aParent === bParent;\n      if (bothDollars || axAx) {\n        mergedParents[k] = aParent;\n        mergedReturnStates[k] = payload;\n      } else {\n        mergedParents[k] = merge(aParent, bParent, rootIsWildcard, mergeCache);\n        mergedReturnStates[k] = payload;\n      }\n      i += 1;\n      j += 1;\n    } else if (a.returnStates[i] < b.returnStates[j]) {\n      mergedParents[k] = aParent;\n      mergedReturnStates[k] = a.returnStates[i];\n      i += 1;\n    } else {\n      mergedParents[k] = bParent;\n      mergedReturnStates[k] = b.returnStates[j];\n      j += 1;\n    }\n    k += 1;\n  }\n  if (i < a.returnStates.length) {\n    for (let p = i; p < a.returnStates.length; p++) {\n      mergedParents[k] = a.parents[p];\n      mergedReturnStates[k] = a.returnStates[p];\n      k += 1;\n    }\n  } else {\n    for (let p = j; p < b.returnStates.length; p++) {\n      mergedParents[k] = b.parents[p];\n      mergedReturnStates[k] = b.returnStates[p];\n      k += 1;\n    }\n  }\n  if (k < mergedParents.length) {\n    if (k === 1) {\n      const aNew = SingletonPredictionContext.create(mergedParents[0] ?? void 0, mergedReturnStates[0]);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, aNew);\n      }\n      return aNew;\n    }\n    mergedParents = mergedParents.slice(0, k);\n    mergedReturnStates = mergedReturnStates.slice(0, k);\n  }\n  const merged = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n  if (merged.equals(a)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, a);\n    }\n    if (PredictionContext.traceATNSimulator) {\n      console.log(\"mergeArrays a=\" + a + \",b=\" + b + \" -> a\");\n    }\n    return a;\n  }\n  if (merged.equals(b)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, b);\n    }\n    return b;\n  }\n  combineCommonParents(mergedParents);\n  if (mergeCache !== null) {\n    mergeCache.set(a, b, merged);\n  }\n  if (PredictionContext.traceATNSimulator) {\n    console.log(\"mergeArrays a=\" + a + \",b=\" + b + \" -> \" + merged);\n  }\n  return merged;\n}, \"mergeArrays\");\nvar combineCommonParents = /* @__PURE__ */ __name((parents) => {\n  const uniqueParents = new HashMap(ObjectEqualityComparator.instance);\n  for (const parent of parents) {\n    if (parent) {\n      if (!uniqueParents.containsKey(parent)) {\n        uniqueParents.set(parent, parent);\n      }\n    }\n  }\n  for (let q = 0; q < parents.length; q++) {\n    if (parents[q]) {\n      parents[q] = uniqueParents.get(parents[q]) ?? null;\n    }\n  }\n}, \"combineCommonParents\");\nvar mergeSingletons = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (mergeCache !== null) {\n    let previous = mergeCache.get(a, b);\n    if (previous !== null) {\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous !== null) {\n      return previous;\n    }\n  }\n  const rootMerge = mergeRoot(a, b, rootIsWildcard);\n  if (rootMerge !== null) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, rootMerge);\n    }\n    return rootMerge;\n  }\n  if (a.returnState === b.returnState) {\n    const parent = merge(a.parent, b.parent, rootIsWildcard, mergeCache);\n    if (parent === a.parent) {\n      return a;\n    }\n    if (parent === b.parent) {\n      return b;\n    }\n    const spc = SingletonPredictionContext.create(parent, a.returnState);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, spc);\n    }\n    return spc;\n  } else {\n    let singleParent = null;\n    if (a === b || a.parent !== null && a.parent === b.parent) {\n      singleParent = a.parent;\n    }\n    if (singleParent !== null) {\n      const payloads2 = [a.returnState, b.returnState];\n      if (a.returnState > b.returnState) {\n        payloads2[0] = b.returnState;\n        payloads2[1] = a.returnState;\n      }\n      const parents2 = [singleParent, singleParent];\n      const apc = new ArrayPredictionContext(parents2, payloads2);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, apc);\n      }\n      return apc;\n    }\n    const payloads = [a.returnState, b.returnState];\n    let parents = [a.parent, b.parent];\n    if (a.returnState > b.returnState) {\n      payloads[0] = b.returnState;\n      payloads[1] = a.returnState;\n      parents = [b.parent, a.parent];\n    }\n    const aNew = new ArrayPredictionContext(parents, payloads);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, aNew);\n    }\n    return aNew;\n  }\n}, \"mergeSingletons\");\nvar mergeRoot = /* @__PURE__ */ __name((a, b, rootIsWildcard) => {\n  if (rootIsWildcard) {\n    if (a === PredictionContext.EMPTY || b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY;\n    }\n  } else {\n    if (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY;\n    }\n    if (a === PredictionContext.EMPTY) {\n      const payloads = [\n        b.returnState,\n        PredictionContext.EMPTY_RETURN_STATE\n      ];\n      const parents = [b.parent, null];\n      return new ArrayPredictionContext(parents, payloads);\n    }\n    if (b === PredictionContext.EMPTY) {\n      const payloads = [a.returnState, PredictionContext.EMPTY_RETURN_STATE];\n      const parents = [a.parent, null];\n      return new ArrayPredictionContext(parents, payloads);\n    }\n  }\n  return null;\n}, \"mergeRoot\");\n\n// src/misc/BitSet.ts\nvar BitSet = class {\n  static {\n    __name(this, \"BitSet\");\n  }\n  data;\n  /**\n   * Creates a new bit set. All bits are initially `false`.\n   *\n   * @param data Optional initial data.\n   */\n  constructor(data) {\n    if (data) {\n      this.data = new Uint32Array(data.map((value) => {\n        return value >>> 0;\n      }));\n    } else {\n      this.data = new Uint32Array(1);\n    }\n  }\n  /**\n   * @returns an iterator over all set bits.\n   */\n  [Symbol.iterator]() {\n    const length = this.data.length;\n    let currentIndex = 0;\n    let currentWord = this.data[currentIndex];\n    const words = this.data;\n    return {\n      [Symbol.iterator]() {\n        return this;\n      },\n      next: /* @__PURE__ */ __name(() => {\n        while (currentIndex < length) {\n          if (currentWord !== 0) {\n            const t = currentWord & -currentWord;\n            const value = (currentIndex << 5) + this.bitCount(t - 1);\n            currentWord ^= t;\n            return { done: false, value };\n          } else {\n            currentIndex++;\n            if (currentIndex < length) {\n              currentWord = words[currentIndex];\n            }\n          }\n        }\n        return { done: true, value: void 0 };\n      }, \"next\")\n    };\n  }\n  /**\n   * Sets a single bit or all of the bits in this `BitSet` to `false`.\n   *\n   * @param index the index of the bit to be cleared, or undefined to clear all bits.\n   */\n  clear(index) {\n    if (index === void 0) {\n      this.data = new Uint32Array();\n    } else {\n      this.resize(index);\n      this.data[index >>> 5] &= ~(1 << index);\n    }\n  }\n  /**\n   * Performs a logical **OR** of this bit set with the bit set argument. This bit set is modified so that a bit in it\n   * has the value `true` if and only if it either already had the value `true` or the corresponding bit in the bit\n   * set argument has the value `true`.\n   *\n   * @param set the bit set to be ORed with.\n   */\n  or(set) {\n    const minCount = Math.min(this.data.length, set.data.length);\n    for (let k = 0; k < minCount; ++k) {\n      this.data[k] |= set.data[k];\n    }\n    if (this.data.length < set.data.length) {\n      this.resize((set.data.length << 5) - 1);\n      const c = set.data.length;\n      for (let k = minCount; k < c; ++k) {\n        this.data[k] = set.data[k];\n      }\n    }\n  }\n  /**\n   * Returns the value of the bit with the specified index. The value is `true` if the bit with the index `bitIndex`\n   * is currently set in this `BitSet`; otherwise, the result is `false`.\n   *\n   * @param index the bit index\n   *\n   * @returns the value of the bit with the specified index.\n   */\n  get(index) {\n    if (index < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    const slot = index >>> 5;\n    if (slot >= this.data.length) {\n      return false;\n    }\n    return (this.data[slot] & 1 << index % 32) !== 0;\n  }\n  /**\n   * @returns the number of set bits.\n   */\n  get length() {\n    let result = 0;\n    const c = this.data.length;\n    const w = this.data;\n    for (let i = 0; i < c; i++) {\n      result += this.bitCount(w[i]);\n    }\n    return result;\n  }\n  /**\n   * @returns an array with indices of set bits.\n   */\n  values() {\n    const result = new Array(this.length);\n    let pos = 0;\n    const length = this.data.length;\n    for (let k = 0; k < length; ++k) {\n      let w = this.data[k];\n      while (w !== 0) {\n        const t = w & -w;\n        result[pos++] = (k << 5) + this.bitCount(t - 1);\n        w ^= t;\n      }\n    }\n    return result;\n  }\n  /**\n   * @returns the index of the first bit that is set to `true` that occurs on or after the specified starting index.\n   * If no such bit exists then undefined is returned.\n   *\n   * @param fromIndex the index to start checking from (inclusive)\n   */\n  nextSetBit(fromIndex) {\n    if (fromIndex < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    for (const index of this) {\n      if (index >= fromIndex) {\n        return index;\n      }\n    }\n    return void 0;\n  }\n  /**\n   * Sets the bit at the specified index to `true`.\n   *\n   * @param index a bit index\n   */\n  set(index) {\n    if (index < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    this.resize(index);\n    this.data[index >>> 5] |= 1 << index % 32;\n  }\n  /**\n   * @returns a string representation of this bit set.\n   */\n  toString() {\n    return \"{\" + this.values().join(\", \") + \"}\";\n  }\n  resize(index) {\n    const count = index + 32 >>> 5;\n    if (count <= this.data.length) {\n      return;\n    }\n    const data = new Uint32Array(count);\n    data.set(this.data);\n    data.fill(0, this.data.length);\n    this.data = data;\n  }\n  bitCount(v) {\n    v = v - (v >> 1 & 1431655765);\n    v = (v & 858993459) + (v >> 2 & 858993459);\n    v = v + (v >> 4) & 252645135;\n    v = v + (v >> 8);\n    v = v + (v >> 16);\n    return v & 63;\n  }\n};\n\n// src/atn/ATNState.ts\nvar ATNState = class _ATNState {\n  static {\n    __name(this, \"ATNState\");\n  }\n  static INVALID_STATE_NUMBER = -1;\n  static INVALID_TYPE = 0;\n  static BASIC = 1;\n  static RULE_START = 2;\n  static BLOCK_START = 3;\n  static PLUS_BLOCK_START = 4;\n  static STAR_BLOCK_START = 5;\n  static TOKEN_START = 6;\n  static RULE_STOP = 7;\n  static BLOCK_END = 8;\n  static STAR_LOOP_BACK = 9;\n  static STAR_LOOP_ENTRY = 10;\n  static PLUS_LOOP_BACK = 11;\n  static LOOP_END = 12;\n  static stateType = _ATNState.INVALID_STATE_NUMBER;\n  stateNumber = 0;\n  ruleIndex = 0;\n  // at runtime, we don't have Rule objects\n  epsilonOnlyTransitions = false;\n  /** Used to cache lookahead during parsing, not used during construction */\n  nextTokenWithinRule;\n  /** Track the transitions emanating from this ATN state. */\n  transitions = [];\n  hashCode() {\n    return this.stateNumber;\n  }\n  equals(other) {\n    return this.stateNumber === other.stateNumber;\n  }\n  toString() {\n    return `${this.stateNumber}`;\n  }\n  addTransitionAtIndex(index, transition) {\n    if (this.transitions.length === 0) {\n      this.epsilonOnlyTransitions = transition.isEpsilon;\n    } else if (this.epsilonOnlyTransitions !== transition.isEpsilon) {\n      this.epsilonOnlyTransitions = false;\n    }\n    this.transitions.splice(index, 1, transition);\n  }\n  addTransition(transition) {\n    if (this.transitions.length === 0) {\n      this.epsilonOnlyTransitions = transition.isEpsilon;\n    } else if (this.epsilonOnlyTransitions !== transition.isEpsilon) {\n      this.epsilonOnlyTransitions = false;\n    }\n    this.transitions.push(transition);\n  }\n  setTransition(i, e) {\n    this.transitions.splice(i, 1, e);\n  }\n  removeTransition(index) {\n    const t = this.transitions.splice(index, 1);\n    return t[0];\n  }\n};\n\n// src/atn/SemanticContext.ts\nvar SemanticContext = class _SemanticContext {\n  static {\n    __name(this, \"SemanticContext\");\n  }\n  cachedHashCode;\n  static andContext(a, b) {\n    if (a === null || a === _SemanticContext.NONE) {\n      return b;\n    }\n    if (b === null || b === _SemanticContext.NONE) {\n      return a;\n    }\n    const result = new AND(a, b);\n    if (result.operands.length === 1) {\n      return result.operands[0];\n    }\n    return result;\n  }\n  static orContext(a, b) {\n    if (a === null) {\n      return b;\n    }\n    if (b === null) {\n      return a;\n    }\n    if (a === _SemanticContext.NONE || b === _SemanticContext.NONE) {\n      return _SemanticContext.NONE;\n    }\n    const result = new OR(a, b);\n    if (result.operands.length === 1) {\n      return result.operands[0];\n    } else {\n      return result;\n    }\n  }\n  static filterPrecedencePredicates(set) {\n    const result = [];\n    for (const context of set) {\n      if (context instanceof _SemanticContext.PrecedencePredicate) {\n        result.push(context);\n      }\n    }\n    return result;\n  }\n  /**\n   * Evaluate the precedence predicates for the context and reduce the result.\n   *\n   * @param _parser The parser instance.\n   * @param _parserCallStack The current parser context object.\n   * @returns The simplified semantic context after precedence predicates are\n   * evaluated, which will be one of the following values.\n   * - {@link NONE}: if the predicate simplifies to `true` after\n   * precedence predicates are evaluated.\n   * - `null`: if the predicate simplifies to `false` after\n   * precedence predicates are evaluated.\n   * - `this`: if the semantic context is not changed as a result of\n   * precedence predicate evaluation.\n   * - A non-`null` {@link SemanticContext}: the new simplified\n   * semantic context after precedence predicates are evaluated.\n   */\n  evalPrecedence(_parser, _parserCallStack) {\n    return this;\n  }\n};\nvar AND = class _AND extends SemanticContext {\n  static {\n    __name(this, \"AND\");\n  }\n  operands;\n  /**\n   * A semantic context which is true whenever none of the contained contexts\n   * is false\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof _AND) {\n      a.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof _AND) {\n      b.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n    const precedencePredicates = SemanticContext.filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      let reduced = null;\n      precedencePredicates.forEach((p) => {\n        if (reduced === null || p.precedence < reduced.precedence) {\n          reduced = p;\n        }\n      });\n      if (reduced) {\n        operands.add(reduced);\n      }\n    }\n    this.operands = operands.toArray();\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _AND)) {\n      return false;\n    }\n    return equalArrays(this.operands, other.operands);\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const operand of this.operands) {\n        hash = MurmurHash.updateFromComparable(hash, operand);\n      }\n      hash = MurmurHash.update(hash, 3813686060);\n      this.cachedHashCode = MurmurHash.finish(hash, this.operands.length + 1);\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * {@inheritDoc}\n   *\n   *\n   * The evaluation of predicates by this context is short-circuiting, but\n   * unordered.\n   */\n  evaluate(parser, parserCallStack) {\n    for (const operand of this.operands) {\n      if (!operand.evaluate(parser, parserCallStack)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  evalPrecedence(parser, parserCallStack) {\n    let differs = false;\n    const operands = [];\n    for (const context of this.operands) {\n      const evaluated = context.evalPrecedence(parser, parserCallStack);\n      differs ||= evaluated !== context;\n      if (evaluated === null) {\n        return null;\n      } else if (evaluated !== SemanticContext.NONE) {\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      return SemanticContext.NONE;\n    }\n    let result = null;\n    operands.forEach((o) => {\n      result = result === null ? o : SemanticContext.andContext(result, o);\n    });\n    return result;\n  }\n  toString() {\n    const s = this.operands.map((o) => {\n      return o.toString();\n    });\n    return (s.length > 3 ? s.slice(3) : s).join(\"&&\");\n  }\n};\nvar OR = class _OR extends SemanticContext {\n  static {\n    __name(this, \"OR\");\n  }\n  operands;\n  /**\n   * A semantic context which is true whenever at least one of the contained\n   * contexts is true\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof _OR) {\n      a.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof _OR) {\n      b.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n    const precedencePredicates = SemanticContext.filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      const s = precedencePredicates.sort((a2, b2) => {\n        return a2.compareTo(b2);\n      });\n      const reduced = s[s.length - 1];\n      operands.add(reduced);\n    }\n    this.operands = operands.toArray();\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof _OR)) {\n      return false;\n    } else {\n      return equalArrays(this.operands, other.operands);\n    }\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const operand of this.operands) {\n        hash = MurmurHash.updateFromComparable(hash, operand);\n      }\n      hash = MurmurHash.update(hash, 3383313031);\n      this.cachedHashCode = MurmurHash.finish(hash, this.operands.length + 1);\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * The evaluation of predicates by this context is short-circuiting, but unordered.\n   */\n  evaluate(parser, parserCallStack) {\n    for (const operand of this.operands) {\n      if (operand.evaluate(parser, parserCallStack)) {\n        return true;\n      }\n    }\n    return false;\n  }\n  evalPrecedence(parser, parserCallStack) {\n    let differs = false;\n    const operands = [];\n    for (const context of this.operands) {\n      const evaluated = context.evalPrecedence(parser, parserCallStack);\n      differs ||= evaluated !== context;\n      if (evaluated === SemanticContext.NONE) {\n        return SemanticContext.NONE;\n      } else if (evaluated !== null) {\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      return null;\n    }\n    let result = null;\n    operands.forEach((o) => {\n      result = result === null ? o : SemanticContext.orContext(result, o);\n    });\n    return result;\n  }\n  toString() {\n    const s = this.operands.map((o) => {\n      return o.toString();\n    });\n    return (s.length > 3 ? s.slice(3) : s).join(\"||\");\n  }\n};\n((SemanticContext2) => {\n  class Predicate extends SemanticContext2 {\n    static {\n      __name(this, \"Predicate\");\n    }\n    ruleIndex;\n    predIndex;\n    isCtxDependent;\n    // e.g., $i ref in pred\n    constructor(ruleIndex, predIndex, isCtxDependent) {\n      super();\n      this.ruleIndex = ruleIndex ?? -1;\n      this.predIndex = predIndex ?? -1;\n      this.isCtxDependent = isCtxDependent ?? false;\n    }\n    evaluate(parser, outerContext) {\n      const localctx = this.isCtxDependent ? outerContext : null;\n      return parser.sempred(localctx, this.ruleIndex, this.predIndex);\n    }\n    hashCode() {\n      if (this.cachedHashCode === void 0) {\n        let hashCode = MurmurHash.initialize();\n        hashCode = MurmurHash.update(hashCode, this.ruleIndex);\n        hashCode = MurmurHash.update(hashCode, this.predIndex);\n        hashCode = MurmurHash.update(hashCode, this.isCtxDependent ? 1 : 0);\n        hashCode = MurmurHash.finish(hashCode, 3);\n        this.cachedHashCode = hashCode;\n      }\n      return this.cachedHashCode;\n    }\n    equals(other) {\n      if (this === other) {\n        return true;\n      }\n      return this.ruleIndex === other.ruleIndex && this.predIndex === other.predIndex && this.isCtxDependent === other.isCtxDependent;\n    }\n    toString() {\n      return \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n    }\n  }\n  SemanticContext2.Predicate = Predicate;\n  class PrecedencePredicate extends SemanticContext2 {\n    static {\n      __name(this, \"PrecedencePredicate\");\n    }\n    precedence;\n    constructor(precedence) {\n      super();\n      this.precedence = precedence ?? 0;\n    }\n    evaluate(parser, outerContext) {\n      return parser.precpred(outerContext, this.precedence);\n    }\n    evalPrecedence(parser, outerContext) {\n      if (parser.precpred(outerContext ?? null, this.precedence)) {\n        return SemanticContext2.NONE;\n      }\n      return null;\n    }\n    compareTo(other) {\n      return this.precedence - other.precedence;\n    }\n    hashCode() {\n      return 31 + this.precedence;\n    }\n    equals(other) {\n      if (this === other) {\n        return true;\n      }\n      return this.precedence === other.precedence;\n    }\n    toString() {\n      return \"{\" + this.precedence + \">=prec}?\";\n    }\n  }\n  SemanticContext2.PrecedencePredicate = PrecedencePredicate;\n  SemanticContext2.NONE = new Predicate();\n})(SemanticContext || (SemanticContext = {}));\n\n// src/atn/ATNConfig.ts\nvar ATNConfig = class _ATNConfig {\n  static {\n    __name(this, \"ATNConfig\");\n  }\n  /** The ATN state associated with this configuration */\n  state;\n  /** What alt (or lexer rule) is predicted by this configuration */\n  alt;\n  /**\n   * We cannot execute predicates dependent upon local context unless\n   * we know for sure we are in the correct context. Because there is\n   * no way to do this efficiently, we simply cannot evaluate\n   * dependent predicates unless we are in the rule that initially\n   * invokes the ATN simulator.\n   *\n   * closure() tracks the depth of how far we dip into the outer context:\n   * depth > 0.\n   */\n  reachesIntoOuterContext = false;\n  // Not used in hash code.\n  precedenceFilterSuppressed = false;\n  // Not used in hash code.\n  get semanticContext() {\n    return this.#semanticContext;\n  }\n  cachedHashCode;\n  // Shared with LexerATNConfig.\n  /**\n   * The syntactic context is a graph-structured stack node whose\n   * path(s) to the root is the rule invocation(s)\n   * chain used to arrive at the state.  The semantic context is\n   * the tree of semantic predicates encountered before reaching\n   * an ATN state\n   */\n  #context = null;\n  #semanticContext;\n  /** Never create config classes directly. Use the factory methods below. */\n  constructor(c, state, context, semanticContext) {\n    this.state = state;\n    this.alt = c.alt;\n    this.context = context;\n    this.#semanticContext = semanticContext ?? SemanticContext.NONE;\n    this.reachesIntoOuterContext = c.reachesIntoOuterContext;\n    if (c.precedenceFilterSuppressed !== void 0) {\n      this.precedenceFilterSuppressed = c.precedenceFilterSuppressed;\n    }\n  }\n  static duplicate(old, semanticContext) {\n    return new _ATNConfig(old, old.state, old.context, semanticContext ?? old.semanticContext);\n  }\n  static createWithContext(state, alt, context, semanticContext) {\n    return new _ATNConfig({ alt }, state, context, semanticContext);\n  }\n  static createWithConfig(state, config, context) {\n    return new _ATNConfig(config, state, context ?? config.context, config.semanticContext);\n  }\n  static createWithSemanticContext(state, c, semanticContext) {\n    return new _ATNConfig(c, state ?? c.state, c.context, semanticContext);\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      hashCode = MurmurHash.update(hashCode, this.state.stateNumber);\n      hashCode = MurmurHash.update(hashCode, this.alt);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.#context);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.semanticContext);\n      hashCode = MurmurHash.finish(hashCode, 4);\n      this.cachedHashCode = hashCode;\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * The stack of invoking states leading to the rule/states associated\n   * with this config.  We track only those contexts pushed during\n   * execution of the ATN simulator.\n   */\n  get context() {\n    return this.#context;\n  }\n  set context(context) {\n    this.#context = context;\n    this.cachedHashCode = void 0;\n  }\n  /**\n   * An ATN configuration is equal to another if both have\n   * the same state, they predict the same alternative, and\n   * syntactic/semantic contexts are the same.\n   */\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    return this.state.stateNumber === other.state.stateNumber && this.alt === other.alt && (this.context === null ? other.context === null : this.context.equals(other.context)) && this.semanticContext.equals(other.semanticContext) && this.precedenceFilterSuppressed === other.precedenceFilterSuppressed;\n  }\n  toString(_recog, showAlt = true) {\n    let alt = \"\";\n    if (showAlt) {\n      alt = \",\" + this.alt;\n    }\n    return \"(\" + this.state + alt + (this.context !== null ? \",[\" + this.context.toString() + \"]\" : \"\") + (this.semanticContext !== SemanticContext.NONE ? \",\" + this.semanticContext.toString() : \"\") + (this.reachesIntoOuterContext ? \",up=\" + this.reachesIntoOuterContext : \"\") + \")\";\n  }\n};\n\n// src/atn/LL1Analyzer.ts\nvar LL1Analyzer = class _LL1Analyzer {\n  static {\n    __name(this, \"LL1Analyzer\");\n  }\n  /**\n   * Special value added to the lookahead sets to indicate that we hit\n   * a predicate during analysis if `seeThruPreds==false`.\n   */\n  static hitPredicate = Token.INVALID_TYPE;\n  #atn;\n  /**\n   * Calculates the SLL(1) expected lookahead set for each outgoing transition\n   * of an {@link ATNState}. The returned array has one element for each\n   * outgoing transition in `s`. If the closure from transition\n   * _i_ leads to a semantic predicate before matching a symbol, the\n   * element at index *i* of the result will be `null`.\n   *\n   * @param s the ATN state\n   * @returns the expected symbols for each outgoing transition of `s`.\n   */\n  getDecisionLookahead(s) {\n    if (!s) {\n      return void 0;\n    }\n    const count = s.transitions.length;\n    const look = new Array(count);\n    for (let alt = 0; alt < count; alt++) {\n      const set = new IntervalSet();\n      const lookBusy = new HashSet();\n      this.doLook(\n        s.transitions[alt].target,\n        void 0,\n        PredictionContext.EMPTY,\n        set,\n        lookBusy,\n        new BitSet(),\n        false,\n        false\n      );\n      if (set.length > 0 && !set.contains(_LL1Analyzer.hitPredicate)) {\n        look[alt] = set;\n      }\n    }\n    return look;\n  }\n  /**\n   * Compute set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   *\n   * If `ctx` is `null` and the end of the rule containing\n   * `s` is reached, {@link Token//EPSILON} is added to the result set.\n   * If `ctx` is not `null` and the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.\n   *\n   * @param atn the ATN\n   * @param s the ATN state\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx the complete parser context, or `null` if the context\n   * should be ignored\n   *\n   * @returns The set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   */\n  look(atn, s, stopState, ctx) {\n    this.#atn = atn;\n    const r = new IntervalSet();\n    const lookContext = ctx ? predictionContextFromRuleContext(atn, ctx) : null;\n    this.doLook(s, stopState, lookContext, r, new HashSet(), new BitSet(), true, true);\n    return r;\n  }\n  /**\n   * Compute set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   *\n   * If `ctx` is `null` and `stopState` or the end of the\n   * rule containing `s` is reached, {@link Token//EPSILON} is added to\n   * the result set. If `ctx` is not `null` and `addEOF` is\n   * `true` and `stopState` or the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.\n   *\n   * @param s the ATN state.\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx The outer context, or `null` if the outer context should\n   * not be used.\n   * @param look The result lookahead set.\n   * @param lookBusy A set used for preventing epsilon closures in the ATN\n   * from causing a stack overflow. Outside code should pass\n   * `new CustomizedSet<ATNConfig>` for this argument.\n   * @param calledRuleStack A set used for preventing left recursion in the\n   * ATN from causing a stack overflow. Outside code should pass\n   * `new BitSet()` for this argument.\n   * @param seeThruPreds `true` to true semantic predicates as\n   * implicitly `true` and \"see through them\", otherwise `false`\n   * to treat semantic predicates as opaque and add {@link hitPredicate} to the\n   * result if one is encountered.\n   * @param addEOF Add {@link Token//EOF} to the result if the end of the\n   * outermost context is reached. This parameter has no effect if `ctx`\n   * is `null`.\n   */\n  doLook(s, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n    const c = ATNConfig.createWithContext(s, 0, ctx);\n    if (lookBusy.get(c)) {\n      return;\n    }\n    lookBusy.add(c);\n    if (s === stopState) {\n      if (!ctx) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n    }\n    if (s.constructor.stateType === ATNState.RULE_STOP) {\n      if (!ctx) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n      if (ctx !== PredictionContext.EMPTY) {\n        const removed = calledRuleStack.get(s.ruleIndex);\n        try {\n          calledRuleStack.clear(s.ruleIndex);\n          for (let i = 0; i < ctx.length; i++) {\n            const returnState = this.#atn.states[ctx.getReturnState(i)];\n            this.doLook(\n              returnState,\n              stopState,\n              ctx.getParent(i),\n              look,\n              lookBusy,\n              calledRuleStack,\n              seeThruPreds,\n              addEOF\n            );\n          }\n        } finally {\n          if (removed) {\n            calledRuleStack.set(s.ruleIndex);\n          }\n        }\n        return;\n      }\n    }\n    for (const t of s.transitions) {\n      switch (t.transitionType) {\n        case Transition.RULE: {\n          if (calledRuleStack.get(t.target.ruleIndex)) {\n            continue;\n          }\n          const newContext = SingletonPredictionContext.create(\n            ctx ?? void 0,\n            t.followState.stateNumber\n          );\n          try {\n            calledRuleStack.set(t.target.ruleIndex);\n            this.doLook(\n              t.target,\n              stopState,\n              newContext,\n              look,\n              lookBusy,\n              calledRuleStack,\n              seeThruPreds,\n              addEOF\n            );\n          } finally {\n            calledRuleStack.clear(t.target.ruleIndex);\n          }\n          break;\n        }\n        case Transition.PREDICATE:\n        case Transition.PRECEDENCE: {\n          if (seeThruPreds) {\n            this.doLook(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n          } else {\n            look.addOne(_LL1Analyzer.hitPredicate);\n          }\n          break;\n        }\n        case Transition.WILDCARD: {\n          look.addRange(Token.MIN_USER_TOKEN_TYPE, this.#atn.maxTokenType);\n          break;\n        }\n        default: {\n          if (t.isEpsilon) {\n            this.doLook(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n          } else {\n            let set = t.label;\n            if (set) {\n              if (t instanceof NotSetTransition) {\n                set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.#atn.maxTokenType);\n              }\n              look.addSet(set);\n            }\n          }\n          break;\n        }\n      }\n    }\n  }\n};\n\n// src/atn/ATN.ts\nvar ATN = class _ATN {\n  static {\n    __name(this, \"ATN\");\n  }\n  static INVALID_ALT_NUMBER = 0;\n  /** Represents the type of recognizer an ATN applies to */\n  static LEXER = 0;\n  static PARSER = 1;\n  /**\n   * Used for runtime deserialization of ATNs from strings\n   * The type of the ATN.\n   */\n  grammarType;\n  /** The maximum value for any symbol recognized by a transition in the ATN. */\n  maxTokenType;\n  states = [];\n  /**\n   * Each subrule/rule is a decision point and we must track them so we\n   * can go back later and build DFA predictors for them.  This includes\n   * all the rules, subrules, optional blocks, ()+, ()* etc...\n   */\n  decisionToState = [];\n  /** Maps from rule index to starting state number. */\n  ruleToStartState = [];\n  // Initialized by the ATN deserializer.\n  /** Maps from rule index to stop state number. */\n  ruleToStopState = [];\n  // Initialized by the ATN deserializer.\n  modeNameToStartState = /* @__PURE__ */ new Map();\n  /**\n   * For lexer ATNs, this maps the rule index to the resulting token type.\n   * For parser ATNs, this maps the rule index to the generated bypass token\n   * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n   * deserialization option was specified; otherwise, this is `null`\n   */\n  ruleToTokenType = [];\n  // Initialized by the ATN deserializer.\n  /**\n   * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n   * be referenced by action transitions in the ATN\n   */\n  lexerActions = [];\n  modeToStartState = [];\n  static #analyzer = new LL1Analyzer();\n  constructor(grammarType, maxTokenType) {\n    this.grammarType = grammarType;\n    this.maxTokenType = maxTokenType;\n  }\n  /**\n   * Compute the set of valid tokens that can occur starting in state `s`.\n   * If `ctx` is null, the set of tokens will not include what can follow\n   * the rule surrounding `s`. In other words, the set will be\n   * restricted to tokens reachable staying within `s`'s rule.\n   */\n  nextTokens(atnState, ctx) {\n    if (!ctx && atnState.nextTokenWithinRule) {\n      return atnState.nextTokenWithinRule;\n    }\n    const next = _ATN.#analyzer.look(this, atnState, void 0, ctx);\n    if (!ctx) {\n      atnState.nextTokenWithinRule = next;\n    }\n    return next;\n  }\n  addState(state) {\n    if (state) {\n      state.stateNumber = this.states.length;\n    }\n    this.states.push(state);\n  }\n  removeState(state) {\n    this.states[state.stateNumber] = null;\n  }\n  defineDecisionState(s) {\n    this.decisionToState.push(s);\n    s.decision = this.decisionToState.length - 1;\n    return s.decision;\n  }\n  getDecisionState(decision) {\n    if (this.decisionToState.length === 0) {\n      return null;\n    } else {\n      return this.decisionToState[decision];\n    }\n  }\n  getNumberOfDecisions() {\n    return this.decisionToState.length;\n  }\n  /**\n   * Computes the set of input symbols which could follow ATN state number\n   * `stateNumber` in the specified full `context`. This method\n   * considers the complete parser context, but does not evaluate semantic\n   * predicates (i.e. all predicates encountered during the calculation are\n   * assumed true). If a path in the ATN exists from the starting state to the\n   * {@link RuleStopState} of the outermost context without matching any\n   * symbols, {@link Token//EOF} is added to the returned set.\n   *\n   * If `context` is `null`, it is treated as\n   * {@link ParserRuleContext//EMPTY}.\n   *\n   * @param stateNumber the ATN state number\n   * @param context the full parse context\n   *\n   * @returns {IntervalSet} The set of potentially valid input symbols which could follow the\n   * specified state in the specified context.\n   *\n   * @throws IllegalArgumentException if the ATN does not contain a state with\n   * number `stateNumber`\n   */\n  getExpectedTokens(stateNumber, context) {\n    if (stateNumber < 0 || stateNumber >= this.states.length) {\n      throw new Error(\"Invalid state number.\");\n    }\n    const s = this.states[stateNumber];\n    let following = this.nextTokens(s);\n    if (!following.contains(Token.EPSILON)) {\n      return following;\n    }\n    let ctx = context;\n    const expected = new IntervalSet();\n    expected.addSet(following);\n    expected.removeOne(Token.EPSILON);\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = this.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = this.nextTokens(rt.followState);\n      expected.addSet(following);\n      expected.removeOne(Token.EPSILON);\n      ctx = ctx.parent;\n    }\n    if (following.contains(Token.EPSILON)) {\n      expected.addOne(Token.EOF);\n    }\n    return expected;\n  }\n};\n\n// src/atn/ATNConfigSet.ts\nvar KeyTypeEqualityComparer = class _KeyTypeEqualityComparer {\n  static {\n    __name(this, \"KeyTypeEqualityComparer\");\n  }\n  static instance = new _KeyTypeEqualityComparer();\n  hashCode(config) {\n    let hashCode = 7;\n    hashCode = 31 * hashCode + config.state.stateNumber;\n    hashCode = 31 * hashCode + config.alt;\n    hashCode = 31 * hashCode + config.semanticContext.hashCode();\n    return hashCode;\n  }\n  equals(a, b) {\n    if (a === b) {\n      return true;\n    }\n    return a.state.stateNumber === b.state.stateNumber && a.alt === b.alt && a.semanticContext.equals(b.semanticContext);\n  }\n};\nvar ATNConfigSet = class {\n  static {\n    __name(this, \"ATNConfigSet\");\n  }\n  /**\n   * The reason that we need this is because we don't want the hash map to use\n   * the standard hash code and equals. We need all configurations with the\n   * same\n   * `(s,i,_,semctx)` to be equal. Unfortunately, this key effectively\n   * doubles\n   * the number of objects associated with ATNConfigs. The other solution is\n   * to\n   * use a hash table that lets us specify the equals/hashCode operation.\n   * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n   * when we go readonly as this set becomes a DFA state\n   */\n  configLookup = new HashSet(KeyTypeEqualityComparer.instance);\n  // Track the elements as they are added to the set; supports get(i).\n  configs = [];\n  uniqueAlt = 0;\n  /**\n   * Used in parser and lexer. In lexer, it indicates we hit a pred\n   * while computing a closure operation. Don't make a DFA state from this\n   */\n  hasSemanticContext = false;\n  dipsIntoOuterContext = false;\n  /**\n   * Indicates that this configuration set is part of a full context\n   * LL prediction. It will be used to determine how to merge $. With SLL\n   * it's a wildcard whereas it is not for LL context merge\n   */\n  fullCtx = false;\n  /**\n   * Indicates that the set of configurations is read-only. Do not\n   * allow any code to manipulate the set; DFA states will point at\n   * the sets and they must not change. This does not protect the other\n   * fields; in particular, conflictingAlts is set after\n   * we've made this readonly\n   */\n  readOnly = false;\n  conflictingAlts = null;\n  /**\n   * Tracks the first config that has a rule stop state. Avoids frequent linear search for that, when adding\n   * a DFA state in the lexer ATN simulator.\n   */\n  firstStopState;\n  #cachedHashCode = -1;\n  constructor(fullCtxOrOldSet) {\n    if (fullCtxOrOldSet !== void 0) {\n      if (typeof fullCtxOrOldSet === \"boolean\") {\n        this.fullCtx = fullCtxOrOldSet ?? true;\n      } else {\n        const old = fullCtxOrOldSet;\n        this.addAll(old.configs);\n        this.uniqueAlt = old.uniqueAlt;\n        this.conflictingAlts = old.conflictingAlts;\n        this.hasSemanticContext = old.hasSemanticContext;\n        this.dipsIntoOuterContext = old.dipsIntoOuterContext;\n      }\n    }\n  }\n  [Symbol.iterator]() {\n    return this.configs[Symbol.iterator]();\n  }\n  /**\n   * Adding a new config means merging contexts with existing configs for\n   * `(s, i, pi, _)`, where `s` is the {@link ATNConfig.state}, `i` is the {@link ATNConfig.alt}, and\n   * `pi` is the {@link ATNConfig.semanticContext}. We use `(s,i,pi)` as key.\n   *\n   * This method updates {@link dipsIntoOuterContext} and\n   * {@link hasSemanticContext} when necessary.\n   */\n  add(config, mergeCache = null) {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    if (!this.firstStopState && config.state.constructor.stateType === ATNState.RULE_STOP) {\n      this.firstStopState = config;\n    }\n    this.hasSemanticContext ||= config.semanticContext !== SemanticContext.NONE;\n    this.dipsIntoOuterContext ||= config.reachesIntoOuterContext;\n    const existing = this.configLookup.getOrAdd(config);\n    if (existing === config) {\n      this.#cachedHashCode = -1;\n      this.configs.push(config);\n      return;\n    }\n    const rootIsWildcard = !this.fullCtx;\n    const merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n    existing.reachesIntoOuterContext ||= config.reachesIntoOuterContext;\n    existing.precedenceFilterSuppressed ||= config.precedenceFilterSuppressed;\n    existing.context = merged;\n  }\n  /** Return a List holding list of configs */\n  get elements() {\n    return this.configs;\n  }\n  /**\n   * Gets the complete set of represented alternatives for the configuration set.\n   *\n   * @returns the set of represented alternatives in this configuration set\n   */\n  getAlts() {\n    const alts = new BitSet();\n    for (const config of this.configs) {\n      alts.set(config.alt);\n    }\n    return alts;\n  }\n  getPredicates() {\n    const preds = [];\n    for (const config of this.configs) {\n      if (config.semanticContext !== SemanticContext.NONE) {\n        preds.push(config.semanticContext);\n      }\n    }\n    return preds;\n  }\n  getStates() {\n    const states = new HashSet();\n    for (const config of this.configs) {\n      states.add(config.state);\n    }\n    return states;\n  }\n  optimizeConfigs(interpreter) {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    if (this.configLookup.size === 0) {\n      return;\n    }\n    for (const config of this.configs) {\n      config.context = interpreter.getCachedContext(config.context);\n    }\n  }\n  addAll(coll) {\n    for (const config of coll) {\n      this.add(config);\n    }\n    return false;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.fullCtx === other.fullCtx && this.uniqueAlt === other.uniqueAlt && this.conflictingAlts === other.conflictingAlts && this.hasSemanticContext === other.hasSemanticContext && this.dipsIntoOuterContext === other.dipsIntoOuterContext && equalArrays(this.configs, other.configs)) {\n      return true;\n    }\n    return false;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === -1) {\n      this.#cachedHashCode = this.computeHashCode();\n    }\n    return this.#cachedHashCode;\n  }\n  get length() {\n    return this.configs.length;\n  }\n  isEmpty() {\n    return this.configs.length === 0;\n  }\n  contains(item) {\n    if (this.configLookup === null) {\n      throw new Error(\"This method is not implemented for readonly sets.\");\n    }\n    return this.configLookup.contains(item);\n  }\n  containsFast(item) {\n    if (this.configLookup === null) {\n      throw new Error(\"This method is not implemented for readonly sets.\");\n    }\n    return this.configLookup.contains(item);\n  }\n  clear() {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    this.configs = [];\n    this.#cachedHashCode = -1;\n    this.configLookup = new HashSet(KeyTypeEqualityComparer.instance);\n  }\n  setReadonly(readOnly) {\n    this.readOnly = readOnly;\n    if (readOnly) {\n      this.configLookup = null;\n    }\n  }\n  toString() {\n    return arrayToString(this.configs) + (this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") + (this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") + (this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") + (this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n  }\n  computeHashCode() {\n    let hash = MurmurHash.initialize();\n    this.configs.forEach((config) => {\n      hash = MurmurHash.update(hash, config.hashCode());\n    });\n    hash = MurmurHash.finish(hash, this.configs.length);\n    return hash;\n  }\n};\n\n// src/atn/BasicState.ts\nvar BasicState = class extends ATNState {\n  static {\n    __name(this, \"BasicState\");\n  }\n  static stateType = ATNState.BASIC;\n};\n\n// src/atn/DecisionState.ts\nvar DecisionState = class extends ATNState {\n  static {\n    __name(this, \"DecisionState\");\n  }\n  decision = -1;\n  nonGreedy = false;\n};\n\n// src/atn/BlockStartState.ts\nvar BlockStartState = class extends DecisionState {\n  static {\n    __name(this, \"BlockStartState\");\n  }\n  endState;\n};\n\n// src/atn/BlockEndState.ts\nvar BlockEndState = class extends ATNState {\n  static {\n    __name(this, \"BlockEndState\");\n  }\n  static stateType = ATNState.BLOCK_END;\n  startState;\n};\n\n// src/atn/LoopEndState.ts\nvar LoopEndState = class extends ATNState {\n  static {\n    __name(this, \"LoopEndState\");\n  }\n  static stateType = ATNState.LOOP_END;\n  loopBackState;\n};\n\n// src/atn/RuleStartState.ts\nvar RuleStartState = class extends ATNState {\n  static {\n    __name(this, \"RuleStartState\");\n  }\n  static stateType = ATNState.RULE_START;\n  stopState;\n  isLeftRecursiveRule = false;\n};\n\n// src/atn/RuleStopState.ts\nvar RuleStopState = class extends ATNState {\n  static {\n    __name(this, \"RuleStopState\");\n  }\n  static stateType = ATNState.RULE_STOP;\n};\n\n// src/atn/TokensStartState.ts\nvar TokensStartState = class extends DecisionState {\n  static {\n    __name(this, \"TokensStartState\");\n  }\n  static stateType = ATNState.TOKEN_START;\n};\n\n// src/atn/PlusLoopbackState.ts\nvar PlusLoopbackState = class extends DecisionState {\n  static {\n    __name(this, \"PlusLoopbackState\");\n  }\n  static stateType = ATNState.PLUS_LOOP_BACK;\n};\n\n// src/atn/StarLoopbackState.ts\nvar StarLoopbackState = class extends ATNState {\n  static {\n    __name(this, \"StarLoopbackState\");\n  }\n  static stateType = ATNState.STAR_LOOP_BACK;\n};\n\n// src/atn/StarLoopEntryState.ts\nvar StarLoopEntryState = class extends DecisionState {\n  static {\n    __name(this, \"StarLoopEntryState\");\n  }\n  static stateType = ATNState.STAR_LOOP_ENTRY;\n  // This is always set during ATN deserialization\n  loopBackState;\n  /**\n   * Indicates whether this state can benefit from a precedence DFA during SLL\n   * decision making.\n   *\n   * This is a computed property that is calculated during ATN deserialization\n   * and stored for use in {@link ParserATNSimulator} and\n   * {@link ParserInterpreter}.\n   *\n   * @see `DFA.isPrecedenceDfa`\n   */\n  precedenceRuleDecision = false;\n};\n\n// src/atn/PlusBlockStartState.ts\nvar PlusBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"PlusBlockStartState\");\n  }\n  static stateType = ATNState.PLUS_BLOCK_START;\n  loopBackState;\n};\n\n// src/atn/StarBlockStartState.ts\nvar StarBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"StarBlockStartState\");\n  }\n  static stateType = ATNState.STAR_BLOCK_START;\n};\n\n// src/atn/BasicBlockStartState.ts\nvar BasicBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"BasicBlockStartState\");\n  }\n  static stateType = ATNState.BLOCK_START;\n};\n\n// src/atn/AtomTransition.ts\nvar AtomTransition = class extends Transition {\n  static {\n    __name(this, \"AtomTransition\");\n  }\n  /** The token type or character value; or, signifies special label. */\n  labelValue;\n  #label;\n  constructor(target, label) {\n    super(target);\n    this.labelValue = label;\n    this.#label = IntervalSet.of(label, label);\n  }\n  get label() {\n    return this.#label;\n  }\n  get transitionType() {\n    return Transition.ATOM;\n  }\n  matches(symbol) {\n    return this.labelValue === symbol;\n  }\n  toString() {\n    return this.labelValue.toString();\n  }\n};\n\n// src/atn/RuleTransition.ts\nvar RuleTransition = class extends Transition {\n  static {\n    __name(this, \"RuleTransition\");\n  }\n  ruleIndex;\n  precedence;\n  followState;\n  constructor(ruleStart, ruleIndex, precedence, followState) {\n    super(ruleStart);\n    this.ruleIndex = ruleIndex;\n    this.precedence = precedence;\n    this.followState = followState;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.RULE;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n};\n\n// src/atn/RangeTransition.ts\nvar RangeTransition = class extends Transition {\n  static {\n    __name(this, \"RangeTransition\");\n  }\n  start;\n  stop;\n  #label = new IntervalSet();\n  constructor(target, start, stop) {\n    super(target);\n    this.start = start;\n    this.stop = stop;\n    this.#label.addRange(start, stop);\n  }\n  get label() {\n    return this.#label;\n  }\n  get transitionType() {\n    return Transition.RANGE;\n  }\n  matches(symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return symbol >= this.start && symbol <= this.stop;\n  }\n  toString() {\n    return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n  }\n};\n\n// src/atn/ActionTransition.ts\nvar ActionTransition = class extends Transition {\n  static {\n    __name(this, \"ActionTransition\");\n  }\n  ruleIndex;\n  actionIndex;\n  isCtxDependent;\n  constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n    super(target);\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex ?? -1;\n    this.isCtxDependent = isCtxDependent ?? false;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.ACTION;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  toString() {\n    return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n  }\n};\n\n// src/atn/EpsilonTransition.ts\nvar EpsilonTransition = class extends Transition {\n  static {\n    __name(this, \"EpsilonTransition\");\n  }\n  #outermostPrecedenceReturn;\n  constructor(target, outermostPrecedenceReturn = -1) {\n    super(target);\n    this.#outermostPrecedenceReturn = outermostPrecedenceReturn;\n  }\n  /**\n   * @returns the rule index of a precedence rule for which this transition is\n   * returning from, where the precedence value is 0; otherwise, -1.\n   *\n   * @see ATNConfig.isPrecedenceFilterSuppressed()\n   * @see ParserATNSimulator.applyPrecedenceFilter(ATNConfigSet)\n   * @since 4.4.1\n   */\n  get outermostPrecedenceReturn() {\n    return this.#outermostPrecedenceReturn;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.EPSILON;\n  }\n  matches() {\n    return false;\n  }\n  toString() {\n    return \"epsilon\";\n  }\n};\n\n// src/atn/WildcardTransition.ts\nvar WildcardTransition = class extends Transition {\n  static {\n    __name(this, \"WildcardTransition\");\n  }\n  get transitionType() {\n    return Transition.WILDCARD;\n  }\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n  }\n  toString() {\n    return \".\";\n  }\n};\n\n// src/atn/AbstractPredicateTransition.ts\nvar AbstractPredicateTransition = class extends Transition {\n  static {\n    __name(this, \"AbstractPredicateTransition\");\n  }\n  constructor(target) {\n    super(target);\n  }\n};\n\n// src/atn/PredicateTransition.ts\nvar PredicateTransition = class extends AbstractPredicateTransition {\n  static {\n    __name(this, \"PredicateTransition\");\n  }\n  ruleIndex;\n  predIndex;\n  isCtxDependent;\n  // e.g., $i ref in pred\n  constructor(target, ruleIndex, predIndex, isCtxDependent) {\n    super(target);\n    this.ruleIndex = ruleIndex;\n    this.predIndex = predIndex;\n    this.isCtxDependent = isCtxDependent;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  get transitionType() {\n    return Transition.PREDICATE;\n  }\n  getPredicate() {\n    return new SemanticContext.Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n  }\n  toString() {\n    return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n  }\n};\n\n// src/atn/PrecedencePredicateTransition.ts\nvar PrecedencePredicateTransition = class extends AbstractPredicateTransition {\n  static {\n    __name(this, \"PrecedencePredicateTransition\");\n  }\n  precedence;\n  constructor(target, precedence) {\n    super(target);\n    this.precedence = precedence;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  getPredicate() {\n    return new SemanticContext.PrecedencePredicate(this.precedence);\n  }\n  get transitionType() {\n    return Transition.PRECEDENCE;\n  }\n  toString() {\n    return this.precedence + \" >= _p\";\n  }\n};\n\n// src/atn/LexerActionType.ts\nvar LexerActionType = {\n  /** The type of a {@link LexerChannelAction} action. */\n  CHANNEL: 0,\n  /** The type of a {@link LexerCustomAction} action */\n  CUSTOM: 1,\n  /** The type of a {@link LexerModeAction} action. */\n  MODE: 2,\n  /** The type of a {@link LexerMoreAction} action. */\n  MORE: 3,\n  /** The type of a {@link LexerPopModeAction} action. */\n  POP_MODE: 4,\n  /** The type of a {@link LexerPushModeAction} action. */\n  PUSH_MODE: 5,\n  /** The type of a {@link LexerSkipAction} action. */\n  SKIP: 6,\n  /** The type of a {@link LexerTypeAction} action. */\n  TYPE: 7\n};\n\n// src/atn/LexerSkipAction.ts\nvar LexerSkipAction = class _LexerSkipAction {\n  static {\n    __name(this, \"LexerSkipAction\");\n  }\n  /** Provides a singleton instance of this parameter-less lexer action. */\n  static instance = new _LexerSkipAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.SKIP;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.SKIP;\n  }\n  execute(lexer) {\n    lexer.skip();\n  }\n  toString() {\n    return \"skip\";\n  }\n};\n\n// src/atn/LexerChannelAction.ts\nvar LexerChannelAction = class _LexerChannelAction {\n  static {\n    __name(this, \"LexerChannelAction\");\n  }\n  channel;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(channel) {\n    this.actionType = LexerActionType.CHANNEL;\n    this.channel = channel;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.setChannel} with the\n   * value provided by {@link getChannel}.\n   */\n  execute(lexer) {\n    lexer.channel = this.channel;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.channel);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerChannelAction)) {\n      return false;\n    }\n    return this.channel === other.channel;\n  }\n  toString() {\n    return \"channel(\" + this.channel + \")\";\n  }\n};\n\n// src/atn/LexerCustomAction.ts\nvar LexerCustomAction = class _LexerCustomAction {\n  static {\n    __name(this, \"LexerCustomAction\");\n  }\n  ruleIndex;\n  actionIndex;\n  actionType;\n  isPositionDependent = true;\n  #cachedHashCode;\n  /**\n   * Constructs a custom lexer action with the specified rule and action indexes.\n   *\n   * @param ruleIndex The rule index to use for calls to {@link Recognizer.action}.\n   * @param actionIndex The action index to use for calls to {@link Recognizer.action}.\n   */\n  constructor(ruleIndex, actionIndex) {\n    this.actionType = LexerActionType.CUSTOM;\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex;\n  }\n  /**\n   * Custom actions are implemented by calling {@link Lexer.action} with the\n   * appropriate rule and action indexes.\n   */\n  execute(lexer) {\n    lexer.action(null, this.ruleIndex, this.actionIndex);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.ruleIndex);\n      hash = MurmurHash.update(hash, this.actionIndex);\n      this.#cachedHashCode = MurmurHash.finish(hash, 3);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerCustomAction)) {\n      return false;\n    }\n    return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n  }\n};\n\n// src/atn/LexerMoreAction.ts\nvar LexerMoreAction = class _LexerMoreAction {\n  static {\n    __name(this, \"LexerMoreAction\");\n  }\n  static instance = new _LexerMoreAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.MORE;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.MORE;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.popMode}.\n   */\n  execute(lexer) {\n    lexer.more();\n  }\n  toString() {\n    return \"more\";\n  }\n};\n\n// src/atn/LexerTypeAction.ts\nvar LexerTypeAction = class _LexerTypeAction {\n  static {\n    __name(this, \"LexerTypeAction\");\n  }\n  type;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(type) {\n    this.actionType = LexerActionType.TYPE;\n    this.type = type;\n  }\n  execute(lexer) {\n    lexer.type = this.type;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.type);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerTypeAction)) {\n      return false;\n    }\n    return this.type === other.type;\n  }\n  toString() {\n    return \"type(\" + this.type + \")\";\n  }\n};\n\n// src/atn/LexerPushModeAction.ts\nvar LexerPushModeAction = class _LexerPushModeAction {\n  static {\n    __name(this, \"LexerPushModeAction\");\n  }\n  mode;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(mode) {\n    this.actionType = LexerActionType.PUSH_MODE;\n    this.mode = mode;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.pushMode} with the\n   * value provided by {@link getMode}.\n   */\n  execute(lexer) {\n    lexer.pushMode(this.mode);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.mode);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerPushModeAction)) {\n      return false;\n    }\n    return this.mode === other.mode;\n  }\n  toString() {\n    return \"pushMode(\" + this.mode + \")\";\n  }\n};\n\n// src/atn/LexerPopModeAction.ts\nvar LexerPopModeAction = class _LexerPopModeAction {\n  static {\n    __name(this, \"LexerPopModeAction\");\n  }\n  static instance = new _LexerPopModeAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.POP_MODE;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.POP_MODE;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer//popMode}.\n   */\n  execute(lexer) {\n    lexer.popMode();\n  }\n  toString() {\n    return \"popMode\";\n  }\n};\n\n// src/atn/LexerModeAction.ts\nvar LexerModeAction = class _LexerModeAction {\n  static {\n    __name(this, \"LexerModeAction\");\n  }\n  mode;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(mode) {\n    this.actionType = LexerActionType.MODE;\n    this.mode = mode;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.mode} with the\n   * value provided by {@link getMode}.\n   */\n  execute(lexer) {\n    lexer.mode = this.mode;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.mode);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerModeAction)) {\n      return false;\n    }\n    return this.mode === other.mode;\n  }\n  toString() {\n    return \"mode(\" + this.mode + \")\";\n  }\n};\n\n// src/atn/ATNDeserializer.ts\nvar ATNDeserializer = class _ATNDeserializer {\n  static {\n    __name(this, \"ATNDeserializer\");\n  }\n  static SERIALIZED_VERSION = 4;\n  static stateTypeMapper = /* @__PURE__ */ new Map([\n    [ATNState.INVALID_TYPE, void 0],\n    [ATNState.BASIC, BasicState],\n    [ATNState.RULE_START, RuleStartState],\n    [ATNState.BLOCK_START, BasicBlockStartState],\n    [ATNState.PLUS_BLOCK_START, PlusBlockStartState],\n    [ATNState.STAR_BLOCK_START, StarBlockStartState],\n    [ATNState.TOKEN_START, TokensStartState],\n    [ATNState.RULE_STOP, RuleStopState],\n    [ATNState.BLOCK_END, BlockEndState],\n    [ATNState.STAR_LOOP_BACK, StarLoopbackState],\n    [ATNState.STAR_LOOP_ENTRY, StarLoopEntryState],\n    [ATNState.PLUS_LOOP_BACK, PlusLoopbackState],\n    [ATNState.LOOP_END, LoopEndState]\n  ]);\n  static lexerActionFactoryMapper = /* @__PURE__ */ new Map([\n    [LexerActionType.CHANNEL, (data1) => {\n      return new LexerChannelAction(data1);\n    }],\n    [LexerActionType.CUSTOM, (data1, data2) => {\n      return new LexerCustomAction(data1, data2);\n    }],\n    [LexerActionType.MODE, (data1) => {\n      return new LexerModeAction(data1);\n    }],\n    [LexerActionType.MORE, () => {\n      return LexerMoreAction.instance;\n    }],\n    [LexerActionType.POP_MODE, () => {\n      return LexerPopModeAction.instance;\n    }],\n    [LexerActionType.PUSH_MODE, (data1) => {\n      return new LexerPushModeAction(data1);\n    }],\n    [LexerActionType.SKIP, () => {\n      return LexerSkipAction.instance;\n    }],\n    [LexerActionType.TYPE, (data1) => {\n      return new LexerTypeAction(data1);\n    }]\n  ]);\n  data = [];\n  pos = 0;\n  deserializationOptions;\n  actionFactories;\n  constructor(options) {\n    if (!options) {\n      options = { readOnly: false, verifyATN: true, generateRuleBypassTransitions: false };\n    }\n    this.deserializationOptions = options;\n  }\n  deserialize(data) {\n    this.data = data;\n    this.checkVersion();\n    const atn = this.readATN();\n    this.readStates(atn);\n    this.readRules(atn);\n    this.readModes(atn);\n    const sets = [];\n    this.readSets(atn, sets);\n    this.readEdges(atn, sets);\n    this.readDecisions(atn);\n    this.readLexerActions(atn);\n    this.markPrecedenceDecisions(atn);\n    this.verifyATN(atn);\n    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATN.PARSER) {\n      this.generateRuleBypassTransitions(atn);\n      this.verifyATN(atn);\n    }\n    return atn;\n  }\n  checkVersion() {\n    const version = this.data[this.pos++];\n    if (version !== _ATNDeserializer.SERIALIZED_VERSION) {\n      throw new Error(\"Could not deserialize ATN with version \" + version + \" (expected \" + _ATNDeserializer.SERIALIZED_VERSION + \").\");\n    }\n  }\n  readATN() {\n    const grammarType = this.data[this.pos++];\n    const maxTokenType = this.data[this.pos++];\n    return new ATN(grammarType, maxTokenType);\n  }\n  readStates(atn) {\n    let j;\n    let stateNumber;\n    const loopBackStateNumbers = [];\n    const endStateNumbers = [];\n    const stateCount = this.data[this.pos++];\n    for (let i = 0; i < stateCount; i++) {\n      const stateType = this.data[this.pos++];\n      if (stateType === ATNState.INVALID_TYPE) {\n        atn.addState(null);\n        continue;\n      }\n      const ruleIndex = this.data[this.pos++];\n      const s = this.stateFactory(stateType, ruleIndex);\n      if (stateType === ATNState.LOOP_END) {\n        const loopBackStateNumber = this.data[this.pos++];\n        loopBackStateNumbers.push([s, loopBackStateNumber]);\n      } else if (s instanceof BlockStartState) {\n        const endStateNumber = this.data[this.pos++];\n        endStateNumbers.push([s, endStateNumber]);\n      }\n      atn.addState(s);\n    }\n    for (j = 0; j < loopBackStateNumbers.length; j++) {\n      const pair = loopBackStateNumbers[j];\n      pair[0].loopBackState = atn.states[pair[1]] ?? void 0;\n    }\n    for (j = 0; j < endStateNumbers.length; j++) {\n      const pair = endStateNumbers[j];\n      pair[0].endState = atn.states[pair[1]];\n    }\n    const numNonGreedyStates = this.data[this.pos++];\n    for (j = 0; j < numNonGreedyStates; j++) {\n      stateNumber = this.data[this.pos++];\n      atn.states[stateNumber].nonGreedy = true;\n    }\n    const numPrecedenceStates = this.data[this.pos++];\n    for (j = 0; j < numPrecedenceStates; j++) {\n      stateNumber = this.data[this.pos++];\n      atn.states[stateNumber].isLeftRecursiveRule = true;\n    }\n  }\n  readRules(atn) {\n    let i;\n    const ruleCount = this.data[this.pos++];\n    if (atn.grammarType === ATN.LEXER) {\n      atn.ruleToTokenType = new Array(ruleCount);\n      atn.ruleToTokenType.fill(0);\n    }\n    atn.ruleToStartState = new Array(ruleCount);\n    atn.ruleToStartState.fill(null);\n    for (i = 0; i < ruleCount; i++) {\n      const s = this.data[this.pos++];\n      atn.ruleToStartState[i] = atn.states[s];\n      if (atn.grammarType === ATN.LEXER) {\n        const tokenType = this.data[this.pos++];\n        atn.ruleToTokenType[i] = tokenType;\n      }\n    }\n    atn.ruleToStopState = new Array(ruleCount);\n    atn.ruleToStopState.fill(null);\n    for (i = 0; i < atn.states.length; i++) {\n      const state = atn.states[i];\n      if (!(state instanceof RuleStopState)) {\n        continue;\n      }\n      atn.ruleToStopState[state.ruleIndex] = state;\n      atn.ruleToStartState[state.ruleIndex].stopState = state;\n    }\n  }\n  readModes(atn) {\n    const modeCount = this.data[this.pos++];\n    for (let i = 0; i < modeCount; i++) {\n      const s = this.data[this.pos++];\n      atn.modeToStartState.push(atn.states[s]);\n    }\n  }\n  readSets(atn, sets) {\n    const m2 = this.data[this.pos++];\n    for (let i = 0; i < m2; i++) {\n      const intervalSet = new IntervalSet();\n      sets.push(intervalSet);\n      const n2 = this.data[this.pos++];\n      const containsEof = this.data[this.pos++];\n      if (containsEof !== 0) {\n        intervalSet.addOne(-1);\n      }\n      for (let j = 0; j < n2; j++) {\n        const i1 = this.data[this.pos++];\n        const i2 = this.data[this.pos++];\n        intervalSet.addRange(i1, i2);\n      }\n    }\n  }\n  readEdges(atn, sets) {\n    let i;\n    let j;\n    let state;\n    let trans;\n    let target;\n    const edgeCount = this.data[this.pos++];\n    for (i = 0; i < edgeCount; i++) {\n      const src = this.data[this.pos++];\n      const trg = this.data[this.pos++];\n      const ttype = this.data[this.pos++];\n      const arg1 = this.data[this.pos++];\n      const arg2 = this.data[this.pos++];\n      const arg3 = this.data[this.pos++];\n      trans = this.edgeFactory(atn, ttype, trg, arg1, arg2, arg3, sets);\n      const srcState = atn.states[src];\n      srcState.addTransition(trans);\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (j = 0; j < state.transitions.length; j++) {\n        const t = state.transitions[j];\n        if (!(t instanceof RuleTransition)) {\n          continue;\n        }\n        let outermostPrecedenceReturn = -1;\n        if (atn.ruleToStartState[t.target.ruleIndex].isLeftRecursiveRule) {\n          if (t.precedence === 0) {\n            outermostPrecedenceReturn = t.target.ruleIndex;\n          }\n        }\n        trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n        atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n      }\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      if (state instanceof BlockStartState) {\n        if (!state.endState) {\n          throw new Error(\"IllegalState\");\n        }\n        if (state.endState.startState) {\n          throw new Error(\"IllegalState\");\n        }\n        state.endState.startState = state;\n      }\n      if (state instanceof PlusLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof PlusBlockStartState) {\n            target.loopBackState = state;\n          }\n        }\n      } else if (state instanceof StarLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof StarLoopEntryState) {\n            target.loopBackState = state;\n          }\n        }\n      }\n    }\n  }\n  readDecisions(atn) {\n    const decisionCount = this.data[this.pos++];\n    for (let i = 0; i < decisionCount; i++) {\n      const s = this.data[this.pos++];\n      const decState = atn.states[s];\n      atn.decisionToState.push(decState);\n      decState.decision = i;\n    }\n  }\n  readLexerActions(atn) {\n    if (atn.grammarType === ATN.LEXER) {\n      const count = this.data[this.pos++];\n      atn.lexerActions = [];\n      for (let i = 0; i < count; i++) {\n        const actionType = this.data[this.pos++];\n        const data1 = this.data[this.pos++];\n        const data2 = this.data[this.pos++];\n        atn.lexerActions.push(this.lexerActionFactory(actionType, data1, data2));\n      }\n    }\n  }\n  generateRuleBypassTransitions(atn) {\n    let i;\n    const count = atn.ruleToStartState.length;\n    for (i = 0; i < count; i++) {\n      atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n    }\n    for (i = 0; i < count; i++) {\n      this.generateRuleBypassTransition(atn, i);\n    }\n  }\n  generateRuleBypassTransition(atn, idx) {\n    let i;\n    let state;\n    const bypassStart = new BasicBlockStartState();\n    bypassStart.ruleIndex = idx;\n    atn.addState(bypassStart);\n    const bypassStop = new BlockEndState();\n    bypassStop.ruleIndex = idx;\n    atn.addState(bypassStop);\n    bypassStart.endState = bypassStop;\n    atn.defineDecisionState(bypassStart);\n    bypassStop.startState = bypassStart;\n    let excludeTransition = null;\n    let endState = null;\n    if (atn.ruleToStartState[idx].isLeftRecursiveRule) {\n      endState = null;\n      for (i = 0; i < atn.states.length; i++) {\n        state = atn.states[i];\n        if (this.stateIsEndStateFor(state, idx)) {\n          endState = state;\n          excludeTransition = state.loopBackState.transitions[0];\n          break;\n        }\n      }\n      if (excludeTransition === null) {\n        throw new Error(\"Couldn't identify final state of the precedence rule prefix section.\");\n      }\n    } else {\n      endState = atn.ruleToStopState[idx];\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (const transition of state.transitions) {\n        if (transition === excludeTransition) {\n          continue;\n        }\n        if (transition.target === endState) {\n          transition.target = bypassStop;\n        }\n      }\n    }\n    const ruleToStartState = atn.ruleToStartState[idx];\n    const count = ruleToStartState.transitions.length;\n    while (count > 0) {\n      bypassStart.addTransition(ruleToStartState.transitions[count - 1]);\n      ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n    }\n    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n    if (endState) {\n      bypassStop.addTransition(new EpsilonTransition(endState));\n    }\n    const matchState = new BasicState();\n    atn.addState(matchState);\n    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n    bypassStart.addTransition(new EpsilonTransition(matchState));\n  }\n  stateIsEndStateFor(state, idx) {\n    if (state.ruleIndex !== idx) {\n      return null;\n    }\n    if (!(state instanceof StarLoopEntryState)) {\n      return null;\n    }\n    const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n    if (!(maybeLoopEndState instanceof LoopEndState)) {\n      return null;\n    }\n    if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transitions[0].target instanceof RuleStopState) {\n      return state;\n    } else {\n      return null;\n    }\n  }\n  /**\n   * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n   * the {@link StarLoopEntryState} field to the correct value.\n   *\n   * @param atn The ATN.\n   */\n  markPrecedenceDecisions(atn) {\n    for (const state of atn.states) {\n      if (!(state instanceof StarLoopEntryState)) {\n        continue;\n      }\n      if (atn.ruleToStartState[state.ruleIndex].isLeftRecursiveRule) {\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (maybeLoopEndState instanceof LoopEndState) {\n          if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transitions[0].target instanceof RuleStopState) {\n            state.precedenceRuleDecision = true;\n          }\n        }\n      }\n    }\n  }\n  verifyATN(atn) {\n    if (!this.deserializationOptions.verifyATN) {\n      return;\n    }\n    for (const state of atn.states) {\n      if (state === null) {\n        continue;\n      }\n      this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n      if (state instanceof PlusBlockStartState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof StarLoopEntryState) {\n        this.checkCondition(state.loopBackState !== null);\n        this.checkCondition(state.transitions.length === 2);\n        if (state.transitions[0].target instanceof StarBlockStartState) {\n          this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n          this.checkCondition(!state.nonGreedy);\n        } else if (state.transitions[0].target instanceof LoopEndState) {\n          this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n          this.checkCondition(state.nonGreedy);\n        } else {\n          throw new Error(\"IllegalState\");\n        }\n      } else if (state instanceof StarLoopbackState) {\n        this.checkCondition(state.transitions.length === 1);\n        this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n      } else if (state instanceof LoopEndState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof RuleStartState) {\n        this.checkCondition(state.stopState !== null);\n      } else if (state instanceof BlockStartState) {\n        this.checkCondition(state.endState !== null);\n      } else if (state instanceof BlockEndState) {\n        this.checkCondition(state.startState !== null);\n      } else if (state instanceof DecisionState) {\n        this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n      } else {\n        this.checkCondition(state.transitions.length <= 1 || state instanceof RuleStopState);\n      }\n    }\n  }\n  checkCondition(condition, message) {\n    if (!condition) {\n      if (message === void 0 || message === null) {\n        message = \"IllegalState\";\n      }\n      throw message;\n    }\n  }\n  edgeFactory(atn, type, trg, arg1, arg2, arg3, sets) {\n    const target = atn.states[trg];\n    switch (type) {\n      case Transition.EPSILON:\n        return new EpsilonTransition(target);\n      case Transition.RANGE:\n        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n      case Transition.RULE:\n        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n      case Transition.PREDICATE:\n        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.PRECEDENCE:\n        return new PrecedencePredicateTransition(target, arg1);\n      case Transition.ATOM:\n        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n      case Transition.ACTION:\n        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.SET:\n        return new SetTransition(target, sets[arg1]);\n      case Transition.NOT_SET:\n        return new NotSetTransition(target, sets[arg1]);\n      case Transition.WILDCARD:\n        return new WildcardTransition(target);\n      default:\n        throw new Error(\"The specified transition type: \" + type + \" is not valid.\");\n    }\n  }\n  stateFactory(type, ruleIndex) {\n    const ctor = _ATNDeserializer.stateTypeMapper.get(type);\n    if (!ctor) {\n      throw new Error(\"The specified state type \" + type + \" is not valid.\");\n    }\n    const s = new ctor();\n    s.ruleIndex = ruleIndex;\n    return s;\n  }\n  lexerActionFactory(type, data1, data2) {\n    const factory = _ATNDeserializer.lexerActionFactoryMapper.get(type);\n    if (!factory) {\n      throw new Error(\"The specified lexer action type \" + type + \" is not valid.\");\n    }\n    return factory(data1, data2);\n  }\n};\n\n// src/misc/OrderedHashMap.ts\nvar OrderedHashMap = class _OrderedHashMap extends HashMap {\n  static {\n    __name(this, \"OrderedHashMap\");\n  }\n  #keys = [];\n  clear() {\n    super.clear();\n    this.#keys = [];\n  }\n  get(key) {\n    return super.get(key);\n  }\n  set(key, value) {\n    const result = super.set(key, value);\n    if (result === void 0) {\n      this.#keys.push(key);\n    }\n    return result;\n  }\n  setIfAbsent(key, value) {\n    const result = super.setIfAbsent(key, value);\n    if (result === void 0) {\n      this.#keys.push(key);\n    }\n    return result;\n  }\n  /**\n   * @returns an iterable of the values in the map, in the order they were inserted.\n   */\n  values() {\n    return {\n      [Symbol.iterator]: () => {\n        let index = 0;\n        return {\n          next: /* @__PURE__ */ __name(() => {\n            if (index < this.#keys.length) {\n              return {\n                done: false,\n                value: super.get(this.#keys[index++])\n              };\n            }\n            return {\n              done: true,\n              value: void 0\n            };\n          }, \"next\")\n        };\n      }\n    };\n  }\n  /**\n   * @returns an iterable of the keys in the map, in the order they were inserted.\n   */\n  keys() {\n    return this.#keys[Symbol.iterator]();\n  }\n  equals(o) {\n    if (!(o instanceof _OrderedHashMap)) {\n      return false;\n    }\n    return super.equals(o);\n  }\n};\n\n// src/atn/ATNSerializer.ts\nvar ATNSerializer = class _ATNSerializer {\n  static {\n    __name(this, \"ATNSerializer\");\n  }\n  atn;\n  data = [];\n  // Note that we use a LinkedHashMap as a set to maintain insertion order while deduplicating entries with the\n  // same key.\n  sets = new OrderedHashMap(ObjectEqualityComparator.instance);\n  nonGreedyStates = [];\n  precedenceStates = [];\n  constructor(atn) {\n    this.atn = atn;\n  }\n  static getSerialized(atn) {\n    return new _ATNSerializer(atn).serialize();\n  }\n  static serializeSets(data, sets) {\n    data.push(sets.length);\n    for (const set of sets) {\n      const containsEof = set.contains(Token.EOF);\n      const intervals = [...set];\n      if (containsEof && intervals[0].stop === Token.EOF) {\n        data.push(intervals.length - 1);\n      } else {\n        data.push(intervals.length);\n      }\n      data.push(containsEof ? 1 : 0);\n      for (const interval of intervals) {\n        if (interval.start === Token.EOF) {\n          if (interval.stop === Token.EOF) {\n            continue;\n          } else {\n            data.push(0);\n          }\n        } else {\n          data.push(interval.start);\n        }\n        data.push(interval.stop);\n      }\n    }\n  }\n  /**\n   * Serialize state descriptors, edge descriptors, and decision -> state map\n   *  into list of ints.  Likely out of date, but keeping as it could be helpful:\n   *\n   *      SERIALIZED_VERSION\n   *      UUID (2 longs)\n   * \t\tgrammar-type, (ANTLRParser.LEXER, ...)\n   *  \tmax token type,\n   *  \tnum states,\n   *  \tstate-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ...\n   *  \tnum rules,\n   *  \trule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ...\n   *  \t(args are token type,actionIndex in lexer else 0,0)\n   *      num modes,\n   *      mode-0-start-state, mode-1-start-state, ... (parser has 0 modes)\n   *      num unicode-bmp-sets\n   *      bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ...\n   *      num unicode-smp-sets\n   *      smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ...\n   *\tnum total edges,\n   *      src, trg, edge-type, edge arg1, optional edge arg2 (present always), ...\n   *      num decisions,\n   *      decision-0-start-state, decision-1-start-state, ...\n   *\n   *  Convenient to pack into unsigned shorts to make as Java string.\n   */\n  serialize() {\n    this.addPreamble();\n    const edgeCount = this.addEdges();\n    this.addNonGreedyStates();\n    this.addPrecedenceStates();\n    this.addRuleStatesAndLexerTokenTypes();\n    this.addModeStartStates();\n    const setIndices = this.addSets();\n    this.addEdges(edgeCount, setIndices);\n    this.addDecisionStartStates();\n    this.addLexerActions();\n    return this.data;\n  }\n  addPreamble() {\n    this.data.push(ATNDeserializer.SERIALIZED_VERSION);\n    this.data.push(this.atn.grammarType);\n    this.data.push(this.atn.maxTokenType);\n  }\n  addLexerActions() {\n    if (this.atn.grammarType === ATN.LEXER) {\n      this.data.push(this.atn.lexerActions.length);\n      for (const action of this.atn.lexerActions) {\n        this.data.push(action.actionType);\n        switch (action.actionType) {\n          case LexerActionType.CHANNEL: {\n            const channel = action.channel;\n            this.data.push(channel);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.CUSTOM: {\n            const ruleIndex = action.ruleIndex;\n            const actionIndex = action.actionIndex;\n            this.data.push(ruleIndex);\n            this.data.push(actionIndex);\n            break;\n          }\n          case LexerActionType.MODE: {\n            const mode = action.mode;\n            this.data.push(mode);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.MORE: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.POP_MODE: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.PUSH_MODE: {\n            const mode = action.mode;\n            this.data.push(mode);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.SKIP: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.TYPE: {\n            const type = action.type;\n            this.data.push(type);\n            this.data.push(0);\n            break;\n          }\n          default: {\n            throw new Error(`The specified lexer action type ${action.actionType} is not valid.`);\n          }\n        }\n      }\n    }\n  }\n  addDecisionStartStates() {\n    this.data.push(this.atn.decisionToState.length);\n    for (const decStartState of this.atn.decisionToState) {\n      this.data.push(decStartState.stateNumber);\n    }\n  }\n  addEdges(...args) {\n    switch (args.length) {\n      case 0: {\n        let edgeCount = 0;\n        this.data.push(this.atn.states.length);\n        let i = 0;\n        for (const s of this.atn.states) {\n          if (s === null) {\n            this.data.push(ATNState.INVALID_TYPE);\n            continue;\n          }\n          const stateType = s.constructor.stateType;\n          if (s instanceof DecisionState && s.nonGreedy) {\n            this.nonGreedyStates.push(s.stateNumber);\n          }\n          if (i === 910) {\n            console.log(\"i\", i);\n          }\n          if (s instanceof RuleStartState && s.isLeftRecursiveRule) {\n            this.precedenceStates.push(s.stateNumber);\n          }\n          this.data.push(stateType);\n          this.data.push(s.ruleIndex);\n          if (s.constructor.stateType === ATNState.LOOP_END) {\n            this.data.push(s.loopBackState.stateNumber);\n          } else {\n            if (s instanceof BlockStartState) {\n              this.data.push(s.endState.stateNumber);\n            }\n          }\n          if (s.constructor.stateType !== ATNState.RULE_STOP) {\n            edgeCount += s.transitions.length;\n          }\n          for (const t of s.transitions) {\n            const edgeType = t.transitionType;\n            if (edgeType === Transition.SET || edgeType === Transition.NOT_SET) {\n              const st = t;\n              this.sets.set(st.set, true);\n            }\n          }\n          ++i;\n        }\n        return edgeCount;\n      }\n      case 2: {\n        const [edgeCount, setIndices] = args;\n        this.data.push(edgeCount);\n        for (const s of this.atn.states) {\n          if (s === null) {\n            continue;\n          }\n          if (s.constructor.stateType === ATNState.RULE_STOP) {\n            continue;\n          }\n          for (const t of s.transitions) {\n            if (this.atn.states[t.target.stateNumber] === null) {\n              throw new Error(\"Cannot serialize a transition to a removed state.\");\n            }\n            const src = s.stateNumber;\n            let trg = t.target.stateNumber;\n            const edgeType = t.transitionType;\n            let arg1 = 0;\n            let arg2 = 0;\n            let arg3 = 0;\n            switch (edgeType) {\n              case Transition.RULE: {\n                trg = t.followState.stateNumber;\n                arg1 = t.target.stateNumber;\n                arg2 = t.ruleIndex;\n                arg3 = t.precedence;\n                break;\n              }\n              case Transition.PRECEDENCE: {\n                const ppt = t;\n                arg1 = ppt.precedence;\n                break;\n              }\n              case Transition.PREDICATE: {\n                const pt = t;\n                arg1 = pt.ruleIndex;\n                arg2 = pt.predIndex;\n                arg3 = pt.isCtxDependent ? 1 : 0;\n                break;\n              }\n              case Transition.RANGE: {\n                arg1 = t.start;\n                arg2 = t.stop;\n                if (arg1 === Token.EOF) {\n                  arg1 = 0;\n                  arg3 = 1;\n                }\n                break;\n              }\n              case Transition.ATOM: {\n                arg1 = t.labelValue;\n                if (arg1 === Token.EOF) {\n                  arg1 = 0;\n                  arg3 = 1;\n                }\n                break;\n              }\n              case Transition.ACTION: {\n                const at = t;\n                arg1 = at.ruleIndex;\n                arg2 = at.actionIndex;\n                arg3 = at.isCtxDependent ? 1 : 0;\n                break;\n              }\n              case Transition.SET: {\n                arg1 = setIndices.get(t.set);\n                break;\n              }\n              case Transition.NOT_SET: {\n                arg1 = setIndices.get(t.set);\n                break;\n              }\n              case Transition.WILDCARD: {\n                break;\n              }\n              default:\n            }\n            this.data.push(src);\n            this.data.push(trg);\n            this.data.push(edgeType);\n            this.data.push(arg1);\n            this.data.push(arg2);\n            this.data.push(arg3);\n          }\n        }\n        break;\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  addSets() {\n    _ATNSerializer.serializeSets(this.data, [...this.sets.keys()]);\n    const setIndices = new HashMap();\n    let setIndex = 0;\n    for (const s of this.sets.keys()) {\n      setIndices.set(s, setIndex++);\n    }\n    return setIndices;\n  }\n  addModeStartStates() {\n    const modeCount = this.atn.modeToStartState.length;\n    this.data.push(modeCount);\n    if (modeCount > 0) {\n      for (const modeStartState of this.atn.modeToStartState) {\n        this.data.push(modeStartState.stateNumber);\n      }\n    }\n  }\n  addRuleStatesAndLexerTokenTypes() {\n    const ruleCount = this.atn.ruleToStartState.length;\n    this.data.push(ruleCount);\n    for (let r = 0; r < ruleCount; r++) {\n      const ruleStartState = this.atn.ruleToStartState[r];\n      this.data.push(ruleStartState.stateNumber);\n      if (this.atn.grammarType === ATN.LEXER) {\n        this.data.push(this.atn.ruleToTokenType[r]);\n      }\n    }\n  }\n  addPrecedenceStates() {\n    this.data.push(this.precedenceStates.length);\n    for (const state of this.precedenceStates) {\n      this.data.push(state);\n    }\n  }\n  addNonGreedyStates() {\n    this.data.push(this.nonGreedyStates.length);\n    for (const state of this.nonGreedyStates) {\n      this.data.push(state);\n    }\n  }\n};\n\n// src/dfa/DFAState.ts\nvar DFAState = class _DFAState {\n  static {\n    __name(this, \"DFAState\");\n  }\n  stateNumber = -1;\n  configs;\n  /**\n   * `edges[symbol]` points to target of symbol. Shift up by 1 so (-1) {@link Token.EOF} maps to `edges[0]`.\n   */\n  edges = [];\n  isAcceptState = false;\n  /**\n   * If accept state, what ttype do we match or alt do we predict? This is set to {@link ATN.INVALID_ALT_NUMBER}\n   * when {@link predicates} `!= null` or {@link requiresFullContext}.\n   */\n  prediction = -1;\n  lexerActionExecutor = null;\n  /**\n   * Indicates that this state was created during SLL prediction that discovered a conflict between the configurations\n   * in the state. Future {@link ParserATNSimulator.execATN} invocations immediately jumped doing\n   * full context prediction if this field is true.\n   */\n  requiresFullContext = false;\n  /**\n   * During SLL parsing, this is a list of predicates associated with the ATN configurations of the DFA state.\n   * When we have predicates, {@link requiresFullContext} is `false` since full context prediction evaluates\n   * predicates on-the-fly. If this is not null, then {@link prediction} is `ATN.INVALID_ALT_NUMBER`.\n   *\n   * We only use these for non-{@link #requiresFullContext} but conflicting states. That\n   * means we know from the context (it's $ or we don't dip into outer\n   * context) that it's an ambiguity not a conflict.\n   *\n   * This list is computed by {@link ParserATNSimulator#predicateDFAState}.\n   */\n  predicates = null;\n  constructor(configs) {\n    if (configs) {\n      this.configs = configs;\n    }\n  }\n  static fromState(stateNumber) {\n    const result = new _DFAState();\n    result.stateNumber = stateNumber;\n    return result;\n  }\n  static fromConfigs(configs) {\n    return new _DFAState(configs);\n  }\n  static hashCode(state) {\n    return state.configs.hashCode();\n  }\n  /**\n   * Two {@link DFAState} instances are equal if their ATN configuration sets\n   * are the same. This method is used to see if a state already exists.\n   *\n   * Because the number of alternatives and number of ATN configurations are\n   * finite, there is a finite number of DFA states that can be processed.\n   * This is necessary to show that the algorithm terminates.\n   *\n   * Cannot test the DFA state numbers here because in\n   * {@link ParserATNSimulator#addDFAState} we need to know if any other state\n   * exists that has this exact set of ATN configurations. The\n   * {@link #stateNumber} is irrelevant.\n   *\n   * @param a The first {@link DFAState}.\n   * @param b The second {@link DFAState}.\n   *\n   * @returns `true` if the two states are equal, otherwise `false`.\n   */\n  static equals(a, b) {\n    return a.configs.equals(b.configs);\n  }\n  /**\n   * @returns the set of all alts mentioned by all ATN configurations in this DFA state.\n   */\n  getAltSet() {\n    const alts = /* @__PURE__ */ new Set();\n    for (const config of this.configs) {\n      alts.add(config.alt);\n    }\n    if (alts.size === 0) {\n      return null;\n    }\n    return alts;\n  }\n  toString() {\n    let buf = \"\";\n    buf += this.stateNumber;\n    buf += \":\";\n    buf += this.configs ? this.configs.toString() : \"\";\n    if (this.isAcceptState) {\n      buf += \"=>\";\n      if (this.predicates) {\n        buf += arrayToString(this.predicates);\n      } else {\n        buf += this.prediction;\n      }\n    }\n    return buf.toString();\n  }\n};\n\n// src/atn/ATNSimulator.ts\nvar ATNSimulator = class {\n  static {\n    __name(this, \"ATNSimulator\");\n  }\n  /** Must distinguish between missing edge and edge we know leads nowhere */\n  static ERROR = DFAState.fromState(2147483647);\n  atn;\n  /**\n   * The context cache maps all PredictionContext objects that are ==\n   * to a single cached copy. This cache is shared across all contexts\n   * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n   * to use only cached nodes/graphs in addDFAState(). We don't want to\n   * fill this during closure() since there are lots of contexts that\n   * pop up but are not used ever again. It also greatly slows down closure().\n   *\n   * This cache makes a huge difference in memory and a little bit in speed.\n   * For the Java grammar on java.*, it dropped the memory requirements\n   * at the end from 25M to 16M. We don't store any of the full context\n   * graphs in the DFA because they are limited to local context only,\n   * but apparently there's a lot of repetition there as well. We optimize\n   * the config contexts before storing the config set in the DFA states\n   * by literally rebuilding them with cached subgraphs only.\n   *\n   * I tried a cache for use during closure operations, that was\n   * whacked after each adaptivePredict(). It cost a little bit\n   * more time I think and doesn't save on the overall footprint\n   * so it's not worth the complexity.\n   */\n  sharedContextCache;\n  constructor(atn, sharedContextCache) {\n    this.atn = atn;\n    this.sharedContextCache = sharedContextCache;\n    return this;\n  }\n  getCachedContext(context) {\n    if (!this.sharedContextCache) {\n      return context;\n    }\n    const visited = new HashMap(ObjectEqualityComparator.instance);\n    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n  }\n};\n\n// src/atn/CodePointTransitions.ts\nvar CodePointTransitions = class _CodePointTransitions {\n  static {\n    __name(this, \"CodePointTransitions\");\n  }\n  /** @returns new {@link AtomTransition}     */\n  static createWithCodePoint(target, codePoint) {\n    return _CodePointTransitions.createWithCodePointRange(target, codePoint, codePoint);\n  }\n  /** @returns new {@link AtomTransition} if range represents one atom else {@link SetTransition}. */\n  static createWithCodePointRange(target, codePointFrom, codePointTo) {\n    return codePointFrom === codePointTo ? new AtomTransition(target, codePointFrom) : new RangeTransition(target, codePointFrom, codePointTo);\n  }\n};\n\n// src/atn/DecisionInfo.ts\nvar DecisionInfo = class {\n  static {\n    __name(this, \"DecisionInfo\");\n  }\n  /**\n   * The decision number, which is an index into {@link ATN.decisionToState}.\n   */\n  decision = 0;\n  /**\n   * The total number of times {@link ParserATNSimulator.adaptivePredict} was\n   * invoked for this decision.\n   */\n  invocations = 0;\n  /**\n   * The total time spent in {@link ParserATNSimulator.adaptivePredict} for\n   * this decision, in nanoseconds.\n   *\n   * The value of this field contains the sum of differential results obtained\n   * by {@link process.hrtime()}, and is not adjusted to compensate for JIT\n   * and/or garbage collection overhead. For best accuracy, use a modern Node.js\n   * version that provides precise results from {@link process.hrtime()}, and\n   * perform profiling in a separate process which is warmed up by parsing the\n   * input prior to profiling.\n   */\n  timeInPrediction = 0;\n  /**\n   * The sum of the lookahead required for SLL prediction for this decision.\n   * Note that SLL prediction is used before LL prediction for performance\n   * reasons even when {@link PredictionMode.LL} or\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION} is used.\n   */\n  sllTotalLook = 0;\n  /**\n   * Gets the minimum lookahead required for any single SLL prediction to\n   * complete for this decision, by reaching a unique prediction, reaching an\n   * SLL conflict state, or encountering a syntax error.\n   */\n  sllMinLook = 0;\n  /**\n   * Gets the maximum lookahead required for any single SLL prediction to\n   * complete for this decision, by reaching a unique prediction, reaching an\n   * SLL conflict state, or encountering a syntax error.\n   */\n  sllMaxLook = 0;\n  /**\n   * Gets the {@link LookaheadEventInfo} associated with the event where the\n   * {@link sllMaxLook} value was set.\n   */\n  sllMaxLookEvent;\n  /**\n   * The sum of the lookahead required for LL prediction for this decision.\n   * Note that LL prediction is only used when SLL prediction reaches a\n   * conflict state.\n   */\n  llTotalLook = 0;\n  /**\n   * Gets the minimum lookahead required for any single LL prediction to\n   * complete for this decision. An LL prediction completes when the algorithm\n   * reaches a unique prediction, a conflict state (for\n   * {@link PredictionMode.LL}, an ambiguity state (for\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION}, or a syntax error.\n   */\n  llMinLook = 0;\n  /**\n   * Gets the maximum lookahead required for any single LL prediction to\n   * complete for this decision. An LL prediction completes when the algorithm\n   * reaches a unique prediction, a conflict state (for\n   * {@link PredictionMode.LL}, an ambiguity state (for\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION}, or a syntax error.\n   */\n  llMaxLook = 0;\n  /**\n   * Gets the {@link LookaheadEventInfo} associated with the event where the\n   * {@link llMaxLook} value was set.\n   */\n  llMaxLookEvent;\n  /**\n   * A collection of {@link ContextSensitivityInfo} instances describing the\n   * context sensitivities encountered during LL prediction for this decision.\n   */\n  contextSensitivities;\n  /**\n   * A collection of {@link DecisionEventInfo} instances describing the parse errors\n   * identified during calls to {@link ParserATNSimulator.adaptivePredict} for\n   * this decision.\n   */\n  errors;\n  /**\n   * A collection of {@link AmbiguityInfo} instances describing the\n   * ambiguities encountered during LL prediction for this decision.\n   */\n  ambiguities;\n  /**\n   * A collection of {@link PredicateEvalInfo} instances describing the\n   * results of evaluating individual predicates during prediction for this\n   * decision.\n   */\n  predicateEvals;\n  /**\n   * The total number of ATN transitions required during SLL prediction for\n   * this decision. An ATN transition is determined by the number of times the\n   * DFA does not contain an edge that is required for prediction, resulting\n   * in on-the-fly computation of that edge.\n  /**\n   * If DFA caching of SLL transitions is employed by the implementation, ATN\n   * computation may cache the computed edge for efficient lookup during\n   * future parsing of this decision. Otherwise, the SLL parsing algorithm\n   * will use ATN transitions exclusively.\n   *\n   * @see sllDFATransitions\n   * @see ParserATNSimulator.computeTargetState\n   * @see LexerATNSimulator.computeTargetState\n   */\n  sllATNTransitions = 0;\n  /**\n   * The total number of DFA transitions required during SLL prediction for\n   * this decision.\n   *\n   * If the ATN simulator implementation does not use DFA caching for SLL\n   * transitions, this value will be 0.\n   *\n   * @see ParserATNSimulator.getExistingTargetState\n   * @see LexerATNSimulator.getExistingTargetState\n   */\n  sllDFATransitions = 0;\n  /**\n   * Gets the total number of times SLL prediction completed in a conflict\n   * state, resulting in fallback to LL prediction.\n   *\n   * Note that this value is not related to whether or not\n   * {@link PredictionMode.SLL} may be used successfully with a particular\n   * grammar. If the ambiguity resolution algorithm applied to the SLL\n   * conflicts for this decision produce the same result as LL prediction for\n   * this decision, {@link PredictionMode.SLL} would produce the same overall\n   * parsing result as {@link PredictionMode.LL}.\n   */\n  llFallback = 0;\n  /**\n   * The total number of ATN transitions required during LL prediction for\n   * this decision. An ATN transition is determined by the number of times the\n   * DFA does not contain an edge that is required for prediction, resulting\n   * in on-the-fly computation of that edge.\n   *\n   * If DFA caching of LL transitions is employed by the implementation, ATN\n   * computation may cache the computed edge for efficient lookup during\n   * future parsing of this decision. Otherwise, the LL parsing algorithm will\n   * use ATN transitions exclusively.\n   *\n   * @see llDFATransitions\n   * @see ParserATNSimulator.computeTargetState\n   * @see LexerATNSimulator.computeTargetState\n   */\n  llATNTransitions = 0;\n  /**\n   * The total number of DFA transitions required during LL prediction for\n   * this decision.\n   *\n   * If the ATN simulator implementation does not use DFA caching for LL\n   * transitions, this value will be 0.\n   *\n   * @see ParserATNSimulator.getExistingTargetState\n   * @see LexerATNSimulator.getExistingTargetState\n   */\n  llDFATransitions = 0;\n  /**\n   * Constructs a new instance of the {@link DecisionInfo} class to contain\n   * statistics for a particular decision.\n   *\n   * @param decision The decision number\n   */\n  constructor(decision) {\n    this.decision = decision;\n    this.contextSensitivities = [];\n    this.errors = [];\n    this.ambiguities = [];\n    this.predicateEvals = [];\n  }\n  toString1() {\n    return \"{decision=\" + this.decision + \", contextSensitivities=\" + this.contextSensitivities.length + \", errors=\" + this.errors.length + \", ambiguities=\" + this.ambiguities.length + \", sllLookahead=\" + this.sllTotalLook + \", sllATNTransitions=\" + this.sllATNTransitions + \", sllDFATransitions=\" + this.sllDFATransitions + \", llFallback=\" + this.llFallback + \", llLookahead=\" + this.llTotalLook + \", llATNTransitions=\" + this.llATNTransitions + \"}\";\n  }\n};\n\n// src/atn/LexerATNConfig.ts\nvar LexerATNConfig = class _LexerATNConfig extends ATNConfig {\n  static {\n    __name(this, \"LexerATNConfig\");\n  }\n  /**\n   * This is the backing field for {@link #getLexerActionExecutor}.\n   */\n  lexerActionExecutor;\n  passedThroughNonGreedyDecision;\n  constructor(config, state, context, lexerActionExecutor) {\n    super(config, state, context ?? config.context, context ? SemanticContext.NONE : config.semanticContext);\n    this.lexerActionExecutor = context ? lexerActionExecutor : config.lexerActionExecutor ?? null;\n    this.passedThroughNonGreedyDecision = _LexerATNConfig.checkNonGreedyDecision(config, this.state);\n    return this;\n  }\n  static createWithExecutor(config, state, lexerActionExecutor) {\n    return new _LexerATNConfig(config, state, config.context, lexerActionExecutor);\n  }\n  static createWithConfig(state, config, context) {\n    return new _LexerATNConfig(config, state, context ?? null, config.lexerActionExecutor);\n  }\n  static createWithContext(state, alt, context) {\n    return new _LexerATNConfig({ alt }, state, context, null);\n  }\n  static checkNonGreedyDecision(source, target) {\n    return source.passedThroughNonGreedyDecision || \"nonGreedy\" in target && target.nonGreedy;\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      hashCode = MurmurHash.update(hashCode, this.state.stateNumber);\n      hashCode = MurmurHash.update(hashCode, this.alt);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.context);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.semanticContext);\n      hashCode = MurmurHash.update(hashCode, this.passedThroughNonGreedyDecision ? 1 : 0);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.lexerActionExecutor);\n      hashCode = MurmurHash.finish(hashCode, 6);\n      this.cachedHashCode = hashCode;\n    }\n    return this.cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    return this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision && (this.lexerActionExecutor && other.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) && super.equals(other);\n  }\n};\n\n// src/BaseErrorListener.ts\nvar BaseErrorListener = class {\n  static {\n    __name(this, \"BaseErrorListener\");\n  }\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n  }\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n  }\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n  }\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n  }\n};\n\n// src/ConsoleErrorListener.ts\nvar ConsoleErrorListener = class _ConsoleErrorListener extends BaseErrorListener {\n  static {\n    __name(this, \"ConsoleErrorListener\");\n  }\n  /**\n   * Provides a default instance of {@link ConsoleErrorListener}.\n   */\n  static instance = new _ConsoleErrorListener();\n  syntaxError(recognizer, offendingSymbol, line, charPositionInLine, msg, _e) {\n    console.error(\"line \" + line + \":\" + charPositionInLine + \" \" + msg);\n  }\n};\n\n// src/ProxyErrorListener.ts\nvar ProxyErrorListener = class extends BaseErrorListener {\n  constructor(delegates) {\n    super();\n    this.delegates = delegates;\n    return this;\n  }\n  static {\n    __name(this, \"ProxyErrorListener\");\n  }\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    this.delegates.forEach((d) => {\n      d.syntaxError(recognizer, offendingSymbol, line, column, msg, e);\n    });\n  }\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    this.delegates.forEach((d) => {\n      d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n    });\n  }\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    this.delegates.forEach((d) => {\n      d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs);\n    });\n  }\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    this.delegates.forEach((d) => {\n      d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs);\n    });\n  }\n};\n\n// src/Recognizer.ts\nvar Recognizer = class _Recognizer {\n  static {\n    __name(this, \"Recognizer\");\n  }\n  static EOF = -1;\n  static tokenTypeMapCache = /* @__PURE__ */ new Map();\n  static ruleIndexMapCache = /* @__PURE__ */ new Map();\n  interpreter;\n  #listeners = [ConsoleErrorListener.instance];\n  #stateNumber = -1;\n  checkVersion(toolVersion) {\n    const runtimeVersion = \"4.13.1\";\n    if (runtimeVersion !== toolVersion) {\n      console.error(\"ANTLR runtime and generated code versions disagree: \" + runtimeVersion + \"!=\" + toolVersion);\n    }\n  }\n  addErrorListener(listener) {\n    this.#listeners.push(listener);\n  }\n  removeErrorListeners() {\n    this.#listeners = [];\n  }\n  removeErrorListener(listener) {\n    for (let i = 0; i < this.#listeners.length; i++) {\n      if (this.#listeners[i] === listener) {\n        this.#listeners.splice(i, 1);\n        return;\n      }\n    }\n  }\n  getErrorListeners() {\n    return this.#listeners;\n  }\n  getTokenTypeMap() {\n    const vocabulary = this.vocabulary;\n    let result = _Recognizer.tokenTypeMapCache.get(vocabulary);\n    if (!result) {\n      result = /* @__PURE__ */ new Map();\n      for (let i = 0; i <= this.atn.maxTokenType; i++) {\n        const literalName = vocabulary.getLiteralName(i);\n        if (literalName) {\n          result.set(literalName, i);\n        }\n        const symbolicName = vocabulary.getSymbolicName(i);\n        if (symbolicName) {\n          result.set(symbolicName, i);\n        }\n      }\n      result.set(\"EOF\", Token.EOF);\n      _Recognizer.tokenTypeMapCache.set(vocabulary, result);\n    }\n    return result;\n  }\n  /**\n   * Get a map from rule names to rule indexes.\n   * Used for XPath and tree pattern compilation.\n   */\n  getRuleIndexMap() {\n    const ruleNames = this.ruleNames;\n    let result = _Recognizer.ruleIndexMapCache.get(ruleNames);\n    if (!result) {\n      result = /* @__PURE__ */ new Map();\n      ruleNames.forEach((ruleName, idx) => {\n        return result.set(ruleName, idx);\n      });\n      _Recognizer.ruleIndexMapCache.set(ruleNames, result);\n    }\n    return result;\n  }\n  getTokenType(tokenName) {\n    const ttype = this.getTokenTypeMap().get(tokenName);\n    if (ttype) {\n      return ttype;\n    }\n    return Token.INVALID_TYPE;\n  }\n  /** What is the error header, normally line/character position information? */\n  getErrorHeader(e) {\n    const line = e.offendingToken?.line;\n    const column = e.offendingToken?.column;\n    return \"line \" + line + \":\" + column;\n  }\n  get errorListenerDispatch() {\n    return new ProxyErrorListener(this.#listeners);\n  }\n  /**\n   * subclass needs to override these if there are semantic predicates or actions\n   * that the ATN interp needs to execute\n   */\n  sempred(_localctx, _ruleIndex, _actionIndex) {\n    return true;\n  }\n  // TODO: make localCtx an optional parameter, not optional null.\n  precpred(_localctx, _precedence) {\n    return true;\n  }\n  action(_localctx, _ruleIndex, _actionIndex) {\n  }\n  get atn() {\n    return this.interpreter.atn;\n  }\n  get state() {\n    return this.#stateNumber;\n  }\n  set state(state) {\n    this.#stateNumber = state;\n  }\n  getSerializedATN() {\n    throw new Error(\"there is no serialized ATN\");\n  }\n  getParseInfo() {\n    return void 0;\n  }\n};\n\n// src/CommonTokenFactory.ts\nvar CommonTokenFactory = class _CommonTokenFactory {\n  static {\n    __name(this, \"CommonTokenFactory\");\n  }\n  /**\n   * The default {@link CommonTokenFactory} instance.\n   *\n   *\n   * This token factory does not explicitly copy token text when constructing\n   * tokens.\n   */\n  static DEFAULT = new _CommonTokenFactory();\n  /**\n   * Indicates whether {@link CommonToken.setText} should be called after\n   * constructing tokens to explicitly set the text. This is useful for cases\n   * where the input stream might not be able to provide arbitrary substrings\n   * of text from the input after the lexer creates a token (e.g. the\n   * implementation of {@link CharStream.getText} in\n   * {@link UnbufferedCharStream} throws an\n   * {@link UnsupportedOperationException}). Explicitly setting the token text\n   * allows {@link Token.getText} to be called at any time regardless of the\n   * input stream implementation.\n   *\n   *\n   * The default value is `false` to avoid the performance and memory\n   * overhead of copying text for every token unless explicitly requested.\n   */\n  copyText = false;\n  constructor(copyText) {\n    this.copyText = copyText ?? false;\n  }\n  create(source, type, text, channel, start, stop, line, column) {\n    const t = CommonToken.fromSource(source, type, channel, start, stop);\n    t.line = line;\n    t.column = column;\n    if (text) {\n      t.text = text;\n    } else if (this.copyText && source[1] !== null) {\n      t.text = source[1].getTextFromRange(start, stop);\n    }\n    return t;\n  }\n};\n\n// src/RecognitionException.ts\nvar RecognitionException = class _RecognitionException extends Error {\n  static {\n    __name(this, \"RecognitionException\");\n  }\n  ctx;\n  /**\n   * The current {@link Token} when an error occurred. Since not all streams\n   * support accessing symbols by index, we have to track the {@link Token}\n   * instance itself\n   */\n  offendingToken = null;\n  /**\n   * Get the ATN state number the parser was in at the time the error\n   * occurred. For {@link NoViableAltException} and\n   * {@link LexerNoViableAltException} exceptions, this is the\n   * {@link DecisionState} number. For others, it is the state whose outgoing\n   * edge we couldn't match.\n   */\n  offendingState = -1;\n  recognizer;\n  input;\n  constructor(params) {\n    super(params.message);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, _RecognitionException);\n    }\n    this.message = params.message;\n    this.recognizer = params.recognizer;\n    this.input = params.input;\n    this.ctx = params.ctx;\n    if (this.recognizer !== null) {\n      this.offendingState = this.recognizer.state;\n    }\n  }\n  /**\n   * Gets the set of input symbols which could potentially follow the\n   * previously matched symbol at the time this exception was thrown.\n   *\n   * If the set of expected tokens is not known and could not be computed,\n   * this method returns `null`.\n   *\n   * @returns The set of token types that could potentially follow the current\n   * state in the ATN, or `null` if the information is not available.\n   */\n  getExpectedTokens() {\n    if (this.recognizer !== null && this.ctx !== null) {\n      return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n    } else {\n      return null;\n    }\n  }\n  // If the state number is not known, this method returns -1.\n  toString() {\n    return this.message;\n  }\n};\n\n// src/LexerNoViableAltException.ts\nvar LexerNoViableAltException = class extends RecognitionException {\n  static {\n    __name(this, \"LexerNoViableAltException\");\n  }\n  startIndex;\n  deadEndConfigs;\n  constructor(lexer, input, startIndex, deadEndConfigs) {\n    super({ message: \"\", recognizer: lexer, input, ctx: null });\n    this.startIndex = startIndex;\n    this.deadEndConfigs = deadEndConfigs;\n  }\n  toString() {\n    let symbol = \"\";\n    if (this.input && this.startIndex >= 0 && this.startIndex < this.input.size) {\n      symbol = this.input.getTextFromRange(this.startIndex, this.startIndex);\n    }\n    return \"LexerNoViableAltException\" + symbol;\n  }\n};\n\n// src/Lexer.ts\nvar Lexer = class _Lexer extends Recognizer {\n  static {\n    __name(this, \"Lexer\");\n  }\n  static DEFAULT_MODE = 0;\n  static MORE = -2;\n  static SKIP = -3;\n  static DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\n  static HIDDEN = Token.HIDDEN_CHANNEL;\n  options = {\n    minDFAEdge: 0,\n    maxDFAEdge: 256,\n    minCodePoint: 0,\n    maxCodePoint: 1114111\n  };\n  /**\n   * What character index in the stream did the current token start at?\n   *  Needed, for example, to get the text for current token.  Set at\n   *  the start of nextToken.\n   */\n  tokenStartCharIndex = -1;\n  /** The channel number for the current token */\n  channel = 0;\n  /** The token type for the current token */\n  type = 0;\n  mode = _Lexer.DEFAULT_MODE;\n  /** The start column of the current token (the one that was last read by `nextToken`). */\n  currentTokenColumn = 0;\n  /**\n   * The line on which the first character of the current token (the one that was last read by `nextToken`) resides.\n   */\n  currentTokenStartLine = 0;\n  #input;\n  /**\n   * The goal of all lexer rules/methods is to create a token object.\n   *  This is an instance variable as multiple rules may collaborate to\n   *  create a single token.  nextToken will return this object after\n   *  matching lexer rule(s).  If you subclass to allow multiple token\n   *  emissions, then set this to the last token to be matched or\n   *  something non-null so that the auto token emit mechanism will not\n   *  emit another token.\n   */\n  #token = null;\n  /**\n   * Once we see EOF on char stream, next token will be EOF.\n   * If you have DONE : EOF ; then you see DONE EOF.\n   */\n  #hitEOF = false;\n  #modeStack = [];\n  /**\n   * The text to be used for the next token. If this is not null, then the text\n   * for the next token is fixed and is not subject to change in the normal\n   * workflow of the lexer.\n   */\n  #text;\n  #factory;\n  constructor(input, options) {\n    super();\n    this.options = { ...this.options, ...options };\n    this.#input = input;\n    this.#factory = CommonTokenFactory.DEFAULT;\n  }\n  reset(seekBack = true) {\n    if (seekBack) {\n      this.#input.seek(0);\n    }\n    this.#token = null;\n    this.type = Token.INVALID_TYPE;\n    this.channel = Token.DEFAULT_CHANNEL;\n    this.tokenStartCharIndex = -1;\n    this.currentTokenColumn = -1;\n    this.currentTokenStartLine = -1;\n    this.#text = void 0;\n    this.#hitEOF = false;\n    this.mode = _Lexer.DEFAULT_MODE;\n    this.#modeStack = [];\n    this.interpreter.reset();\n  }\n  /** @returns a token from this source; i.e., match a token on the char stream. */\n  nextToken() {\n    if (this.#input === null) {\n      throw new Error(\"nextToken requires a non-null input stream.\");\n    }\n    const tokenStartMarker = this.#input.mark();\n    try {\n      while (true) {\n        if (this.#hitEOF) {\n          this.emitEOF();\n          return this.#token;\n        }\n        this.#token = null;\n        this.channel = Token.DEFAULT_CHANNEL;\n        this.tokenStartCharIndex = this.#input.index;\n        this.currentTokenColumn = this.interpreter.column;\n        this.currentTokenStartLine = this.interpreter.line;\n        this.#text = void 0;\n        let continueOuter = false;\n        while (true) {\n          this.type = Token.INVALID_TYPE;\n          let ttype = _Lexer.SKIP;\n          try {\n            ttype = this.interpreter.match(this.#input, this.mode);\n          } catch (e) {\n            if (e instanceof LexerNoViableAltException) {\n              this.notifyListeners(e);\n              this.recover(e);\n            } else {\n              throw e;\n            }\n          }\n          if (this.#input.LA(1) === Token.EOF) {\n            this.#hitEOF = true;\n          }\n          if (this.type === Token.INVALID_TYPE) {\n            this.type = ttype;\n          }\n          if (this.type === _Lexer.SKIP) {\n            continueOuter = true;\n            break;\n          }\n          if (this.type !== _Lexer.MORE) {\n            break;\n          }\n        }\n        if (continueOuter) {\n          continue;\n        }\n        if (this.#token === null) {\n          this.emit();\n        }\n        return this.#token;\n      }\n    } finally {\n      this.#input.release(tokenStartMarker);\n    }\n  }\n  /**\n   * Instruct the lexer to skip creating a token for current lexer rule\n   * and look for another token. nextToken() knows to keep looking when\n   * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n   * if token==null at end of any token rule, it creates one for you\n   * and emits it.\n   */\n  skip() {\n    this.type = _Lexer.SKIP;\n  }\n  more() {\n    this.type = _Lexer.MORE;\n  }\n  pushMode(m2) {\n    if (LexerATNSimulator.debug) {\n      console.log(\"pushMode \" + m2);\n    }\n    this.#modeStack.push(this.mode);\n    this.mode = m2;\n  }\n  popMode() {\n    if (this.#modeStack.length === 0) {\n      throw new Error(\"Empty Stack\");\n    }\n    if (LexerATNSimulator.debug) {\n      console.log(\"popMode back to \" + this.#modeStack.slice(0, -1));\n    }\n    this.mode = this.#modeStack.pop();\n    return this.mode;\n  }\n  get modeStack() {\n    return this.#modeStack;\n  }\n  /**\n   * By default does not support multiple emits per nextToken invocation\n   * for efficiency reasons. Subclass and override this method, nextToken,\n   * and getToken (to push tokens into a list and pull from that list\n   * rather than a single variable as this implementation does).\n   */\n  emitToken(token) {\n    this.#token = token;\n  }\n  /**\n   * The standard method called to automatically emit a token at the\n   * outermost lexical rule. The token object should point into the\n   * char buffer start..stop. If there is a text override in 'text',\n   * use that to set the token's text. Override this method to emit\n   * custom Token objects or provide a new factory.\n   */\n  emit() {\n    const t = this.#factory.create(\n      [this, this.#input],\n      this.type,\n      this.#text,\n      this.channel,\n      this.tokenStartCharIndex,\n      this.getCharIndex() - 1,\n      this.currentTokenStartLine,\n      this.currentTokenColumn\n    );\n    this.emitToken(t);\n    return t;\n  }\n  emitEOF() {\n    const eof = this.#factory.create(\n      [this, this.#input],\n      Token.EOF,\n      void 0,\n      Token.DEFAULT_CHANNEL,\n      this.#input.index,\n      this.#input.index - 1,\n      this.line,\n      this.column\n    );\n    this.emitToken(eof);\n    return eof;\n  }\n  /** What is the index of the current character of lookahead? */\n  getCharIndex() {\n    return this.#input.index;\n  }\n  /**\n   * Return a list of all Token objects in input char stream.\n   * Forces load of all tokens. Does not include EOF token.\n   */\n  getAllTokens() {\n    const tokens = [];\n    let t = this.nextToken();\n    while (t.type !== Token.EOF) {\n      tokens.push(t);\n      t = this.nextToken();\n    }\n    return tokens;\n  }\n  notifyListeners(e) {\n    const start = this.tokenStartCharIndex;\n    const stop = this.#input.index;\n    const text = this.#input.getTextFromRange(start, stop);\n    const msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n    this.errorListenerDispatch.syntaxError(this, null, this.currentTokenStartLine, this.currentTokenColumn, msg, e);\n  }\n  getErrorDisplay(s) {\n    return s;\n  }\n  getErrorDisplayForChar(c) {\n    if (c.charCodeAt(0) === Token.EOF) {\n      return \"<EOF>\";\n    }\n    if (c === \"\\n\") {\n      return \"\\\\n\";\n    }\n    if (c === \"\t\") {\n      return \"\\\\t\";\n    }\n    if (c === \"\\r\") {\n      return \"\\\\r\";\n    }\n    return c;\n  }\n  getCharErrorDisplay(c) {\n    return \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n  }\n  /**\n   * Lexers can normally match any char in it's vocabulary after matching\n   * a token, so do the easy thing and just kill a character and hope\n   * it all works out. You can instead use the rule invocation stack\n   * to do sophisticated error recovery if you are in a fragment rule.\n   */\n  recover(re) {\n    if (this.#input.LA(1) !== Token.EOF) {\n      if (re instanceof LexerNoViableAltException) {\n        this.interpreter.consume(this.#input);\n      } else {\n        this.#input.consume();\n      }\n    }\n  }\n  get inputStream() {\n    return this.#input;\n  }\n  set inputStream(input) {\n    this.reset(false);\n    this.#input = input;\n  }\n  set tokenFactory(factory) {\n    this.#factory = factory;\n  }\n  get tokenFactory() {\n    return this.#factory;\n  }\n  get sourceName() {\n    return this.#input.getSourceName();\n  }\n  get line() {\n    return this.interpreter.line;\n  }\n  set line(line) {\n    this.interpreter.line = line;\n  }\n  get column() {\n    return this.interpreter.column;\n  }\n  set column(column) {\n    this.interpreter.column = column;\n  }\n  get text() {\n    if (this.#text) {\n      return this.#text;\n    } else {\n      return this.interpreter.getText(this.#input);\n    }\n  }\n  set text(text) {\n    this.#text = text;\n  }\n};\n\n// src/misc/OrderedHashSet.ts\nvar OrderedHashSet = class _OrderedHashSet extends HashSet {\n  static {\n    __name(this, \"OrderedHashSet\");\n  }\n  #elements = [];\n  getOrAdd(o) {\n    const oldSize = this.size;\n    const result = super.getOrAdd(o);\n    if (this.size > oldSize) {\n      this.#elements.push(o);\n    }\n    return result;\n  }\n  equals(o) {\n    if (!(o instanceof _OrderedHashSet)) {\n      return false;\n    }\n    return super.equals(o);\n  }\n  clear() {\n    super.clear();\n    this.#elements = [];\n  }\n  *[Symbol.iterator]() {\n    yield* this.#elements;\n  }\n  toArray() {\n    return this.#elements.slice(0);\n  }\n};\n\n// src/atn/OrderedATNConfigSet.ts\nvar OrderedATNConfigSet = class extends ATNConfigSet {\n  static {\n    __name(this, \"OrderedATNConfigSet\");\n  }\n  constructor() {\n    super();\n    this.configLookup = new OrderedHashSet();\n  }\n};\n\n// src/atn/LexerIndexedCustomAction.ts\nvar LexerIndexedCustomAction = class _LexerIndexedCustomAction {\n  static {\n    __name(this, \"LexerIndexedCustomAction\");\n  }\n  offset;\n  action;\n  actionType;\n  isPositionDependent = true;\n  #cachedHashCode;\n  constructor(offset, action) {\n    this.actionType = action.actionType;\n    this.offset = offset;\n    this.action = action;\n  }\n  /**\n   * This method calls {@link execute} on the result of {@link getAction}\n   * using the provided `lexer`.\n   */\n  execute(lexer) {\n    this.action.execute(lexer);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.offset);\n      hash = MurmurHash.updateFromComparable(hash, this.action);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerIndexedCustomAction)) {\n      return false;\n    }\n    return this.offset === other.offset && this.action === other.action;\n  }\n};\n\n// src/atn/LexerActionExecutor.ts\nvar LexerActionExecutor = class _LexerActionExecutor {\n  static {\n    __name(this, \"LexerActionExecutor\");\n  }\n  lexerActions;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  /**\n   * Represents an executor for a sequence of lexer actions which traversed during\n   * the matching operation of a lexer rule (token).\n   *\n   * The executor tracks position information for position-dependent lexer actions\n   * efficiently, ensuring that actions appearing only at the end of the rule do\n   * not cause bloating of the {@link DFA} created for the lexer.\n   */\n  constructor(lexerActions) {\n    this.actionType = -1;\n    this.lexerActions = lexerActions ?? [];\n    return this;\n  }\n  /**\n   * Creates a {@link LexerActionExecutor} which executes the actions for\n   * the input `lexerActionExecutor` followed by a specified\n   * `lexerAction`.\n   *\n   * @param lexerActionExecutor The executor for actions already traversed by\n   * the lexer while matching a token within a particular\n   * {@link LexerATNConfig}. If this is `null`, the method behaves as\n   * though it were an empty executor.\n   * @param lexerAction The lexer action to execute after the actions\n   * specified in `lexerActionExecutor`.\n   *\n   * @returns {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n   * of `lexerActionExecutor` and `lexerAction`.\n   */\n  static append(lexerActionExecutor, lexerAction) {\n    if (lexerActionExecutor === null) {\n      return new _LexerActionExecutor([lexerAction]);\n    }\n    const lexerActions = lexerActionExecutor.lexerActions.concat([lexerAction]);\n    return new _LexerActionExecutor(lexerActions);\n  }\n  /**\n   * Creates a {@link LexerActionExecutor} which encodes the current offset\n   * for position-dependent lexer actions.\n   *\n   * Normally, when the executor encounters lexer actions where\n   * {@link LexerAction//isPositionDependent} returns `true`, it calls\n   * {@link IntStream.seek} on the input {@link CharStream} to set the input\n   * position to the *end* of the current token. This behavior provides\n   * for efficient DFA representation of lexer actions which appear at the end\n   * of a lexer rule, even when the lexer rule matches a variable number of\n   * characters.\n   *\n   * Prior to traversing a match transition in the ATN, the current offset\n   * from the token start index is assigned to all position-dependent lexer\n   * actions which have not already been assigned a fixed offset. By storing\n   * the offsets relative to the token start index, the DFA representation of\n   * lexer actions which appear in the middle of tokens remains efficient due\n   * to sharing among tokens of the same length, regardless of their absolute\n   * position in the input stream.\n   *\n   * If the current executor already has offsets assigned to all\n   * position-dependent lexer actions, the method returns `this`.\n   *\n   * @param offset The current offset to assign to all position-dependent\n   * lexer actions which do not already have offsets assigned.\n   *\n   * @returns {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n   * for all position-dependent lexer actions.\n   */\n  fixOffsetBeforeMatch(offset) {\n    let updatedLexerActions = null;\n    for (let i = 0; i < this.lexerActions.length; i++) {\n      if (this.lexerActions[i].isPositionDependent && !(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n        if (updatedLexerActions === null) {\n          updatedLexerActions = this.lexerActions.concat([]);\n        }\n        updatedLexerActions[i] = new LexerIndexedCustomAction(\n          offset,\n          this.lexerActions[i]\n        );\n      }\n    }\n    if (updatedLexerActions === null) {\n      return this;\n    } else {\n      return new _LexerActionExecutor(updatedLexerActions);\n    }\n  }\n  /**\n   * Execute the actions encapsulated by this executor within the context of a\n   * particular {@link Lexer}.\n   *\n   * This method calls {@link IntStream.seek} to set the position of the\n   * `input` {@link CharStream} prior to calling\n   * {@link LexerAction.execute} on a position-dependent action. Before the\n   * method returns, the input position will be restored to the same position\n   * it was in when the method was invoked.\n   *\n   * @param lexer The lexer instance.\n   * @param input The input stream which is the source for the current token.\n   * When this method is called, the current {@link IntStream.index} for\n   * `input` should be the start of the following token, i.e. 1\n   * character past the end of the current token.\n   * @param startIndex The token start index. This value may be passed to\n   * {@link IntStream.seek} to set the `input` position to the beginning\n   * of the token.\n   */\n  execute(lexer, input, startIndex) {\n    if (input === void 0 || startIndex === void 0) {\n      return;\n    }\n    let requiresSeek = false;\n    const stopIndex = input.index;\n    try {\n      for (const lexerAction of this.lexerActions) {\n        let action = lexerAction;\n        if (lexerAction instanceof LexerIndexedCustomAction) {\n          const offset = lexerAction.offset;\n          input.seek(startIndex + offset);\n          action = lexerAction.action;\n          requiresSeek = startIndex + offset !== stopIndex;\n        } else if (lexerAction.isPositionDependent) {\n          input.seek(stopIndex);\n          requiresSeek = false;\n        }\n        action.execute(lexer);\n      }\n    } finally {\n      if (requiresSeek) {\n        input.seek(stopIndex);\n      }\n    }\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      for (const lexerAction of this.lexerActions) {\n        hashCode = MurmurHash.update(hashCode, lexerAction.hashCode());\n      }\n      this.#cachedHashCode = MurmurHash.finish(hashCode, this.lexerActions.length);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.#cachedHashCode !== other.#cachedHashCode) {\n      return false;\n    }\n    if (this.lexerActions.length !== other.lexerActions.length) {\n      return false;\n    }\n    return this.lexerActions.every((action, index) => {\n      return action.equals(other.lexerActions[index]);\n    });\n  }\n};\n\n// src/dfa/DFASerializer.ts\nvar DFASerializer = class {\n  static {\n    __name(this, \"DFASerializer\");\n  }\n  dfa;\n  vocabulary;\n  constructor(dfa, vocabulary) {\n    this.dfa = dfa;\n    this.vocabulary = vocabulary;\n  }\n  toString() {\n    if (!this.dfa.s0) {\n      return \"\";\n    }\n    let buf = \"\";\n    const states = this.dfa.getStates();\n    for (const s of states) {\n      let n2 = 0;\n      n2 = s.edges.length;\n      for (let i = 0; i < n2; i++) {\n        const t = s.edges[i];\n        if (t && t.stateNumber !== 2147483647) {\n          buf += this.getStateString(s);\n          const label = this.getEdgeLabel(i);\n          buf += \"-\";\n          buf += label;\n          buf += \"->\";\n          buf += this.getStateString(t);\n          buf += \"\\n\";\n        }\n      }\n    }\n    return buf;\n  }\n  getEdgeLabel(i) {\n    const name = this.vocabulary.getDisplayName(i - 1);\n    return `${name}`;\n  }\n  getStateString(s) {\n    const n2 = s.stateNumber;\n    const baseStateStr = (s.isAcceptState ? \":\" : \"\") + \"s\" + n2 + (s.requiresFullContext ? \"^\" : \"\");\n    if (s.isAcceptState) {\n      if (s.predicates !== null) {\n        return `${baseStateStr}=>${s.predicates.toString()}`;\n      }\n      return `${baseStateStr}=>${s.prediction}`;\n    } else {\n      return `${baseStateStr}`;\n    }\n  }\n};\n\n// src/dfa/LexerDFASerializer.ts\nvar LexerDFASerializer = class extends DFASerializer {\n  static {\n    __name(this, \"LexerDFASerializer\");\n  }\n  constructor(dfa) {\n    super(dfa, Vocabulary.EMPTY_VOCABULARY);\n  }\n  getEdgeLabel = /* @__PURE__ */ __name((i) => {\n    return \"'\" + String.fromCharCode(i) + \"'\";\n  }, \"getEdgeLabel\");\n};\n\n// src/dfa/DFA.ts\nvar DFA = class {\n  static {\n    __name(this, \"DFA\");\n  }\n  s0;\n  decision;\n  /** From which ATN state did we create this DFA? */\n  atnStartState;\n  /**\n   * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special\n   * start state {@link #s0} which is not stored in {@link #states}. The\n   * {@link DFAState#edges} array for this start state contains outgoing edges\n   * supplying individual start states corresponding to specific precedence\n   * values.\n   *\n   * @returns `true` if this is a precedence DFA; otherwise, `false`.\n   */\n  isPrecedenceDfa;\n  /**\n   * A mapping from an ATNConfigSet hash to a DFAState.\n   * Used to quick look up the DFA state for a particular configuration set.\n   */\n  #states = /* @__PURE__ */ new Map();\n  constructor(atnStartState, decision) {\n    this.atnStartState = atnStartState;\n    this.decision = decision ?? 0;\n    let precedenceDfa = false;\n    if (atnStartState instanceof StarLoopEntryState) {\n      if (atnStartState.precedenceRuleDecision) {\n        precedenceDfa = true;\n        this.s0 = DFAState.fromState(-1);\n      }\n    }\n    this.isPrecedenceDfa = precedenceDfa;\n  }\n  [Symbol.iterator] = () => {\n    return this.#states.values()[Symbol.iterator]();\n  };\n  /**\n   * Get the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n    @returns The start state corresponding to the specified precedence, or\n   * `null` if no start state exists for the specified precedence.\n   *\n   * @throws IllegalStateException if this is not a precedence DFA.\n   * @see #isPrecedenceDfa\n   */\n  getPrecedenceStartState = /* @__PURE__ */ __name((precedence) => {\n    if (!this.isPrecedenceDfa) {\n      throw new Error(`Only precedence DFAs may contain a precedence start state.`);\n    }\n    if (!this.s0 || !this.s0.edges || precedence < 0 || precedence >= this.s0.edges.length) {\n      return void 0;\n    }\n    return this.s0.edges[precedence];\n  }, \"getPrecedenceStartState\");\n  /**\n   * Set the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n   * @param startState The start state corresponding to the specified precedence.\n   */\n  setPrecedenceStartState = /* @__PURE__ */ __name((precedence, startState) => {\n    if (!this.isPrecedenceDfa) {\n      throw new Error(`Only precedence DFAs may contain a precedence start state.`);\n    }\n    if (precedence < 0 || !this.s0) {\n      return;\n    }\n    this.s0.edges[precedence] = startState;\n  }, \"setPrecedenceStartState\");\n  /**\n   * @returns a list of all states in this DFA, ordered by state number.\n   */\n  getStates() {\n    const result = [...this.#states.values()];\n    result.sort((o1, o2) => {\n      return o1.stateNumber - o2.stateNumber;\n    });\n    return result;\n  }\n  getState(state) {\n    return this.#states.get(state.configs.hashCode()) ?? null;\n  }\n  getStateForConfigs(configs) {\n    return this.#states.get(configs.hashCode()) ?? null;\n  }\n  addState(state) {\n    const hash = state.configs.hashCode();\n    if (this.#states.has(hash)) {\n      return;\n    }\n    this.#states.set(hash, state);\n    state.stateNumber = this.#states.size - 1;\n  }\n  toString(vocabulary) {\n    if (!vocabulary) {\n      return this.toString(Vocabulary.EMPTY_VOCABULARY);\n    }\n    if (!this.s0) {\n      return \"\";\n    }\n    const serializer = new DFASerializer(this, vocabulary);\n    return serializer.toString() ?? \"\";\n  }\n  toLexerString() {\n    if (!this.s0) {\n      return \"\";\n    }\n    const serializer = new LexerDFASerializer(this);\n    return serializer.toString() ?? \"\";\n  }\n  get length() {\n    return this.#states.size;\n  }\n};\n\n// src/atn/LexerATNSimulator.ts\nvar LexerATNSimulator = class _LexerATNSimulator extends ATNSimulator {\n  static {\n    __name(this, \"LexerATNSimulator\");\n  }\n  static debug = false;\n  decisionToDFA;\n  recognizer = null;\n  /**\n   * The current token's starting index into the character stream.\n   *  Shared across DFA to ATN simulation in case the ATN fails and the\n   *  DFA did not have a previous accept state. In this case, we use the\n   *  ATN-generated exception object.\n   */\n  startIndex = -1;\n  /** line number 1..n within the input */\n  line = 1;\n  /** The index of the character relative to the beginning of the line 0..n-1 */\n  column = 0;\n  mode = Lexer.DEFAULT_MODE;\n  /** Used during DFA/ATN exec to record the most recent accept configuration info */\n  #prevAccept;\n  #options;\n  /** Lookup table for lexer ATN config creation. */\n  #lexerATNConfigFactory;\n  /**\n   * When we hit an accept state in either the DFA or the ATN, we\n   * have to notify the character stream to start buffering characters\n   * via {@link IntStream//mark} and record the current state. The current sim state\n   * includes the current index into the input, the current line,\n   * and current character position in that line. Note that the Lexer is\n   * tracking the starting line and characterization of the token. These\n   * variables track the \"state\" of the simulator when it hits an accept state.\n   *\n   * We track these variables separately for the DFA and ATN simulation\n   * because the DFA simulation often has to fail over to the ATN\n   * simulation. If the ATN simulation fails, we need the DFA to fall\n   * back to its previously accepted state, if any. If the ATN succeeds,\n   * then the ATN does the accept and the DFA simulator that invoked it\n   * can simply return the predicted token type.\n   */\n  constructor(recog, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.decisionToDFA = decisionToDFA;\n    this.recognizer = recog;\n    if (recog) {\n      this.#options = recog.options;\n    }\n  }\n  match(input, mode) {\n    this.mode = mode;\n    const mark = input.mark();\n    try {\n      this.startIndex = input.index;\n      this.#prevAccept = void 0;\n      const dfa = this.decisionToDFA[mode];\n      if (!dfa.s0) {\n        return this.matchATN(input);\n      }\n      return this.execATN(input, dfa.s0);\n    } finally {\n      input.release(mark);\n    }\n  }\n  reset() {\n    this.#prevAccept = void 0;\n    this.startIndex = -1;\n    this.line = 1;\n    this.column = 0;\n    this.mode = Lexer.DEFAULT_MODE;\n  }\n  clearDFA() {\n    for (let d = 0; d < this.decisionToDFA.length; d++) {\n      this.decisionToDFA[d] = new DFA(this.atn.getDecisionState(d), d);\n    }\n  }\n  getDFA(mode) {\n    return this.decisionToDFA[mode];\n  }\n  /** @returns the text matched so far for the current token. */\n  getText(input) {\n    return input.getTextFromRange(this.startIndex, input.index - 1);\n  }\n  consume(input) {\n    const curChar = input.LA(1);\n    if (curChar === \"\\n\".charCodeAt(0)) {\n      this.line += 1;\n      this.column = 0;\n    } else {\n      this.column += 1;\n    }\n    input.consume();\n  }\n  getTokenName(tt) {\n    if (tt === Token.EOF) {\n      return \"EOF\";\n    } else {\n      return \"'\" + String.fromCharCode(tt) + \"'\";\n    }\n  }\n  matchATN(input) {\n    const startState = this.atn.modeToStartState[this.mode];\n    if (_LexerATNSimulator.debug) {\n      console.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n    }\n    const oldMode = this.mode;\n    const s0Closure = this.computeStartState(input, startState);\n    const suppressEdge = s0Closure.hasSemanticContext;\n    s0Closure.hasSemanticContext = false;\n    const next = this.addDFAState(s0Closure);\n    if (!suppressEdge) {\n      this.decisionToDFA[this.mode].s0 = next;\n    }\n    const predict = this.execATN(input, next);\n    if (_LexerATNSimulator.debug) {\n      console.log(\"DFA after matchATN: \" + this.decisionToDFA[oldMode].toLexerString());\n    }\n    return predict;\n  }\n  execATN(input, state) {\n    if (_LexerATNSimulator.debug) {\n      console.log(\"start state closure=\" + state.configs);\n    }\n    if (state.isAcceptState) {\n      this.captureSimState(input, state);\n    }\n    let t = input.LA(1);\n    while (true) {\n      if (_LexerATNSimulator.debug) {\n        console.log(\"execATN loop starting closure: \" + state.configs);\n      }\n      let target = this.getExistingTargetState(state, t);\n      if (!target) {\n        target = this.computeTargetState(input, state, t);\n      }\n      if (target === ATNSimulator.ERROR) {\n        break;\n      }\n      if (t !== Token.EOF) {\n        this.consume(input);\n      }\n      if (target.isAcceptState) {\n        this.captureSimState(input, target);\n        if (t === Token.EOF) {\n          break;\n        }\n      }\n      t = input.LA(1);\n      state = target;\n    }\n    return this.failOrAccept(input, state.configs, t);\n  }\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns `null`.\n   *\n   * @param s The current DFA state.\n   * @param t The next input symbol.\n   *\n   * @returns The existing target DFA state for the given input symbol\n   * `t`, or `null` if the target state for this edge is not already cached\n   */\n  getExistingTargetState(s, t) {\n    if (t >= this.#options.minDFAEdge && t <= this.#options.maxDFAEdge) {\n      const target = s.edges[t - this.#options.minDFAEdge];\n      if (_LexerATNSimulator.debug && target) {\n        console.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n      }\n      return target;\n    }\n    return void 0;\n  }\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the computed state and corresponding\n   * edge to the DFA.\n   *\n   * @param input The input stream\n   * @param s The current DFA state\n   * @param t The next input symbol\n   *\n   * @returns The computed target DFA state for the given input symbol `t`.\n   *          If `t` does not lead to a valid DFA state, this method returns `ERROR`.\n   */\n  computeTargetState(input, s, t) {\n    const reach = new OrderedATNConfigSet();\n    this.getReachableConfigSet(input, s.configs, reach, t);\n    if (reach.length === 0) {\n      if (!reach.hasSemanticContext) {\n        this.addDFAEdge(s, t, ATNSimulator.ERROR);\n      }\n      return ATNSimulator.ERROR;\n    }\n    return this.addDFAEdge(s, t, null, reach);\n  }\n  failOrAccept(input, reach, t) {\n    if (this.#prevAccept?.dfaState) {\n      const { dfaState, index, line, column } = this.#prevAccept;\n      this.accept(input, dfaState.lexerActionExecutor, this.startIndex, index, line, column);\n      return dfaState.prediction;\n    }\n    if (t === Token.EOF && input.index === this.startIndex) {\n      return Token.EOF;\n    }\n    throw new LexerNoViableAltException(this.recognizer, input, this.startIndex, reach);\n  }\n  /**\n   * Given a starting configuration set, figure out all ATN configurations we can reach upon input `t`.\n   * Parameter `reach` is a return parameter.\n   */\n  getReachableConfigSet(input, closure, reach, t) {\n    let skipAlt = ATN.INVALID_ALT_NUMBER;\n    for (const cfg of closure) {\n      const currentAltReachedAcceptState = cfg.alt === skipAlt;\n      if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n        continue;\n      }\n      if (_LexerATNSimulator.debug) {\n        console.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg.toString(this.recognizer, true));\n      }\n      for (const trans of cfg.state.transitions) {\n        const target = this.getReachableTarget(trans, t);\n        if (target) {\n          let lexerActionExecutor = cfg.lexerActionExecutor;\n          if (lexerActionExecutor) {\n            lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n          }\n          const treatEofAsEpsilon = t === Token.EOF;\n          const config = LexerATNConfig.createWithExecutor(\n            cfg,\n            target,\n            lexerActionExecutor\n          );\n          if (this.closure(input, config, reach, currentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n            skipAlt = cfg.alt;\n          }\n        }\n      }\n    }\n  }\n  accept(input, lexerActionExecutor, startIndex, index, line, charPos) {\n    if (_LexerATNSimulator.debug) {\n      console.log(\"ACTION %s\\n\", lexerActionExecutor);\n    }\n    input.seek(index);\n    this.line = line;\n    this.column = charPos;\n    if (lexerActionExecutor && this.recognizer) {\n      lexerActionExecutor.execute(this.recognizer, input, startIndex);\n    }\n  }\n  getReachableTarget(trans, t) {\n    if (trans.matches(t, this.#options.minCodePoint, this.#options.maxCodePoint)) {\n      return trans.target;\n    } else {\n      return void 0;\n    }\n  }\n  computeStartState(input, p) {\n    const initialContext = PredictionContext.EMPTY;\n    const configs = new OrderedATNConfigSet();\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const cfg = LexerATNConfig.createWithContext(target, i + 1, initialContext);\n      this.closure(input, cfg, configs, false, false, false);\n    }\n    return configs;\n  }\n  /**\n   * Since the alternatives within any lexer decision are ordered by\n   * preference, this method stops pursuing the closure as soon as an accept\n   * state is reached. After the first accept state is reached by depth-first\n   * search from `config`, all other (potentially reachable) states for\n   * this rule would have a lower priority.\n   *\n   * @returns {boolean} `true` if an accept state is reached, otherwise `false`.\n   */\n  closure(input, config, configs, currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n    let cfg = null;\n    if (_LexerATNSimulator.debug) {\n      console.log(\"closure(\" + config.toString(this.recognizer, true) + \")\");\n    }\n    if (config.state.constructor.stateType === ATNState.RULE_STOP) {\n      if (_LexerATNSimulator.debug) {\n        if (this.recognizer !== null) {\n          console.log(\n            \"closure at %s rule stop %s\\n\",\n            this.recognizer.ruleNames[config.state.ruleIndex],\n            config\n          );\n        } else {\n          console.log(\"closure at rule stop %s\\n\", config);\n        }\n      }\n      if (!config.context || config.context.hasEmptyPath()) {\n        if (!config.context || config.context.isEmpty()) {\n          configs.add(config);\n          return true;\n        } else {\n          configs.add(LexerATNConfig.createWithConfig(config.state, config, PredictionContext.EMPTY));\n          currentAltReachedAcceptState = true;\n        }\n      }\n      if (config.context && !config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n            const newContext = config.context.getParent(i);\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            cfg = LexerATNConfig.createWithConfig(returnState, config, newContext);\n            currentAltReachedAcceptState = this.closure(\n              input,\n              cfg,\n              configs,\n              currentAltReachedAcceptState,\n              speculative,\n              treatEofAsEpsilon\n            );\n          }\n        }\n      }\n      return currentAltReachedAcceptState;\n    }\n    if (!config.state.epsilonOnlyTransitions) {\n      if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n        configs.add(config);\n      }\n    }\n    for (const trans of config.state.transitions) {\n      cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n      if (cfg) {\n        currentAltReachedAcceptState = this.closure(\n          input,\n          cfg,\n          configs,\n          currentAltReachedAcceptState,\n          speculative,\n          treatEofAsEpsilon\n        );\n      }\n    }\n    return currentAltReachedAcceptState;\n  }\n  // side-effect: can alter configs.hasSemanticContext\n  getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon) {\n    if (!this.#lexerATNConfigFactory) {\n      this.setupATNFactoryLookup();\n    }\n    const factory = this.#lexerATNConfigFactory[trans.transitionType];\n    if (!factory) {\n      return null;\n    }\n    return factory(input, config, trans, configs, speculative, treatEofAsEpsilon);\n  }\n  /**\n   * Fills the lookup table for creating lexer ATN configs. This helps to avoid frequent checks of the transition\n   * type, which determines the configuration of the created config.\n   */\n  setupATNFactoryLookup() {\n    this.#lexerATNConfigFactory = [];\n    this.#lexerATNConfigFactory[Transition.RULE] = (input, config, trans) => {\n      const newContext = SingletonPredictionContext.create(\n        config.context ?? void 0,\n        trans.followState.stateNumber\n      );\n      return LexerATNConfig.createWithConfig(trans.target, config, newContext);\n    };\n    this.#lexerATNConfigFactory[Transition.PRECEDENCE] = () => {\n      throw new Error(\"Precedence predicates are not supported in lexers.\");\n    };\n    this.#lexerATNConfigFactory[Transition.PREDICATE] = (input, config, trans, configs, speculative) => {\n      const pt = trans;\n      if (_LexerATNSimulator.debug) {\n        console.log(\"EVAL rule \" + pt.ruleIndex + \":\" + pt.predIndex);\n      }\n      configs.hasSemanticContext = true;\n      if (this.evaluatePredicate(input, pt.ruleIndex, pt.predIndex, speculative)) {\n        return LexerATNConfig.createWithConfig(trans.target, config);\n      }\n      return null;\n    };\n    this.#lexerATNConfigFactory[Transition.ACTION] = (input, config, trans) => {\n      if (config.context === null || config.context.hasEmptyPath()) {\n        const lexerActionExecutor = LexerActionExecutor.append(\n          config.lexerActionExecutor,\n          this.atn.lexerActions[trans.actionIndex]\n        );\n        return LexerATNConfig.createWithExecutor(config, trans.target, lexerActionExecutor);\n      } else {\n        return LexerATNConfig.createWithConfig(trans.target, config);\n      }\n    };\n    this.#lexerATNConfigFactory[Transition.EPSILON] = (input, config, trans) => {\n      return LexerATNConfig.createWithConfig(trans.target, config);\n    };\n    const simple = /* @__PURE__ */ __name((input, config, trans, configs, speculative, treatEofAsEpsilon) => {\n      if (treatEofAsEpsilon) {\n        if (trans.matches(Token.EOF, this.#options.minCodePoint, this.#options.maxCodePoint)) {\n          return LexerATNConfig.createWithConfig(trans.target, config);\n        }\n      }\n      return null;\n    }, \"simple\");\n    this.#lexerATNConfigFactory[Transition.ATOM] = simple;\n    this.#lexerATNConfigFactory[Transition.RANGE] = simple;\n    this.#lexerATNConfigFactory[Transition.SET] = simple;\n  }\n  /**\n   * Evaluate a predicate specified in the lexer.\n   *\n   * If `speculative` is `true`, this method was called before\n   * {@link consume} for the matched character. This method should call\n   * {@link consume} before evaluating the predicate to ensure position\n   * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n   * and {@link Lexer}, properly reflect the current\n   * lexer state. This method should restore `input` and the simulator\n   * to the original state before returning (i.e. undo the actions made by the\n   * call to {@link consume}.\n   *\n   * @param input The input stream.\n   * @param ruleIndex The rule containing the predicate.\n   * @param predIndex The index of the predicate within the rule.\n   * @param speculative `true` if the current index in `input` is\n   * one character before the predicate's location.\n   *\n   * @returns `true` if the specified predicate evaluates to\n   * `true`.\n   */\n  evaluatePredicate(input, ruleIndex, predIndex, speculative) {\n    if (!this.recognizer) {\n      return true;\n    }\n    if (!speculative) {\n      return this.recognizer.sempred(null, ruleIndex, predIndex);\n    }\n    const savedColumn = this.column;\n    const savedLine = this.line;\n    const index = input.index;\n    const marker = input.mark();\n    try {\n      this.consume(input);\n      return this.recognizer.sempred(null, ruleIndex, predIndex);\n    } finally {\n      this.column = savedColumn;\n      this.line = savedLine;\n      input.seek(index);\n      input.release(marker);\n    }\n  }\n  captureSimState(input, dfaState) {\n    this.#prevAccept = {\n      index: input.index,\n      line: this.line,\n      column: this.column,\n      dfaState\n    };\n  }\n  addDFAEdge(from, tk, to, configs) {\n    if (!to && configs) {\n      const suppressEdge = configs.hasSemanticContext;\n      configs.hasSemanticContext = false;\n      to = this.addDFAState(configs);\n      if (suppressEdge) {\n        return to;\n      }\n    }\n    if (tk < this.#options.minDFAEdge || tk > this.#options.maxDFAEdge) {\n      return to;\n    }\n    if (_LexerATNSimulator.debug) {\n      console.log(\"EDGE \" + from + \" -> \" + to + \" upon \" + tk);\n    }\n    from.edges[tk - this.#options.minDFAEdge] = to;\n    return to;\n  }\n  /**\n   * Add a new DFA state if there isn't one with this set of configurations already. This method also detects\n   * the first configuration containing an ATN rule stop state. Later, when traversing the DFA, we will know\n   * which rule to accept.\n   */\n  addDFAState(configs) {\n    const dfa = this.decisionToDFA[this.mode];\n    const existing = dfa.getStateForConfigs(configs);\n    if (existing) {\n      return existing;\n    }\n    const proposed = DFAState.fromConfigs(configs);\n    const firstConfigWithRuleStopState = configs.firstStopState;\n    if (firstConfigWithRuleStopState) {\n      proposed.isAcceptState = true;\n      proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n      proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n    }\n    configs.setReadonly(true);\n    dfa.addState(proposed);\n    return proposed;\n  }\n};\n\n// src/atn/ParseInfo.ts\nvar ParseInfo = class {\n  static {\n    __name(this, \"ParseInfo\");\n  }\n  atnSimulator;\n  constructor(atnSimulator) {\n    this.atnSimulator = atnSimulator;\n  }\n  /**\n   * Gets an array of {@link DecisionInfo} instances containing the profiling\n   * information gathered for each decision in the ATN.\n   *\n   * @returns An array of {@link DecisionInfo} instances, indexed by decision\n   * number.\n   */\n  getDecisionInfo() {\n    return this.atnSimulator.getDecisionInfo();\n  }\n  /**\n   * Gets the decision numbers for decisions that required one or more\n   * full-context predictions during parsing. These are decisions for which\n   * {@link DecisionInfo#llFallback} is non-zero.\n   *\n   * @returns A list of decision numbers which required one or more\n   * full-context predictions during parsing.\n   */\n  getLLDecisions() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    const result = new Array();\n    for (let i = 0; i < decisions.length; i++) {\n      const fallBack = decisions[i].llFallback;\n      if (fallBack > 0) {\n        result.push(i);\n      }\n    }\n    return result;\n  }\n  /**\n   * Gets the total time spent during prediction across all decisions made\n   * during parsing. This value is the sum of\n   * {@link DecisionInfo#timeInPrediction} for all decisions.\n   */\n  getTotalTimeInPrediction() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let t = 0;\n    for (const decision of decisions) {\n      t += decision.timeInPrediction;\n    }\n    return t;\n  }\n  /**\n   * Gets the total number of SLL lookahead operations across all decisions\n   * made during parsing. This value is the sum of\n   * {@link DecisionInfo#sllTotalLook} for all decisions.\n   */\n  getTotalSLLLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllTotalLook;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of LL lookahead operations across all decisions\n   * made during parsing. This value is the sum of\n   * {@link DecisionInfo#llTotalLook} for all decisions.\n   */\n  getTotalLLLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.llTotalLook;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for SLL prediction\n   * across all decisions made during parsing.\n   */\n  getTotalSLLATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllATNTransitions;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for LL prediction\n   * across all decisions made during parsing.\n   */\n  getTotalLLATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.llATNTransitions;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for SLL and LL\n   * prediction across all decisions made during parsing.\n   *\n   *\n   * This value is the sum of {@link #getTotalSLLATNLookaheadOps} and\n   * {@link #getTotalLLATNLookaheadOps}.\n   */\n  getTotalATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllATNTransitions;\n      k += decision.llATNTransitions;\n    }\n    return k;\n  }\n  getDFASize(decision) {\n    if (decision === void 0) {\n      let n2 = 0;\n      const decisionToDFA = this.atnSimulator.decisionToDFA;\n      for (let i = 0; i < decisionToDFA.length; i++) {\n        n2 += this.getDFASize(i);\n      }\n      return n2;\n    } else {\n      const decisionToDFA = this.atnSimulator.decisionToDFA[decision];\n      return decisionToDFA.length;\n    }\n  }\n};\n\n// src/NoViableAltException.ts\nvar NoViableAltException = class extends RecognitionException {\n  static {\n    __name(this, \"NoViableAltException\");\n  }\n  /** Which configurations did we try at input.index() that couldn't match input.LT(1)? */\n  deadEndConfigs = null;\n  /**\n   * The token object at the start index; the input stream might\n   * \tnot be buffering tokens so get a reference to it. (At the\n   *  time the error occurred, of course the stream needs to keep a\n   *  buffer all of the tokens but later we might not have access to those.)\n   */\n  startToken;\n  constructor(recognizer, input = null, startToken = null, offendingToken = null, deadEndConfigs = null, ctx = null) {\n    ctx = ctx ?? recognizer.context;\n    offendingToken = offendingToken ?? recognizer.getCurrentToken();\n    startToken = startToken ?? recognizer.getCurrentToken();\n    input = input ?? recognizer.inputStream;\n    super({ message: \"\", recognizer, input, ctx });\n    this.deadEndConfigs = deadEndConfigs;\n    this.startToken = startToken;\n    this.offendingToken = offendingToken;\n  }\n};\n\n// src/utils/DoubleDict.ts\nvar DoubleDict = class {\n  static {\n    __name(this, \"DoubleDict\");\n  }\n  cacheMap;\n  constructor() {\n    this.cacheMap = new HashMap();\n  }\n  get(a, b) {\n    const d = this.cacheMap.get(a) ?? null;\n    return d === null ? null : d.get(b) ?? null;\n  }\n  set(a, b, o) {\n    let d = this.cacheMap.get(a);\n    if (!d) {\n      d = new HashMap();\n      this.cacheMap.set(a, d);\n    }\n    d.set(b, o);\n  }\n};\n\n// src/atn/PredictionMode.ts\nvar SubsetEqualityComparer = class _SubsetEqualityComparer {\n  static {\n    __name(this, \"SubsetEqualityComparer\");\n  }\n  static instance = new _SubsetEqualityComparer();\n  hashCode(config) {\n    let hashCode = MurmurHash.initialize(7);\n    hashCode = MurmurHash.update(hashCode, config.state.stateNumber);\n    hashCode = MurmurHash.updateFromComparable(hashCode, config.context);\n    hashCode = MurmurHash.finish(hashCode, 2);\n    return hashCode;\n  }\n  equals(a, b) {\n    return a.state.stateNumber === b.state.stateNumber && (a.context?.equals(b.context) ?? true);\n  }\n};\nvar PredictionMode = class _PredictionMode {\n  static {\n    __name(this, \"PredictionMode\");\n  }\n  /**\n   * The SLL(*) prediction mode. This prediction mode ignores the current\n   * parser context when making predictions. This is the fastest prediction\n   * mode, and provides correct results for many grammars. This prediction\n   * mode is more powerful than the prediction mode provided by ANTLR 3, but\n   * may result in syntax errors for grammar and input combinations which are\n   * not SLL.\n   *\n   *\n   * When using this prediction mode, the parser will either return a correct\n   * parse tree (i.e. the same parse tree that would be returned with the\n   * {@link LL} prediction mode), or it will report a syntax error. If a\n   * syntax error is encountered when using the {@link SLL} prediction mode,\n   * it may be due to either an actual syntax error in the input or indicate\n   * that the particular combination of grammar and input requires the more\n   * powerful {@link LL} prediction abilities to complete successfully.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static SLL = 0;\n  /**\n   * The LL(*) prediction mode. This prediction mode allows the current parser\n   * context to be used for resolving SLL conflicts that occur during\n   * prediction. This is the fastest prediction mode that guarantees correct\n   * parse results for all combinations of grammars with syntactically correct\n   * inputs.\n   *\n   *\n   * When using this prediction mode, the parser will make correct decisions\n   * for all syntactically-correct grammar and input combinations. However, in\n   * cases where the grammar is truly ambiguous this prediction mode might not\n   * report a precise answer for *exactly which* alternatives are\n   * ambiguous.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static LL = 1;\n  /**\n   *\n   * The LL(*) prediction mode with exact ambiguity detection. In addition to\n   * the correctness guarantees provided by the {@link LL} prediction mode,\n   * this prediction mode instructs the prediction algorithm to determine the\n   * complete and exact set of ambiguous alternatives for every ambiguous\n   * decision encountered while parsing.\n   *\n   *\n   * This prediction mode may be used for diagnosing ambiguities during\n   * grammar development. Due to the performance overhead of calculating sets\n   * of ambiguous alternatives, this prediction mode should be avoided when\n   * the exact results are not necessary.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static LL_EXACT_AMBIG_DETECTION = 2;\n  /**\n   *\n   *Computes the SLL prediction termination condition.\n   *\n   *\n   *This method computes the SLL prediction termination condition for both of\n   *the following cases.\n   *\n   * - The usual SLL+LL fallback upon SLL conflict\n   * - Pure SLL without LL fallback\n   *\n   ***COMBINED SLL+LL PARSING**\n   *\n   *When LL-fallback is enabled upon SLL conflict, correct predictions are\n   *ensured regardless of how the termination condition is computed by this\n   *method. Due to the substantially higher cost of LL prediction, the\n   *prediction should only fall back to LL when the additional lookahead\n   *cannot lead to a unique SLL prediction.\n   *\n   *Assuming combined SLL+LL parsing, an SLL configuration set with only\n   *conflicting subsets should fall back to full LL, even if the\n   *configuration sets don't resolve to the same alternative (e.g.\n   *`{1,2`} and `{3,4`}. If there is at least one non-conflicting\n   *configuration, SLL could continue with the hopes that more lookahead will\n   *resolve via one of those non-conflicting configurations.\n   *\n   *Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n   *stops when it sees only conflicting configuration subsets. In contrast,\n   *full LL keeps going when there is uncertainty.\n   *\n   ***HEURISTIC**\n   *\n   *As a heuristic, we stop prediction when we see any conflicting subset\n   *unless we see a state that only has one alternative associated with it.\n   *The single-alt-state thing lets prediction continue upon rules like\n   *(otherwise, it would admit defeat too soon):\n   *\n   *`[12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;`\n   *\n   *When the ATN simulation reaches the state before `';'`, it has a\n   *DFA state that looks like: `[12|1|[], 6|2|[], 12|2|[]]`. Naturally\n   *`12|1|[]` and `12|2|[]` conflict, but we cannot stop\n   *processing this node because alternative to has another way to continue,\n   *via `[6|2|[]]`.\n   *\n   *It also let's us continue for this rule:\n   *\n   *`[1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;`\n   *\n   *After matching input A, we reach the stop state for rule A, state 1.\n   *State 8 is the state right before B. Clearly alternatives 1 and 2\n   *conflict and no amount of further lookahead will separate the two.\n   *However, alternative 3 will be able to continue and so we do not stop\n   *working on this state. In the previous example, we're concerned with\n   *states associated with the conflicting alternatives. Here alt 3 is not\n   *associated with the conflicting configs, but since we can continue\n   *looking for input reasonably, don't declare the state done.\n   *\n   ***PURE SLL PARSING**\n   *\n   *To handle pure SLL parsing, all we have to do is make sure that we\n   *combine stack contexts for configurations that differ only by semantic\n   *predicate. From there, we can do the usual SLL termination heuristic.\n   *\n   ***PREDICATES IN SLL+LL PARSING**\n   *\n   *SLL decisions don't evaluate predicates until after they reach DFA stop\n   *states because they need to create the DFA cache that works in all\n   *semantic situations. In contrast, full LL evaluates predicates collected\n   *during start state computation so it can ignore predicates thereafter.\n   *This means that SLL termination detection can totally ignore semantic\n   *predicates.\n   *\n   *Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n   *semantic predicate contexts so we might see two configurations like the\n   *following.\n   *\n   *`(s, 1, x, {`), (s, 1, x', {p})}\n   *\n   *Before testing these configurations against others, we have to merge\n   *`x` and `x'` (without modifying the existing configurations).\n   *For example, we test `(x+x')==x''` when looking for conflicts in\n   *the following configurations.\n   *\n   *`(s, 1, x, {`), (s, 1, x', {p}), (s, 2, x'', {})}\n   *\n   *If the configuration set has predicates (as indicated by\n   *{@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n   *the configurations to strip out all of the predicates so that a standard\n   *{@link ATNConfigSet} will merge everything ignoring predicates.\n   */\n  static hasSLLConflictTerminatingPrediction(mode, configs) {\n    if (_PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return true;\n    }\n    if (mode === _PredictionMode.SLL) {\n      if (configs.hasSemanticContext) {\n        const dup = new ATNConfigSet();\n        for (let c of configs) {\n          c = ATNConfig.duplicate(c, SemanticContext.NONE);\n          dup.add(c);\n        }\n        configs = dup;\n      }\n    }\n    const altSets = _PredictionMode.getConflictingAltSubsets(configs);\n    return _PredictionMode.hasConflictingAltSet(altSets) && !_PredictionMode.hasStateAssociatedWithOneAlt(configs);\n  }\n  /**\n   * Checks if any configuration in `configs` is in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @returns `true` if any configuration in `configs` is in a\n   * {@link RuleStopState}, otherwise `false`\n   */\n  static hasConfigInRuleStopState(configs) {\n    for (const c of configs) {\n      if (c.state instanceof RuleStopState) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Checks if all configurations in `configs` are in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @returns `true` if all configurations in `configs` are in a\n   * {@link RuleStopState}, otherwise `false`\n   */\n  static allConfigsInRuleStopStates(configs) {\n    for (const c of configs) {\n      if (!(c.state instanceof RuleStopState)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  /**\n   *\n   * Full LL prediction termination.\n   *\n   * Can we stop looking ahead during ATN simulation or is there some\n   * uncertainty as to which alternative we will ultimately pick, after\n   * consuming more input? Even if there are partial conflicts, we might know\n   * that everything is going to resolve to the same minimum alternative. That\n   * means we can stop since no more lookahead will change that fact. On the\n   * other hand, there might be multiple conflicts that resolve to different\n   * minimums. That means we need more look ahead to decide which of those\n   * alternatives we should predict.\n   *\n   * The basic idea is to split the set of configurations `C`, into\n   * conflicting subsets `(s, _, ctx, _)` and singleton subsets with\n   * non-conflicting configurations. Two configurations conflict if they have\n   * identical {@link ATNConfig.state} and {@link ATNConfig.context} values\n   * but different {@link ATNConfig.alt} value, e.g. `(s, i, ctx, _)`\n   * and `(s, j, ctx, _)` for `i!=j`.\n   *\n   * Reduce these configuration subsets to the set of possible alternatives.\n   * You can compute the alternative subsets in one pass as follows:\n   *\n   * `A_s,ctx = {i | (s, i, ctx, _)`} for each configuration in\n   * `C` holding `s` and `ctx` fixed.\n   *\n   * Or in pseudo-code, for each configuration `c` in `C`:\n   *\n   * ```\n   * map[c] U= c.{@link ATNConfig.alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * ```\n   *\n   * The values in `map` are the set of `A_s,ctx` sets.\n   *\n   * If `|A_s,ctx|=1` then there is no conflict associated with\n   * `s` and `ctx`.\n   *\n   * Reduce the subsets to singletons by choosing a minimum of each subset. If\n   * the union of these alternative subsets is a singleton, then no amount of\n   * more lookahead will help us. We will always pick that alternative. If,\n   * however, there is more than one alternative, then we are uncertain which\n   * alternative to predict and must continue looking for resolution. We may\n   * or may not discover an ambiguity in the future, even if there are no\n   * conflicting subsets this round.\n   *\n   * The biggest sin is to terminate early because it means we've made a\n   * decision but were uncertain as to the eventual outcome. We haven't used\n   * enough lookahead. On the other hand, announcing a conflict too late is no\n   * big deal; you will still have the conflict. It's just inefficient. It\n   * might even look until the end of file.\n   *\n   * No special consideration for semantic predicates is required because\n   * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n   * no configuration contains a semantic context during the termination\n   * check.\n   *\n   * **CONFLICTING CONFIGS**\n   *\n   * Two configurations `(s, i, x)` and `(s, j, x')`, conflict when `i!=j` but `x=x'`. Because we merge all\n   * `(s, i, _)` configurations together, that means that there are at most `n` configurations associated with state\n   * `s` for `n` possible alternatives in the decision. The merged stacks complicate the comparison of configuration\n   * contexts `x` and `x'`. Sam checks to see if one is a subset of the other by calling merge and checking to see\n   * if the merged result is either `x` or `x'`. If the `x` associated with lowest alternative `i` is the superset,\n   * then `i` is the only possible prediction since the others resolve to `min(i)` as well. However, if `x` is\n   * associated with `j>i` then at least one stack configuration for `j` is not in conflict with alternative `i`.\n   * The algorithm should keep going, looking for more lookahead due to the uncertainty.\n   *\n   * For simplicity, I'm doing a equality check between `x` and `x'` that lets the algorithm continue to consume\n   * lookahead longer than necessary. The reason I like the equality is of course the simplicity but also because\n   * that is the test you need to detect the alternatives that are actually in conflict.\n   *\n   * **CONTINUE/STOP RULE**\n   *\n   * Continue if union of resolved alternative sets from non-conflicting and conflicting alternative subsets has more\n   * than one alternative. We are uncertain about which alternative to predict.\n   *\n   * The complete set of alternatives, `[i for (_,i,_)]`, tells us which alternatives are still in the running for\n   * the amount of input we've consumed at this point. The conflicting sets let us to strip away configurations that\n   * won't lead to more states because we resolve conflicts to the configuration with a minimum alternate for the\n   * conflicting set.\n   *\n   * **CASES**\n   *\n   * - no conflicts and more than 1 alternative in set => continue\n   * -  `(s, 1, x)`, `(s, 2, x)`, `(s, 3, z)`, `(s', 1, y)`, `(s', 2, y)` yields non-conflicting set `{3`} U\n   *   conflicting sets `min({1,2`)} U `min({1,2`)} = `{1,3`} => continue\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 1, y)`, `(s', 2, y)`, `(s'', 1, z)` yields non-conflicting set `{1`} U\n   *   conflicting sets `min({1,2`)} U `min({1,2`)} = `{1`} => stop and predict 1\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 1, y)`, `(s', 2, y)` yields conflicting, reduced sets `{1`} U\n   *   `{1`} = `{1`} => stop and predict 1, can announce ambiguity `{1,2`}\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 2, y)`, `(s', 3, y)` yields conflicting, reduced sets `{1`} U\n   *   `{2`} = `{1,2`} => continue\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 3, y)`, `(s', 4, y)` yields conflicting, reduced sets `{1`} U\n   *   `{3`} = `{1,3`} => continue\n   *\n   * **EXACT AMBIGUITY DETECTION**\n   *\n   *If all states report the same conflicting set of alternatives, then we\n   *know we have the exact ambiguity set.\n   *\n   * `|A_*i*|>1` and `A_*i* = A_*j*` for all *i*, *j*.\n   *\n   * In other words, we continue examining lookahead until all `A_i` have more than one alternative and all `A_i`\n   * are the same. If `A={{1,2`, {1,3}}}, then regular LL prediction would terminate because the resolved set\n   * is `{1`}. To determine what the real ambiguity is, we have to know whether the ambiguity is between one and\n   * two or one and three so we keep going. We can only stop prediction when we need exact ambiguity detection when\n   * the sets look like `A={{1,2`}} or `{{1,2`,{1,2}}}, etc...\n   */\n  static resolvesToJustOneViableAlt(altSets) {\n    return _PredictionMode.getSingleViableAlt(altSets);\n  }\n  /**\n   * Determines if every alternative subset in `altSets` contains more\n   * than one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if every {@link BitSet} in `altSets` has\n   * {@link BitSet//cardinality cardinality} > 1, otherwise `false`\n   */\n  static allSubsetsConflict(altSets) {\n    return !_PredictionMode.hasNonConflictingAltSet(altSets);\n  }\n  /**\n   * Determines if any single alternative subset in `altSets` contains\n   * exactly one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if `altSets` contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} 1, otherwise `false`\n   */\n  static hasNonConflictingAltSet(altSets) {\n    for (const alts of altSets) {\n      if (alts.length === 1) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Determines if any single alternative subset in `altSets` contains\n   * more than one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if `altSets` contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} > 1, otherwise `false`\n   */\n  static hasConflictingAltSet(altSets) {\n    for (const alts of altSets) {\n      if (alts.length > 1) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Determines if every alternative subset in `altSets` is equivalent.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if every member of `altSets` is equal to the\n   * others, otherwise `false`\n   */\n  static allSubsetsEqual(altSets) {\n    let first = null;\n    for (const alts of altSets) {\n      if (first === null) {\n        first = alts;\n      } else if (alts !== first) {\n        return false;\n      }\n    }\n    return true;\n  }\n  /**\n   * Returns the unique alternative predicted by all alternative subsets in\n   * `altSets`. If no such alternative exists, this method returns\n   * {@link ATN.INVALID_ALT_NUMBER}.\n   *\n   * @param altSets a collection of alternative subsets\n   */\n  static getUniqueAlt(altSets) {\n    const all = _PredictionMode.getAlts(altSets);\n    if (all.length === 1) {\n      return all.nextSetBit(0);\n    } else {\n      return ATN.INVALID_ALT_NUMBER;\n    }\n  }\n  /**\n   * Gets the complete set of represented alternatives for a collection of\n   * alternative subsets. This method returns the union of each {@link BitSet}\n   * in `altSets`.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns the set of represented alternatives in `altSets`\n   */\n  static getAlts(altSets) {\n    const all = new BitSet();\n    altSets.forEach((alts) => {\n      all.or(alts);\n    });\n    return all;\n  }\n  /**\n   * This function gets the conflicting alt subsets from a configuration set.\n   * For each configuration `c` in `configs`:\n   *\n   * ```\n   * map[c] U= c.{@link ATNConfig.alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * ```\n   */\n  static getConflictingAltSubsets(configs) {\n    const configToAlts = new HashMap(SubsetEqualityComparer.instance);\n    for (const cfg of configs) {\n      let alts = configToAlts.get(cfg);\n      if (!alts) {\n        alts = new BitSet();\n        configToAlts.set(cfg, alts);\n      }\n      alts.set(cfg.alt);\n    }\n    return Array.from(configToAlts.values());\n  }\n  /**\n   * Get a map from state to alt subset from a configuration set. For each configuration `c` in `configs`:\n   *\n   * ```\n   * map[c.state] = c.alt\n   * ```\n   */\n  static getStateToAltMap(configs) {\n    const m2 = new HashMap(ObjectEqualityComparator.instance);\n    for (const c of configs) {\n      let alts = m2.get(c.state);\n      if (!alts) {\n        alts = new BitSet();\n        m2.set(c.state, alts);\n      }\n      alts.set(c.alt);\n    }\n    return m2;\n  }\n  static hasStateAssociatedWithOneAlt(configs) {\n    const counts = {};\n    for (const c of configs) {\n      const stateNumber = c.state.stateNumber;\n      if (!counts[stateNumber]) {\n        counts[stateNumber] = 0;\n      }\n      counts[stateNumber]++;\n    }\n    return Object.values(counts).some((count) => {\n      return count === 1;\n    });\n  }\n  static getSingleViableAlt(altSets) {\n    let result = null;\n    for (const alts of altSets) {\n      const minAlt = alts.nextSetBit(0);\n      if (result === null) {\n        result = minAlt;\n      } else if (result !== minAlt) {\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return result ?? 0;\n  }\n};\n\n// src/atn/ParserATNSimulator.ts\nvar ParserATNSimulator = class _ParserATNSimulator extends ATNSimulator {\n  static {\n    __name(this, \"ParserATNSimulator\");\n  }\n  static traceATNSimulator = false;\n  static debug;\n  static debugAdd = false;\n  static debugClosure = false;\n  static dfaDebug = false;\n  static retryDebug = false;\n  /** SLL, LL, or LL + exact ambig detection? */\n  predictionMode;\n  decisionToDFA;\n  parser;\n  /**\n   * Each prediction operation uses a cache for merge of prediction contexts.\n   * Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n   * isn't synchronized but we're ok since two threads shouldn't reuse same\n   * parser/atn sim object because it can only handle one input at a time.\n   * This maps graphs a and b to merged result c. (a,b)->c. We can avoid\n   * the merge if we ever see a and b again.  Note that (b,a)->c should\n   * also be examined during cache lookup.\n   */\n  mergeCache = new DoubleDict();\n  // Used also in the profiling ATN simulator.\n  predictionState;\n  constructor(recog, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.parser = recog;\n    this.decisionToDFA = decisionToDFA;\n  }\n  static getUniqueAlt(configs) {\n    let alt = ATN.INVALID_ALT_NUMBER;\n    for (const c of configs) {\n      if (alt === ATN.INVALID_ALT_NUMBER) {\n        alt = c.alt;\n      } else if (c.alt !== alt) {\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return alt;\n  }\n  reset() {\n  }\n  clearDFA() {\n    for (let d = 0; d < this.decisionToDFA.length; d++) {\n      this.decisionToDFA[d] = new DFA(this.atn.getDecisionState(d), d);\n    }\n  }\n  // TODO: make outerContext an optional parameter, not optional null.\n  adaptivePredict(input, decision, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"adaptivePredict decision \" + decision + \" exec LA(1)==\" + this.getLookaheadName(input) + \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    const dfa = this.decisionToDFA[decision];\n    this.predictionState = {\n      input,\n      startIndex: input.index,\n      outerContext: outerContext ?? void 0,\n      dfa\n    };\n    const m2 = input.mark();\n    const index = input.index;\n    try {\n      let s0;\n      if (dfa.isPrecedenceDfa) {\n        s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n      } else {\n        s0 = dfa.s0;\n      }\n      if (!s0) {\n        if (!outerContext) {\n          outerContext = ParserRuleContext.empty;\n        }\n        if (_ParserATNSimulator.debug) {\n          console.log(\"predictATN decision \" + dfa.decision + \" exec LA(1)==\" + this.getLookaheadName(input) + \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n        }\n        const fullCtx = false;\n        let s0_closure = this.computeStartState(dfa.atnStartState, ParserRuleContext.empty, fullCtx);\n        if (dfa.isPrecedenceDfa) {\n          s0_closure = this.applyPrecedenceFilter(s0_closure);\n          s0 = this.addDFAState(dfa, DFAState.fromConfigs(s0_closure));\n          dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n        } else {\n          s0 = this.addDFAState(dfa, DFAState.fromConfigs(s0_closure));\n          dfa.s0 = s0;\n        }\n      }\n      const alt = this.execATN(dfa, s0, input, index, outerContext);\n      if (_ParserATNSimulator.debug) {\n        console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.vocabulary));\n      }\n      return alt;\n    } finally {\n      this.predictionState.dfa = void 0;\n      this.mergeCache = new DoubleDict();\n      input.seek(index);\n      input.release(m2);\n    }\n  }\n  /**\n   * Performs ATN simulation to compute a predicted alternative based\n   *  upon the remaining input, but also updates the DFA cache to avoid\n   *  having to traverse the ATN again for the same input sequence.\n   *\n   * There are some key conditions we're looking for after computing a new\n   * set of ATN configs (proposed DFA state):\n   *       if the set is empty, there is no viable alternative for current symbol\n   *       does the state uniquely predict an alternative?\n   *       does the state have a conflict that would prevent us from\n   *         putting it on the work list?\n   *\n   * We also have some key operations to do:\n   *       add an edge from previous DFA state to potentially new DFA state, D,\n   *         upon current symbol but only if adding to work list, which means in all\n   *         cases except no viable alternative (and possibly non-greedy decisions?)\n   *       collecting predicates and adding semantic context to DFA accept states\n   *       adding rule context to context-sensitive DFA accept states\n   *       consuming an input symbol\n   *       reporting a conflict\n   *       reporting an ambiguity\n   *       reporting a context sensitivity\n   *       reporting insufficient predicates\n   *\n   * cover these cases:\n   *    dead end\n   *    single alt\n   *    single alt + preds\n   *    conflict\n   *    conflict + preds\n   */\n  execATN(dfa, s0, input, startIndex, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"execATN decision \" + dfa.decision + \", DFA state \" + s0 + \", LA(1)==\" + this.getLookaheadName(input) + \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    let alt;\n    let previousState = s0;\n    let t = input.LA(1);\n    while (true) {\n      let nextState = this.getExistingTargetState(previousState, t);\n      if (!nextState) {\n        nextState = this.computeTargetState(dfa, previousState, t);\n      }\n      if (nextState === ATNSimulator.ERROR) {\n        const e = this.noViableAlt(input, outerContext, previousState.configs, startIndex);\n        input.seek(startIndex);\n        alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousState.configs, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      if (nextState.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n        let conflictingAlts = null;\n        if (nextState.predicates !== null) {\n          if (_ParserATNSimulator.debug) {\n            console.log(\"DFA state has preds in DFA sim LL failover\");\n          }\n          const conflictIndex = input.index;\n          if (conflictIndex !== startIndex) {\n            input.seek(startIndex);\n          }\n          conflictingAlts = this.evalSemanticContext(nextState.predicates, outerContext, true);\n          if (conflictingAlts.length === 1) {\n            if (_ParserATNSimulator.debug) {\n              console.log(\"Full LL avoided\");\n            }\n            return conflictingAlts.nextSetBit(0);\n          }\n          if (conflictIndex !== startIndex) {\n            input.seek(conflictIndex);\n          }\n        }\n        if (_ParserATNSimulator.dfaDebug) {\n          console.log(\"ctx sensitive state \" + outerContext + \" in \" + nextState);\n        }\n        const fullCtx = true;\n        const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n        this.reportAttemptingFullContext(dfa, conflictingAlts, nextState.configs, startIndex, input.index);\n        alt = this.execATNWithFullContext(dfa, nextState, s0_closure, input, startIndex, outerContext);\n        return alt;\n      }\n      if (nextState.isAcceptState) {\n        if (nextState.predicates === null) {\n          return nextState.prediction;\n        }\n        const stopIndex = input.index;\n        input.seek(startIndex);\n        const alts = this.evalSemanticContext(nextState.predicates, outerContext, true);\n        if (alts.length === 0) {\n          throw this.noViableAlt(input, outerContext, nextState.configs, startIndex);\n        }\n        if (alts.length === 1) {\n          return alts.nextSetBit(0);\n        }\n        this.reportAmbiguity(dfa, nextState, startIndex, stopIndex, false, alts, nextState.configs);\n        return alts.nextSetBit(0);\n      }\n      previousState = nextState;\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n  }\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns `null`.\n   *\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   * @returns The existing target DFA state for the given input symbol\n   * `t`, or `null` if the target state for this edge is not\n   * already cached\n   */\n  getExistingTargetState(previousD, t) {\n    return previousD.edges[t + 1];\n  }\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the\n   * computed state and corresponding edge to the DFA.\n   *\n   * @param dfa The DFA\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   *\n   * @returns The computed target DFA state for the given input symbol\n   * `t`. If `t` does not lead to a valid DFA state, this method\n   * returns {@link ERROR\n   */\n  computeTargetState(dfa, previousD, t) {\n    const reach = this.computeReachSet(previousD.configs, t, false);\n    if (reach === null) {\n      this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n      return ATNSimulator.ERROR;\n    }\n    let D = DFAState.fromConfigs(reach);\n    const predictedAlt = _ParserATNSimulator.getUniqueAlt(reach);\n    if (_ParserATNSimulator.debug) {\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      console.log(\"SLL altSubSets=\" + arrayToString(altSubSets) + /*\", previous=\" + previousD.configs + */\n      \", configs=\" + reach + \", predict=\" + predictedAlt + \", allSubsetsConflict=\" + PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" + this.getConflictingAlts(reach));\n    }\n    if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n      D.isAcceptState = true;\n      D.configs.uniqueAlt = predictedAlt;\n      D.prediction = predictedAlt;\n    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n      D.configs.conflictingAlts = this.getConflictingAlts(reach);\n      D.requiresFullContext = true;\n      D.isAcceptState = true;\n      D.prediction = D.configs.conflictingAlts.nextSetBit(0);\n    }\n    if (D.isAcceptState && D.configs.hasSemanticContext) {\n      this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n      if (D.predicates !== null) {\n        D.prediction = ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    D = this.addDFAEdge(dfa, previousD, t, D);\n    return D;\n  }\n  getRuleName(index) {\n    if (this.parser !== null && index >= 0) {\n      return this.parser.ruleNames[index];\n    } else {\n      return \"<rule \" + index + \">\";\n    }\n  }\n  getTokenName(t) {\n    if (t === Token.EOF) {\n      return \"EOF\";\n    }\n    const vocabulary = this.parser?.vocabulary ?? Vocabulary.EMPTY_VOCABULARY;\n    const displayName = vocabulary.getDisplayName(t);\n    if (displayName === t.toString()) {\n      return displayName;\n    }\n    return displayName + \"<\" + t + \">\";\n  }\n  getLookaheadName(input) {\n    return this.getTokenName(input.LA(1));\n  }\n  /**\n   * Used for debugging in adaptivePredict around execATN but I cut\n   * it out for clarity now that alg. works well. We can leave this\n   * \"dead\" code for a bit\n   */\n  dumpDeadEndConfigs(e) {\n    console.log(\"dead end configs: \");\n    const decs = e.deadEndConfigs;\n    for (const c of decs) {\n      let trans = \"no edges\";\n      if (c.state.transitions.length > 0) {\n        const t = c.state.transitions[0];\n        if (t instanceof AtomTransition) {\n          trans = \"Atom \" + this.getTokenName(t.labelValue);\n        } else if (t instanceof SetTransition) {\n          const neg = t instanceof NotSetTransition;\n          trans = (neg ? \"~\" : \"\") + \"Set \" + t.label;\n        }\n      }\n      console.error(c.toString(this.parser, true) + \":\" + trans);\n    }\n  }\n  predicateDFAState(dfaState, decisionState) {\n    const altCount = decisionState.transitions.length;\n    const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n    const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, altCount);\n    if (altToPred !== null) {\n      dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n      dfaState.prediction = ATN.INVALID_ALT_NUMBER;\n    } else {\n      dfaState.prediction = altsToCollectPredsFrom.nextSetBit(0);\n    }\n  }\n  // comes back with reach.uniqueAlt set to a valid alt\n  execATNWithFullContext(dfa, D, s0, input, startIndex, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"execATNWithFullContext \" + s0);\n    }\n    const fullCtx = true;\n    let foundExactAmbig = false;\n    let reach;\n    let previous = s0;\n    input.seek(startIndex);\n    let t = input.LA(1);\n    let predictedAlt = -1;\n    for (; ; ) {\n      reach = this.computeReachSet(previous, t, fullCtx);\n      if (reach === null) {\n        const e = this.noViableAlt(input, outerContext, previous, startIndex);\n        input.seek(startIndex);\n        const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      if (_ParserATNSimulator.debug) {\n        console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" + PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" + PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n      }\n      reach.uniqueAlt = _ParserATNSimulator.getUniqueAlt(reach);\n      if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n        predictedAlt = reach.uniqueAlt;\n        break;\n      } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n        predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n        if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n          break;\n        }\n      } else {\n        if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n          foundExactAmbig = true;\n          predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n          break;\n        }\n      }\n      previous = reach;\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n      return predictedAlt;\n    }\n    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, reach.getAlts(), reach);\n    return predictedAlt;\n  }\n  computeReachSet(closure, t, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"in computeReachSet, starting closure: \" + closure);\n    }\n    const intermediate = new ATNConfigSet(fullCtx);\n    let skippedStopStates = null;\n    for (const c of closure) {\n      if (_ParserATNSimulator.debug) {\n        console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n      }\n      if (c.state instanceof RuleStopState) {\n        if (fullCtx || t === Token.EOF) {\n          if (skippedStopStates === null) {\n            skippedStopStates = [];\n          }\n          skippedStopStates.push(c);\n        }\n        continue;\n      }\n      for (const trans of c.state.transitions) {\n        const target = this.getReachableTarget(trans, t);\n        if (target !== null) {\n          const cfg = ATNConfig.createWithConfig(target, c);\n          intermediate.add(cfg, this.mergeCache);\n          if (_ParserATNSimulator.debugAdd) {\n            console.log(\"added \" + cfg + \" to intermediate\");\n          }\n        }\n      }\n    }\n    let reach = null;\n    if (skippedStopStates === null && t !== Token.EOF) {\n      if (intermediate.length === 1) {\n        reach = intermediate;\n      } else if (_ParserATNSimulator.getUniqueAlt(intermediate) !== ATN.INVALID_ALT_NUMBER) {\n        reach = intermediate;\n      }\n    }\n    if (reach === null) {\n      reach = new ATNConfigSet(fullCtx);\n      const closureBusy = new HashSet();\n      const treatEofAsEpsilon = t === Token.EOF;\n      for (const config of intermediate) {\n        this.closure(config, reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n      }\n    }\n    if (t === Token.EOF) {\n      reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n    }\n    if (skippedStopStates !== null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {\n      for (const config of skippedStopStates) {\n        reach.add(config, this.mergeCache);\n      }\n    }\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"computeReachSet \" + closure + \" -> \" + reach);\n    }\n    if (reach.length === 0) {\n      return null;\n    } else {\n      return reach;\n    }\n  }\n  /**\n   * Return a configuration set containing only the configurations from\n   * `configs` which are in a {@link RuleStopState}. If all\n   * configurations in `configs` are already in a rule stop state, this\n   * method simply returns `configs`.\n   *\n   * When `lookToEndOfRule` is true, this method uses\n   * {@link ATN.nextTokens} for each configuration in `configs` which is\n   * not already in a rule stop state to see if a rule stop state is reachable\n   * from the configuration via epsilon-only transitions.\n   *\n   * @param configs the configuration set to update\n   * @param lookToEndOfRule when true, this method checks for rule stop states\n   * reachable by epsilon-only transitions from each configuration in\n   * `configs`.\n   *\n   * @returns `configs` if all configurations in `configs` are in a\n   * rule stop state, otherwise return a new configuration set containing only\n   * the configurations from `configs` which are in a rule stop state\n   */\n  removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return configs;\n    }\n    const result = new ATNConfigSet(configs.fullCtx);\n    for (const config of configs) {\n      if (config.state instanceof RuleStopState) {\n        result.add(config, this.mergeCache);\n        continue;\n      }\n      if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n        const nextTokens = this.atn.nextTokens(config.state);\n        if (nextTokens.contains(Token.EPSILON)) {\n          const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n          result.add(ATNConfig.createWithConfig(endOfRuleState, config), this.mergeCache);\n        }\n      }\n    }\n    return result;\n  }\n  computeStartState(p, ctx, fullCtx) {\n    const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n    const configs = new ATNConfigSet(fullCtx);\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"computeStartState from ATN state \" + p + \" initialContext=\" + initialContext.toString(this.parser));\n    }\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const c = ATNConfig.createWithContext(target, i + 1, initialContext);\n      const closureBusy = new HashSet();\n      this.closure(c, configs, closureBusy, true, fullCtx, false);\n    }\n    return configs;\n  }\n  /**\n   * This method transforms the start state computed by\n   * {@link computeStartState} to the special start state used by a\n   * precedence DFA for a particular precedence value. The transformation\n   * process applies the following changes to the start state's configuration\n   * set.\n   *\n   * 1. Evaluate the precedence predicates for each configuration using\n   * {@link SemanticContext//evalPrecedence}.\n   * 2. Remove all configurations which predict an alternative greater than\n   * 1, for which another configuration that predicts alternative 1 is in the\n   * same ATN state with the same prediction context. This transformation is\n   * valid for the following reasons:\n   * 3. The closure block cannot contain any epsilon transitions which bypass\n   * the body of the closure, so all states reachable via alternative 1 are\n   * part of the precedence alternatives of the transformed left-recursive\n   * rule.\n   * 4. The \"primary\" portion of a left recursive rule cannot contain an\n   * epsilon transition, so the only way an alternative other than 1 can exist\n   * in a state that is also reachable via alternative 1 is by nesting calls\n   * to the left-recursive rule, with the outer calls not being at the\n   * preferred precedence level.\n   *\n   *\n   * The prediction context must be considered by this filter to address\n   * situations like the following.\n   *\n   * `\n   * ```\n   * grammar TA;\n   * prog: statement* EOF;\n   * statement: letterA | statement letterA 'b' ;\n   * letterA: 'a';\n   * ```\n   * `\n   *\n   * If the above grammar, the ATN state immediately before the token\n   * reference `'a'` in `letterA` is reachable from the left edge\n   * of both the primary and closure blocks of the left-recursive rule\n   * `statement`. The prediction context associated with each of these\n   * configurations distinguishes between them, and prevents the alternative\n   * which stepped out to `prog` (and then back in to `statement`\n   * from being eliminated by the filter.\n   *\n   * @param configs The configuration set computed by\n   * {@link computeStartState} as the start state for the DFA.\n   * @returns The transformed configuration set representing the start state\n   * for a precedence DFA at a particular precedence level (determined by\n   * calling {@link Parser//getPrecedence})\n   */\n  applyPrecedenceFilter(configs) {\n    const statesFromAlt1 = [];\n    const configSet = new ATNConfigSet(configs.fullCtx);\n    for (const config of configs) {\n      if (config.alt !== 1) {\n        continue;\n      }\n      const updatedContext = config.semanticContext.evalPrecedence(\n        this.parser,\n        this.predictionState.outerContext\n      );\n      if (updatedContext === null) {\n        continue;\n      }\n      statesFromAlt1[config.state.stateNumber] = config.context;\n      if (updatedContext !== config.semanticContext) {\n        configSet.add(ATNConfig.duplicate(config, updatedContext), this.mergeCache);\n      } else {\n        configSet.add(config, this.mergeCache);\n      }\n    }\n    for (const config of configs) {\n      if (config.alt === 1) {\n        continue;\n      }\n      if (!config.precedenceFilterSuppressed) {\n        const context = statesFromAlt1[config.state.stateNumber] || null;\n        if (context !== null && context.equals(config.context)) {\n          continue;\n        }\n      }\n      configSet.add(config, this.mergeCache);\n    }\n    return configSet;\n  }\n  getReachableTarget(trans, ttype) {\n    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n      return trans.target;\n    } else {\n      return null;\n    }\n  }\n  getPredsForAmbigAlts(ambigAlts, configs, altCount) {\n    let altToPred = [];\n    for (const c of configs) {\n      if (ambigAlts.get(c.alt)) {\n        altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] ?? null, c.semanticContext);\n      }\n    }\n    let nPredAlts = 0;\n    for (let i = 1; i < altCount + 1; i++) {\n      const pred = altToPred[i] ?? null;\n      if (pred === null) {\n        altToPred[i] = SemanticContext.NONE;\n      } else if (pred !== SemanticContext.NONE) {\n        nPredAlts += 1;\n      }\n    }\n    if (nPredAlts === 0) {\n      altToPred = null;\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"getPredsForAmbigAlts result \" + arrayToString(altToPred));\n    }\n    return altToPred;\n  }\n  getPredicatePredictions(ambigAlts, altToPred) {\n    const pairs = [];\n    let containsPredicate = false;\n    for (let i = 1; i < altToPred.length; i++) {\n      const pred = altToPred[i];\n      if (ambigAlts.get(i)) {\n        pairs.push({ pred, alt: i });\n      }\n      if (pred !== SemanticContext.NONE) {\n        containsPredicate = true;\n      }\n    }\n    if (!containsPredicate) {\n      return null;\n    }\n    return pairs;\n  }\n  /**\n   * This method is used to improve the localization of error messages by\n   * choosing an alternative rather than throwing a\n   * {@link NoViableAltException} in particular prediction scenarios where the\n   * {@link ERROR} state was reached during ATN simulation.\n   *\n   *\n   * The default implementation of this method uses the following\n   * algorithm to identify an ATN configuration which successfully parsed the\n   * decision entry rule. Choosing such an alternative ensures that the\n   * {@link ParserRuleContext} returned by the calling rule will be complete\n   * and valid, and the syntax error will be reported later at a more\n   * localized location.\n   *\n   * - If a syntactically valid path or paths reach the end of the decision rule and\n   * they are semantically valid if predicated, return the min associated alt.\n   * - Else, if a semantically invalid but syntactically valid path exist\n   * or paths exist, return the minimum associated alt.\n   *\n   * - Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.\n   *\n   *\n   * In some scenarios, the algorithm described above could predict an\n   * alternative which will result in a {@link FailedPredicateException} in\n   * the parser. Specifically, this could occur if the *only* configuration\n   * capable of successfully parsing to the end of the decision rule is\n   * blocked by a semantic predicate. By choosing this alternative within\n   * {@link adaptivePredict} instead of throwing a\n   * {@link NoViableAltException}, the resulting\n   * {@link FailedPredicateException} in the parser will identify the specific\n   * predicate which is preventing the parser from successfully parsing the\n   * decision rule, which helps developers identify and correct logic errors\n   * in semantic predicates.\n   *\n   * @param configs The ATN configurations which were valid immediately before\n   * the {@link ERROR} state was reached\n   * @param outerContext The is the \\gamma_0 initial parser context from the paper\n   * or the parser stack at the instant before prediction commences.\n   *\n   * @returns The value to return from {@link adaptivePredict}, or\n   * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n   * identified and {@link adaptivePredict} should report an error instead\n   */\n  getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n    const splitConfigs = this.splitAccordingToSemanticValidity(configs, outerContext);\n    const semValidConfigs = splitConfigs[0];\n    const semInvalidConfigs = splitConfigs[1];\n    let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n    if (alt !== ATN.INVALID_ALT_NUMBER) {\n      return alt;\n    }\n    if (semInvalidConfigs.length > 0) {\n      alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n      if (alt !== ATN.INVALID_ALT_NUMBER) {\n        return alt;\n      }\n    }\n    return ATN.INVALID_ALT_NUMBER;\n  }\n  getAltThatFinishedDecisionEntryRule(configs) {\n    const alts = [];\n    for (const c of configs) {\n      if (c.reachesIntoOuterContext || c.state instanceof RuleStopState && c.context.hasEmptyPath()) {\n        if (alts.indexOf(c.alt) < 0) {\n          alts.push(c.alt);\n        }\n      }\n    }\n    if (alts.length === 0) {\n      return ATN.INVALID_ALT_NUMBER;\n    } else {\n      return Math.min(...alts);\n    }\n  }\n  /**\n   * Walk the list of configurations and split them according to\n   * those that have preds evaluating to true/false.  If no pred, assume\n   * true pred and include in succeeded set.  Returns Pair of sets.\n   *\n   * Create a new set so as not to alter the incoming parameter.\n   *\n   * Assumption: the input stream has been restored to the starting point\n   * prediction, which is where predicates need to evaluate.\n   */\n  splitAccordingToSemanticValidity(configs, outerContext) {\n    const succeeded = new ATNConfigSet(configs.fullCtx);\n    const failed = new ATNConfigSet(configs.fullCtx);\n    for (const c of configs) {\n      if (c.semanticContext !== SemanticContext.NONE) {\n        const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n        if (predicateEvaluationResult) {\n          succeeded.add(c);\n        } else {\n          failed.add(c);\n        }\n      } else {\n        succeeded.add(c);\n      }\n    }\n    return [succeeded, failed];\n  }\n  /**\n   * Look through a list of predicate/alt pairs, returning alts for the\n   * pairs that win. A `NONE` predicate indicates an alt containing an\n   * unpredicated config which behaves as \"always true.\" If !complete\n   * then we stop at the first predicate that evaluates to true. This\n   * includes pairs with null predicates.\n   */\n  evalSemanticContext(predPredictions, outerContext, complete) {\n    const predictions = new BitSet();\n    for (const pair of predPredictions) {\n      if (pair.pred === SemanticContext.NONE) {\n        predictions.set(pair.alt);\n        if (!complete) {\n          break;\n        }\n        continue;\n      }\n      const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n      if (_ParserATNSimulator.debug || _ParserATNSimulator.dfaDebug) {\n        console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n      }\n      if (predicateEvaluationResult) {\n        predictions.set(pair.alt);\n        if (!complete) {\n          break;\n        }\n      }\n    }\n    return predictions;\n  }\n  // TODO: If we are doing predicates, there is no point in pursuing\n  //     closure operations if we reach a DFA state that uniquely predicts\n  //     alternative. We will not be caching that DFA state and it is a\n  //     waste to pursue the closure. Might have to advance when we do\n  //     ambig detection thought :(\n  //\n  closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n    const initialDepth = 0;\n    this.closureCheckingStopState(\n      config,\n      configs,\n      closureBusy,\n      collectPredicates,\n      fullCtx,\n      initialDepth,\n      treatEofAsEpsilon\n    );\n  }\n  closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    if (_ParserATNSimulator.traceATNSimulator || _ParserATNSimulator.debugClosure) {\n      console.log(\"closure(\" + config.toString(this.parser, true) + \")\");\n    }\n    if (config.state instanceof RuleStopState) {\n      if (config.context && !config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n            if (fullCtx) {\n              configs.add(\n                ATNConfig.createWithConfig(\n                  config.state,\n                  config,\n                  PredictionContext.EMPTY\n                ),\n                this.mergeCache\n              );\n              continue;\n            } else {\n              if (_ParserATNSimulator.debug) {\n                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n              }\n              this.closure_(\n                config,\n                configs,\n                closureBusy,\n                collectPredicates,\n                fullCtx,\n                depth,\n                treatEofAsEpsilon\n              );\n            }\n            continue;\n          }\n          const returnState = this.atn.states[config.context.getReturnState(i)];\n          const newContext = config.context.getParent(i);\n          const c = ATNConfig.createWithContext(returnState, config.alt, newContext, config.semanticContext);\n          c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n          this.closureCheckingStopState(\n            c,\n            configs,\n            closureBusy,\n            collectPredicates,\n            fullCtx,\n            depth - 1,\n            treatEofAsEpsilon\n          );\n        }\n        return;\n      } else if (fullCtx) {\n        configs.add(config, this.mergeCache);\n        return;\n      } else {\n        if (_ParserATNSimulator.debug) {\n          console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n        }\n      }\n    }\n    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n  }\n  // Do the actual work of walking epsilon edges//\n  closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    const p = config.state;\n    if (!p.epsilonOnlyTransitions) {\n      configs.add(config, this.mergeCache);\n    }\n    for (let i = 0; i < p.transitions.length; i++) {\n      if (i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config)) {\n        continue;\n      }\n      const t = p.transitions[i];\n      const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n      const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n      if (c) {\n        let newDepth = depth;\n        if (config.state.constructor.stateType === ATNState.RULE_STOP) {\n          if (this.predictionState.dfa && this.predictionState?.dfa.isPrecedenceDfa) {\n            const outermostPrecedenceReturn = t.outermostPrecedenceReturn;\n            if (outermostPrecedenceReturn === this.predictionState?.dfa.atnStartState?.ruleIndex) {\n              c.precedenceFilterSuppressed = true;\n            }\n          }\n          c.reachesIntoOuterContext = true;\n          if (closureBusy.getOrAdd(c) !== c) {\n            continue;\n          }\n          configs.dipsIntoOuterContext = true;\n          newDepth -= 1;\n          if (_ParserATNSimulator.debug) {\n            console.log(\"dips into outer ctx: \" + c);\n          }\n        } else {\n          if (!t.isEpsilon && closureBusy.getOrAdd(c) !== c) {\n            continue;\n          }\n          if (t instanceof RuleTransition) {\n            if (newDepth >= 0) {\n              newDepth += 1;\n            }\n          }\n        }\n        this.closureCheckingStopState(\n          c,\n          configs,\n          closureBusy,\n          continueCollecting,\n          fullCtx,\n          newDepth,\n          treatEofAsEpsilon\n        );\n      }\n    }\n  }\n  canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n    const p = config.state;\n    if (p.constructor.stateType !== ATNState.STAR_LOOP_ENTRY || !config.context) {\n      return false;\n    }\n    if (!p.precedenceRuleDecision || config.context.isEmpty() || config.context.hasEmptyPath()) {\n      return false;\n    }\n    const numCtxs = config.context.length;\n    for (let i = 0; i < numCtxs; i++) {\n      const returnState = this.atn.states[config.context.getReturnState(i)];\n      if (returnState.ruleIndex !== p.ruleIndex) {\n        return false;\n      }\n    }\n    const decisionStartState = p.transitions[0].target;\n    const blockEndStateNum = decisionStartState.endState.stateNumber;\n    const blockEndState = this.atn.states[blockEndStateNum];\n    for (let i = 0; i < numCtxs; i++) {\n      const returnStateNumber = config.context.getReturnState(i);\n      const returnState = this.atn.states[returnStateNumber];\n      if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon) {\n        return false;\n      }\n      const returnStateTarget = returnState.transitions[0].target;\n      if (returnState.constructor.stateType === ATNState.BLOCK_END && returnStateTarget === p) {\n        continue;\n      }\n      if (returnState === blockEndState) {\n        continue;\n      }\n      if (returnStateTarget === blockEndState) {\n        continue;\n      }\n      if (returnStateTarget.constructor.stateType === ATNState.BLOCK_END && returnStateTarget.transitions.length === 1 && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p) {\n        continue;\n      }\n      return false;\n    }\n    return true;\n  }\n  getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n    switch (t.transitionType) {\n      case Transition.RULE: {\n        return this.ruleTransition(config, t);\n      }\n      case Transition.PRECEDENCE: {\n        return this.precedenceTransition(\n          config,\n          t,\n          collectPredicates,\n          inContext,\n          fullCtx\n        );\n      }\n      case Transition.PREDICATE: {\n        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n      }\n      case Transition.ACTION: {\n        if (_ParserATNSimulator.debug) {\n          const at = t;\n          const index = at.actionIndex === -1 ? 65535 : at.actionIndex;\n          console.log(\"ACTION edge \" + at.ruleIndex + \":\" + index);\n        }\n        return ATNConfig.createWithConfig(t.target, config);\n      }\n      case Transition.EPSILON: {\n        return ATNConfig.createWithConfig(t.target, config);\n      }\n      case Transition.ATOM:\n      case Transition.RANGE:\n      case Transition.SET: {\n        if (treatEofAsEpsilon) {\n          if (t.matches(Token.EOF, 0, 1)) {\n            return ATNConfig.createWithConfig(t.target, config);\n          }\n        }\n        return null;\n      }\n      default:\n        return null;\n    }\n  }\n  precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.precedence + \">=_p, ctx dependent=true\");\n      if (this.parser !== null) {\n        console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && inContext) {\n      if (fullCtx && this.predictionState?.input) {\n        const currentPosition = this.predictionState.input.index;\n        this.predictionState.input.seek(this.predictionState.startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this.predictionState.outerContext);\n        this.predictionState.input.seek(currentPosition);\n        if (predSucceeds) {\n          c = ATNConfig.createWithConfig(pt.target, config);\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = ATNConfig.createWithSemanticContext(pt.target, config, newSemCtx);\n      }\n    } else {\n      c = ATNConfig.createWithConfig(pt.target, config);\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n  }\n  predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex + \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n      if (this.parser !== null) {\n        console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && (pt.isCtxDependent && inContext || !pt.isCtxDependent)) {\n      if (fullCtx && this.predictionState?.input) {\n        const currentPosition = this.predictionState.input.index;\n        this.predictionState.input.seek(this.predictionState.startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this.predictionState.outerContext);\n        this.predictionState.input.seek(currentPosition);\n        if (predSucceeds) {\n          c = ATNConfig.createWithConfig(pt.target, config);\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = ATNConfig.createWithSemanticContext(pt.target, config, newSemCtx);\n      }\n    } else {\n      c = ATNConfig.createWithConfig(pt.target, config);\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n  }\n  ruleTransition(config, t) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n    }\n    const returnState = t.followState;\n    const newContext = SingletonPredictionContext.create(config.context ?? void 0, returnState.stateNumber);\n    return ATNConfig.createWithConfig(t.target, config, newContext);\n  }\n  getConflictingAlts(configs) {\n    const altSets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.getAlts(altSets);\n  }\n  /**\n   * Sam pointed out a problem with the previous definition, v3, of\n   * ambiguous states. If we have another state associated with conflicting\n   * alternatives, we should keep going. For example, the following grammar\n   *\n   * s : (ID | ID ID?) ';' ;\n   *\n   * When the ATN simulation reaches the state before ';', it has a DFA\n   * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n   * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n   * because alternative to has another way to continue, via [6|2|[]].\n   * The key is that we have a single state that has config's only associated\n   * with a single alternative, 2, and crucially the state transitions\n   * among the configurations are all non-epsilon transitions. That means\n   * we don't consider any conflicts that include alternative 2. So, we\n   * ignore the conflict between alts 1 and 2. We ignore a set of\n   * conflicting alts when there is an intersection with an alternative\n   * associated with a single alt state in the state -> config-list map.\n   *\n   * It's also the case that we might have two conflicting configurations but\n   * also a 3rd nonconflicting configuration for a different alternative:\n   * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n   *\n   * a : A | A | A B ;\n   *\n   * After matching input A, we reach the stop state for rule A, state 1.\n   * State 8 is the state right before B. Clearly alternatives 1 and 2\n   * conflict and no amount of further lookahead will separate the two.\n   * However, alternative 3 will be able to continue and so we do not\n   * stop working on this state. In the previous example, we're concerned\n   * with states associated with the conflicting alternatives. Here alt\n   * 3 is not associated with the conflicting configs, but since we can continue\n   * looking for input reasonably, I don't declare the state done. We\n   * ignore a set of conflicting alts when we have an alternative\n   * that we still need to pursue\n   */\n  getConflictingAltsOrUniqueAlt(configs) {\n    let conflictingAlts;\n    if (configs.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      conflictingAlts = new BitSet();\n      conflictingAlts.set(configs.uniqueAlt);\n    } else {\n      conflictingAlts = configs.conflictingAlts;\n    }\n    return conflictingAlts;\n  }\n  noViableAlt(input, outerContext, configs, startIndex) {\n    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n  }\n  /**\n   * Add an edge to the DFA, if possible. This method calls\n   * {@link addDFAState} to ensure the `to` state is present in the\n   * DFA. If `from` is `null`, or if `t` is outside the\n   * range of edges that can be represented in the DFA tables, this method\n   * returns without adding the edge to the DFA.\n   *\n   * If `to` is `null`, this method returns `null`.\n   * Otherwise, this method returns the {@link DFAState} returned by calling\n   * {@link addDFAState} for the `to` state.\n   *\n   * @param dfa The DFA\n   * @param from The source state for the edge\n   * @param t The input symbol\n   * @param to The target state for the edge\n   *\n   * @returns If `to` is `null`, this method returns `null`;\n   * otherwise this method returns the result of calling {@link addDFAState}\n   * on `to`\n   */\n  addDFAEdge(dfa, from, t, to) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"EDGE \" + from + \" -> \" + to + \" upon \" + this.getTokenName(t));\n    }\n    to = this.addDFAState(dfa, to);\n    if (t < -1 || t > this.atn.maxTokenType) {\n      return to;\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"DFA=\\n\" + dfa.toString(this.parser != null ? this.parser.vocabulary : Vocabulary.EMPTY_VOCABULARY));\n    }\n    from.edges[t + 1] = to;\n    return to;\n  }\n  /**\n   * Add state `D` to the DFA if it is not already present, and return\n   * the actual instance stored in the DFA. If a state equivalent to `D`\n   * is already in the DFA, the existing state is returned. Otherwise this\n   * method returns `D` after adding it to the DFA.\n   *\n   * If `D` is {@link ERROR}, this method returns {@link ERROR} and\n   * does not change the DFA.\n   *\n   * @param dfa The dfa.\n   * @param newState The DFA state to add.\n   *\n   * @returns The state stored in the DFA. This will be either the existing state if `newState` is already in\n   *          the DFA, or `newState` itself if the state was not already present.\n   */\n  addDFAState(dfa, newState) {\n    if (newState === ATNSimulator.ERROR) {\n      return newState;\n    }\n    const existing = dfa.getState(newState);\n    if (existing !== null) {\n      return existing;\n    }\n    if (!newState.configs.readOnly) {\n      newState.configs.optimizeConfigs(this);\n      newState.configs.setReadonly(true);\n    }\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"addDFAState new \" + newState);\n    }\n    dfa.addState(newState);\n    return newState;\n  }\n  reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportAttemptingFullContext(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      conflictingAlts,\n      configs\n    );\n  }\n  reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportContextSensitivity(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      prediction,\n      configs\n    );\n  }\n  // If context sensitive parsing, we know it's ambiguity not conflict.\n  reportAmbiguity(dfa, D, startIndex, stopIndex, exact, ambigAlts, configs) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportAmbiguity(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      exact,\n      ambigAlts,\n      configs\n    );\n  }\n};\n\n// src/atn/PredictionContextCache.ts\nvar PredictionContextCache = class {\n  static {\n    __name(this, \"PredictionContextCache\");\n  }\n  cache = new HashMap(ObjectEqualityComparator.instance);\n  /**\n   * Add a context to the cache and return it. If the context already exists,\n   * return that one instead and do not add a new context to the cache.\n   * Protect shared cache from unsafe thread access.\n   *\n   * @param ctx tbd\n   * @returns tbd\n   */\n  add(ctx) {\n    if (ctx === PredictionContext.EMPTY) {\n      return ctx;\n    }\n    const existing = this.cache.get(ctx);\n    if (existing) {\n      return existing;\n    }\n    this.cache.set(ctx, ctx);\n    return ctx;\n  }\n  get(ctx) {\n    return this.cache.get(ctx);\n  }\n  get length() {\n    return this.cache.size;\n  }\n};\n\n// src/atn/ProfilingATNSimulator.ts\nvar ProfilingATNSimulator = class extends ParserATNSimulator {\n  static {\n    __name(this, \"ProfilingATNSimulator\");\n  }\n  decisions;\n  numDecisions = 0;\n  currentDecision = 0;\n  currentState;\n  /**\n   * At the point of LL failover, we record how SLL would resolve the conflict so that\n   *  we can determine whether or not a decision / input pair is context-sensitive.\n   *  If LL gives a different result than SLL's predicted alternative, we have a\n   *  context sensitivity for sure. The converse is not necessarily true, however.\n   *  It's possible that after conflict resolution chooses minimum alternatives,\n   *  SLL could get the same answer as LL. Regardless of whether or not the result indicates\n   *  an ambiguity, it is not treated as a context sensitivity because LL prediction\n   *  was not required in order to produce a correct prediction for this decision and input sequence.\n   *  It may in fact still be a context sensitivity but we don't know by looking at the\n   *  minimum alternatives for the current input.\n   */\n  conflictingAltResolvedBySLL;\n  #sllStopIndex = 0;\n  #llStopIndex = 0;\n  constructor(parser) {\n    const sharedContextCache = parser.interpreter.sharedContextCache;\n    super(parser, parser.interpreter.atn, parser.interpreter.decisionToDFA, sharedContextCache);\n    if (sharedContextCache) {\n      this.numDecisions = this.atn.decisionToState.length;\n      this.decisions = new Array(this.numDecisions);\n      for (let i = 0; i < this.numDecisions; i++) {\n        this.decisions[i] = new DecisionInfo(i);\n      }\n    }\n  }\n  adaptivePredict(input, decision, outerContext) {\n    try {\n      this.#sllStopIndex = -1;\n      this.#llStopIndex = -1;\n      this.currentDecision = decision;\n      const start = performance.now();\n      const alt = super.adaptivePredict(input, decision, outerContext);\n      const stop = performance.now();\n      this.decisions[decision].timeInPrediction += stop - start;\n      this.decisions[decision].invocations++;\n      const sllLook = this.#sllStopIndex - this.predictionState.startIndex + 1;\n      this.decisions[decision].sllTotalLook += sllLook;\n      this.decisions[decision].sllMinLook = this.decisions[decision].sllMinLook === 0 ? sllLook : Math.min(this.decisions[decision].sllMinLook, sllLook);\n      if (sllLook > this.decisions[decision].sllMaxLook) {\n        this.decisions[decision].sllMaxLook = sllLook;\n        this.decisions[decision].sllMaxLookEvent = {\n          decision,\n          configs: null,\n          predictedAlt: alt,\n          input,\n          startIndex: this.predictionState.startIndex,\n          stopIndex: this.#sllStopIndex,\n          fullCtx: false\n        };\n      }\n      if (this.#llStopIndex >= 0) {\n        const llLook = this.#llStopIndex - this.predictionState.startIndex + 1;\n        this.decisions[decision].llTotalLook += llLook;\n        this.decisions[decision].llMinLook = this.decisions[decision].llMinLook === 0 ? llLook : Math.min(this.decisions[decision].llMinLook, llLook);\n        if (llLook > this.decisions[decision].llMaxLook) {\n          this.decisions[decision].llMaxLook = llLook;\n          this.decisions[decision].llMaxLookEvent = {\n            decision,\n            configs: null,\n            predictedAlt: alt,\n            input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#llStopIndex,\n            fullCtx: true\n          };\n        }\n      }\n      return alt;\n    } finally {\n      this.currentDecision = -1;\n    }\n  }\n  getExistingTargetState(previousD, t) {\n    if (this.predictionState?.input) {\n      this.#sllStopIndex = this.predictionState.input.index;\n      const existingTargetState = super.getExistingTargetState(previousD, t);\n      if (existingTargetState !== null) {\n        this.decisions[this.currentDecision].sllDFATransitions++;\n        if (existingTargetState === ATNSimulator.ERROR) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: previousD.configs,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: false\n          });\n        }\n      }\n      this.currentState = existingTargetState;\n      return existingTargetState;\n    }\n    return void 0;\n  }\n  computeTargetState(dfa, previousD, t) {\n    const state = super.computeTargetState(dfa, previousD, t);\n    this.currentState = state;\n    return state;\n  }\n  computeReachSet(closure, t, fullCtx) {\n    if (fullCtx && this.predictionState?.input) {\n      this.#llStopIndex = this.predictionState.input.index;\n    }\n    const reachConfigs = super.computeReachSet(closure, t, fullCtx);\n    if (this.predictionState?.input) {\n      if (fullCtx) {\n        this.decisions[this.currentDecision].llATNTransitions++;\n        if (reachConfigs === null) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: closure,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: true\n          });\n        }\n      } else {\n        this.decisions[this.currentDecision].sllATNTransitions++;\n        if (reachConfigs === null) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: closure,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: false\n          });\n        }\n      }\n    }\n    return reachConfigs;\n  }\n  reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (conflictingAlts !== null) {\n      this.conflictingAltResolvedBySLL = conflictingAlts.nextSetBit(0);\n    } else {\n      this.conflictingAltResolvedBySLL = configs.getAlts().nextSetBit(0);\n    }\n    this.decisions[this.currentDecision].llFallback++;\n    if (conflictingAlts) {\n      super.reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex);\n    }\n  }\n  reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n    if (prediction !== this.conflictingAltResolvedBySLL && this.predictionState.input) {\n      this.decisions[this.currentDecision].contextSensitivities.push({\n        decision: this.currentDecision,\n        configs,\n        input: this.predictionState.input,\n        startIndex,\n        stopIndex,\n        fullCtx: true\n      });\n    }\n    super.reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex);\n  }\n  reportAmbiguity(dfa, state, startIndex, stopIndex, exact, ambigAlts, configs) {\n    let prediction;\n    if (ambigAlts) {\n      prediction = ambigAlts.nextSetBit(0);\n    } else {\n      prediction = configs.getAlts().nextSetBit(0);\n    }\n    if (this.predictionState?.input) {\n      if (configs.fullCtx && prediction !== this.conflictingAltResolvedBySLL) {\n        this.decisions[this.currentDecision].contextSensitivities.push({\n          decision: this.currentDecision,\n          configs,\n          input: this.predictionState.input,\n          startIndex,\n          stopIndex,\n          fullCtx: true\n        });\n      }\n      this.decisions[this.currentDecision].ambiguities.push({\n        ambigAlts,\n        decision: this.currentDecision,\n        configs,\n        input: this.predictionState.input,\n        startIndex,\n        stopIndex,\n        fullCtx: configs.fullCtx\n      });\n    }\n    super.reportAmbiguity(dfa, state, startIndex, stopIndex, exact, ambigAlts, configs);\n  }\n  getDecisionInfo() {\n    return this.decisions;\n  }\n  getCurrentState() {\n    return this.currentState;\n  }\n};\n\n// src/dfa/PredPrediction.ts\nvar PredPrediction;\n((PredPrediction2) => {\n  PredPrediction2.toString = /* @__PURE__ */ __name((prediction) => {\n    return `(${prediction.pred}, ${prediction.alt})`;\n  }, \"toString\");\n})(PredPrediction || (PredPrediction = {}));\n\n// src/misc/ParseCancellationException.ts\nvar ParseCancellationException = class _ParseCancellationException extends Error {\n  static {\n    __name(this, \"ParseCancellationException\");\n  }\n  constructor(_e) {\n    super();\n    Error.captureStackTrace(this, _ParseCancellationException);\n  }\n};\n\n// src/misc/InterpreterDataReader.ts\nvar InterpreterDataReader = class {\n  static {\n    __name(this, \"InterpreterDataReader\");\n  }\n  /**\n   * The structure of the data file is very simple. Everything is line based with empty lines\n   * separating the different parts. For lexers the layout is:\n   * token literal names:\n   * ...\n   *\n   * token symbolic names:\n   * ...\n   *\n   * rule names:\n   * ...\n   *\n   * channel names:\n   * ...\n   *\n   * mode names:\n   * ...\n   *\n   * atn:\n   * a single line with comma separated int values, enclosed in a pair of squared brackets.\n   *\n   * Data for a parser does not contain channel and mode names.\n   */\n  static parseInterpreterData(source) {\n    const ruleNames = [];\n    const channels = [];\n    const modes = [];\n    const literalNames = [];\n    const symbolicNames = [];\n    const lines = source.split(\"\\n\");\n    let index = 0;\n    let line = lines[index++];\n    if (line !== \"token literal names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      literalNames.push(line === \"null\" ? null : line);\n    } while (true);\n    line = lines[index++];\n    if (line !== \"token symbolic names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      symbolicNames.push(line === \"null\" ? null : line);\n    } while (true);\n    line = lines[index++];\n    if (line !== \"rule names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      ruleNames.push(line);\n    } while (true);\n    line = lines[index++];\n    if (line === \"channel names:\") {\n      do {\n        line = lines[index++];\n        if (line.length === 0) {\n          break;\n        }\n        channels.push(line);\n      } while (true);\n      line = lines[index++];\n      if (line !== \"mode names:\") {\n        throw new Error(\"Unexpected data entry\");\n      }\n      do {\n        line = lines[index++];\n        if (line.length === 0) {\n          break;\n        }\n        modes.push(line);\n      } while (true);\n    }\n    line = lines[index++];\n    if (line !== \"atn:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    line = lines[index++];\n    const elements = line.split(\",\");\n    let value;\n    const serializedATN = [];\n    for (let i = 0; i < elements.length; ++i) {\n      const element = elements[i];\n      if (element.startsWith(\"[\")) {\n        value = Number(element.substring(1).trim());\n      } else if (element.endsWith(\"]\")) {\n        value = Number(element.substring(0, element.length - 1).trim());\n      } else {\n        value = Number(element.trim());\n      }\n      serializedATN[i] = value;\n    }\n    const deserializer = new ATNDeserializer();\n    return {\n      atn: deserializer.deserialize(serializedATN),\n      vocabulary: new Vocabulary(literalNames, symbolicNames, []),\n      ruleNames,\n      channels: channels.length > 0 ? channels : void 0,\n      modes: modes.length > 0 ? modes : void 0\n    };\n  }\n};\n\n// src/tree/AbstractParseTreeVisitor.ts\nvar AbstractParseTreeVisitor = class {\n  static {\n    __name(this, \"AbstractParseTreeVisitor\");\n  }\n  visit(tree) {\n    return tree.accept(this);\n  }\n  visitChildren(node) {\n    let result = this.defaultResult();\n    const n2 = node.getChildCount();\n    for (let i = 0; i < n2; i++) {\n      if (!this.shouldVisitNextChild(node, result)) {\n        break;\n      }\n      const c = node.getChild(i);\n      if (c) {\n        const childResult = c.accept(this);\n        result = this.aggregateResult(result, childResult);\n      }\n    }\n    return result;\n  }\n  visitTerminal(_node) {\n    return this.defaultResult();\n  }\n  visitErrorNode(_node) {\n    return this.defaultResult();\n  }\n  defaultResult() {\n    return null;\n  }\n  shouldVisitNextChild(_node, _currentResult) {\n    return true;\n  }\n  aggregateResult(aggregate, nextResult) {\n    return nextResult;\n  }\n};\n\n// src/tree/ParseTreeWalker.ts\nvar ParseTreeWalker = class _ParseTreeWalker {\n  static {\n    __name(this, \"ParseTreeWalker\");\n  }\n  static DEFAULT = new _ParseTreeWalker();\n  /**\n   * Performs a walk on the given parse tree starting at the root and going down recursively\n   * with depth-first search. On each node, {@link ParseTreeWalker.enterRule} is called before\n   * recursively walking down into child nodes, then\n   * {@link ParseTreeWalker.exitRule} is called after the recursive call to wind up.\n   *\n   * @param listener The listener used by the walker to process grammar rules\n   * @param t The parse tree to be walked on\n   */\n  walk(listener, t) {\n    const errorNode = t instanceof ErrorNode;\n    if (errorNode) {\n      listener.visitErrorNode(t);\n    } else if (t instanceof TerminalNode) {\n      listener.visitTerminal(t);\n    } else {\n      const r = t;\n      this.enterRule(listener, r);\n      for (let i = 0; i < t.getChildCount(); i++) {\n        this.walk(listener, t.getChild(i));\n      }\n      this.exitRule(listener, r);\n    }\n  }\n  /**\n   * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener.enterEveryRule}\n   * then by triggering the event specific to the given parse tree node\n   *\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  enterRule(listener, r) {\n    const ctx = r.ruleContext;\n    listener.enterEveryRule(ctx);\n    ctx.enterRule(listener);\n  }\n  /**\n   * Exits a grammar rule by first triggering the event specific to the given parse tree node\n   * then by triggering the generic event {@link ParseTreeListener.exitEveryRule}\n   *\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  exitRule(listener, r) {\n    const ctx = r.ruleContext;\n    ctx.exitRule(listener);\n    listener.exitEveryRule(ctx);\n  }\n};\n\n// src/CharStream.ts\nvar CharStream;\n((CharStream2) => {\n  CharStream2.fromString = /* @__PURE__ */ __name((str) => {\n    return new CharStreamImpl(str);\n  }, \"fromString\");\n})(CharStream || (CharStream = {}));\nvar CharStreamImpl = class {\n  static {\n    __name(this, \"CharStreamImpl\");\n  }\n  name = \"\";\n  index = 0;\n  data;\n  constructor(input) {\n    const codePoints = [];\n    for (const char of input) {\n      codePoints.push(char.codePointAt(0));\n    }\n    this.data = new Uint32Array(codePoints);\n  }\n  /**\n   * Reset the stream so that it's in the same state it was\n   * when the object was created *except* the data array is not\n   * touched.\n   */\n  reset() {\n    this.index = 0;\n  }\n  consume() {\n    if (this.index >= this.data.length) {\n      throw new Error(\"cannot consume EOF\");\n    }\n    this.index += 1;\n  }\n  LA(offset) {\n    if (offset === 0) {\n      return 0;\n    }\n    if (offset < 0) {\n      offset += 1;\n    }\n    const pos = this.index + offset - 1;\n    if (pos < 0 || pos >= this.data.length) {\n      return Token.EOF;\n    }\n    return this.data[pos];\n  }\n  // mark/release do nothing; we have entire buffer\n  mark() {\n    return -1;\n  }\n  release(_marker) {\n  }\n  /**\n   * consume() ahead until p==_index; can't just set p=_index as we must\n   * update line and column. If we seek backwards, just set p\n   */\n  seek(index) {\n    if (index <= this.index) {\n      this.index = index;\n      return;\n    }\n    this.index = Math.min(index, this.data.length);\n  }\n  getTextFromRange(start, stop) {\n    stop = stop ?? this.data.length - 1;\n    if (stop >= this.data.length) {\n      stop = this.data.length - 1;\n    }\n    if (start >= this.data.length) {\n      return \"\";\n    }\n    return this.#stringFromRange(start, stop + 1);\n  }\n  getTextFromInterval(interval) {\n    const start = interval.start;\n    let stop = interval.stop;\n    if (stop >= this.data.length) {\n      stop = this.data.length - 1;\n    }\n    if (start >= this.data.length) {\n      return \"\";\n    }\n    return this.#stringFromRange(start, stop + 1);\n  }\n  toString() {\n    return this.#stringFromRange(0);\n  }\n  get size() {\n    return this.data.length;\n  }\n  getSourceName() {\n    if (this.name) {\n      return this.name;\n    }\n    return IntStream.UNKNOWN_SOURCE_NAME;\n  }\n  #stringFromRange(start, stop) {\n    const data = this.data.slice(start, stop);\n    let result = \"\";\n    data.forEach((value) => {\n      result += String.fromCodePoint(value);\n    });\n    return result;\n  }\n};\n\n// src/BufferedTokenStream.ts\nvar BufferedTokenStream = class {\n  static {\n    __name(this, \"BufferedTokenStream\");\n  }\n  /**\n   * The {@link TokenSource} from which tokens for this stream are fetched.\n   */\n  tokenSource;\n  /**\n   * A collection of all tokens fetched from the token source. The list is\n   * considered a complete view of the input once {@link fetchedEOF} is set\n   * to `true`.\n   */\n  tokens = [];\n  /**\n   * The index into {@link tokens} of the current token (next token to\n   * {@link consume}). {@link tokens}`[p]` should be\n   * {@link LT LT(1)}.\n   *\n   * This field is set to -1 when the stream is first constructed or when\n   * {@link setTokenSource} is called, indicating that the first token has\n   * not yet been fetched from the token source. For additional information,\n   * see the documentation of {@link IntStream} for a description of\n   * Initializing Methods.\n   */\n  p = -1;\n  /**\n   * Indicates whether the {@link Token.EOF} token has been fetched from\n   * {@link tokenSource} and added to {@link tokens}. This field improves\n   * performance for the following cases:\n   *\n   * - {@link consume}: The lookahead check in {@link consume} to prevent\n   * consuming the EOF symbol is optimized by checking the values of\n   * {@link fetchedEOF} and {@link p} instead of calling {@link LA}.\n   * - {@link fetch}: The check to prevent adding multiple EOF symbols into\n   * {@link tokens} is trivial with this field.\n   */\n  fetchedEOF = false;\n  constructor(tokenSource) {\n    this.tokenSource = tokenSource;\n  }\n  mark() {\n    return 0;\n  }\n  release(_marker) {\n  }\n  reset() {\n    this.seek(0);\n  }\n  seek(index) {\n    this.lazyInit();\n    this.p = this.adjustSeekIndex(index);\n  }\n  get size() {\n    return this.tokens.length;\n  }\n  get index() {\n    return this.p;\n  }\n  get(index) {\n    this.lazyInit();\n    return this.tokens[index];\n  }\n  consume() {\n    let skipEofCheck = false;\n    if (this.p >= 0) {\n      if (this.fetchedEOF) {\n        skipEofCheck = this.p < this.tokens.length - 1;\n      } else {\n        skipEofCheck = this.p < this.tokens.length;\n      }\n    } else {\n      skipEofCheck = false;\n    }\n    if (!skipEofCheck && this.LA(1) === Token.EOF) {\n      throw new Error(\"cannot consume EOF\");\n    }\n    if (this.sync(this.p + 1)) {\n      this.p = this.adjustSeekIndex(this.p + 1);\n    }\n  }\n  /**\n   * Make sure index `i` in tokens has a token.\n   *\n   * @returns {boolean} `true` if a token is located at index `i`, otherwise `false`.\n   */\n  sync(i) {\n    const n2 = i - this.tokens.length + 1;\n    if (n2 > 0) {\n      const fetched = this.fetch(n2);\n      return fetched >= n2;\n    }\n    return true;\n  }\n  /**\n   * Add `n` elements to buffer.\n   *\n   * @returns {number} The actual number of elements added to the buffer.\n   */\n  fetch(n2) {\n    if (this.fetchedEOF) {\n      return 0;\n    }\n    for (let i = 0; i < n2; i++) {\n      const t = this.tokenSource.nextToken();\n      t.tokenIndex = this.tokens.length;\n      this.tokens.push(t);\n      if (t.type === Token.EOF) {\n        this.fetchedEOF = true;\n        return i + 1;\n      }\n    }\n    return n2;\n  }\n  /** Get all tokens from start..stop, inclusively. */\n  getTokens(start, stop, types) {\n    this.lazyInit();\n    if (start === void 0 && stop === void 0) {\n      return this.tokens;\n    }\n    start ??= 0;\n    if (stop === void 0) {\n      stop = this.tokens.length - 1;\n    }\n    if (start < 0 || stop >= this.tokens.length || stop < 0 || start >= this.tokens.length) {\n      throw new RangeError(\"start \" + start + \" or stop \" + stop + \" not in 0..\" + (this.tokens.length - 1));\n    }\n    if (start > stop) {\n      return [];\n    }\n    if (types === void 0) {\n      return this.tokens.slice(start, stop + 1);\n    }\n    const subset = [];\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    for (let i = start; i < stop; i++) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        subset.push(t);\n        break;\n      }\n      if (types.has(t.type)) {\n        subset.push(t);\n      }\n    }\n    return subset;\n  }\n  LA(k) {\n    return this.LT(k)?.type ?? Token.INVALID_TYPE;\n  }\n  LB(k) {\n    if (this.p - k < 0) {\n      return null;\n    }\n    return this.tokens[this.p - k];\n  }\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    const i = this.p + k - 1;\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      return this.tokens[this.tokens.length - 1];\n    }\n    return this.tokens[i];\n  }\n  /**\n   * Allowed derived classes to modify the behavior of operations which change\n   * the current stream position by adjusting the target token index of a seek\n   * operation. The default implementation simply returns `i`. If an\n   * exception is thrown in this method, the current stream index should not be\n   * changed.\n   *\n   * For example, {@link CommonTokenStream} overrides this method to ensure that\n   * the seek target is always an on-channel token.\n   *\n   * @param  i The target token index.\n   *\n   * @returns The adjusted target token index.\n   */\n  adjustSeekIndex(i) {\n    return i;\n  }\n  lazyInit() {\n    if (this.p === -1) {\n      this.setup();\n    }\n  }\n  setup() {\n    this.sync(0);\n    this.p = this.adjustSeekIndex(0);\n  }\n  /** Reset this token stream by setting its token source. */\n  setTokenSource(tokenSource) {\n    this.tokenSource = tokenSource;\n    this.tokens = [];\n    this.p = -1;\n    this.fetchedEOF = false;\n  }\n  /**\n   * Given a starting index, return the index of the next token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and EOF.\n   */\n  nextTokenOnChannel(i, channel) {\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      return -1;\n    }\n    let token = this.tokens[i];\n    while (token.channel !== channel) {\n      if (token.type === Token.EOF) {\n        return -1;\n      }\n      i += 1;\n      this.sync(i);\n      token = this.tokens[i];\n    }\n    return i;\n  }\n  /**\n   * Given a starting index, return the index of the previous token on\n   * channel. Return `i` if `tokens[i]` is on channel. Return -1\n   * if there are no tokens on channel between `i` and 0.\n   *\n   * If `i` specifies an index at or after the EOF token, the EOF token\n   * index is returned. This is due to the fact that the EOF token is treated\n   * as though it were on every channel.\n   */\n  previousTokenOnChannel(i, channel) {\n    if (i >= this.tokens.length) {\n      return this.tokens.length - 1;\n    }\n    while (i >= 0) {\n      const token = this.tokens[i];\n      if (token.type === Token.EOF || token.channel === channel) {\n        return i;\n      }\n      --i;\n    }\n    return i;\n  }\n  /**\n   * Collect all tokens on specified channel to the right of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n   * EOF. If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToRight(tokenIndex, channel) {\n    if (channel === void 0) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw new Error(`${tokenIndex} not in 0..${this.tokens.length - 1}`);\n    }\n    const nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    const from = tokenIndex + 1;\n    const to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n    return this.filterForChannel(from, to, channel);\n  }\n  /**\n   * Collect all tokens on specified channel to the left of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n   * If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToLeft(tokenIndex, channel) {\n    if (channel === void 0) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw new Error(`${tokenIndex} not in 0..${this.tokens.length - 1}`);\n    }\n    const prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    if (prevOnChannel === tokenIndex - 1) {\n      return void 0;\n    }\n    const from = prevOnChannel + 1;\n    const to = tokenIndex - 1;\n    return this.filterForChannel(from, to, channel);\n  }\n  filterForChannel(left, right, channel) {\n    const hidden = [];\n    for (let i = left; i < right + 1; i++) {\n      const t = this.tokens[i];\n      if (channel === -1) {\n        if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n          hidden.push(t);\n        }\n      } else if (t.channel === channel) {\n        hidden.push(t);\n      }\n    }\n    if (hidden.length === 0) {\n      return void 0;\n    }\n    return hidden;\n  }\n  getSourceName() {\n    return this.tokenSource.sourceName;\n  }\n  /** Get the text of all tokens in this buffer. */\n  getText() {\n    return this.getTextFromInterval(Interval.of(0, this.size - 1));\n  }\n  getTextFromInterval(interval) {\n    const start = interval.start;\n    let stop = interval.stop;\n    if (start < 0 || stop < 0) {\n      return \"\";\n    }\n    this.sync(stop);\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    let result = \"\";\n    for (let i = start; i <= stop; ++i) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        break;\n      }\n      result += t.text;\n    }\n    return result;\n  }\n  getTextFromContext(ctx) {\n    return this.getTextFromInterval(ctx.getSourceInterval());\n  }\n  getTextFromRange(start, stop) {\n    if (start !== null && stop !== null) {\n      return this.getTextFromInterval(Interval.of(start.tokenIndex, stop.tokenIndex));\n    }\n    return \"\";\n  }\n  /** Get all tokens from lexer until EOF. */\n  fill() {\n    this.lazyInit();\n    while (this.fetch(1e3) === 1e3) {\n      ;\n    }\n  }\n};\n\n// src/CommonTokenStream.ts\nvar CommonTokenStream = class extends BufferedTokenStream {\n  static {\n    __name(this, \"CommonTokenStream\");\n  }\n  /**\n   * Specifies the channel to use for filtering tokens.\n   *\n   *\n   * The default value is {@link Token.DEFAULT_CHANNEL}, which matches the\n   * default channel assigned to tokens created by the lexer.\n   */\n  channel = Token.DEFAULT_CHANNEL;\n  constructor(lexer, channel) {\n    super(lexer);\n    this.channel = channel ?? Token.DEFAULT_CHANNEL;\n  }\n  adjustSeekIndex(i) {\n    return this.nextTokenOnChannel(i, this.channel);\n  }\n  LB(k) {\n    if (k === 0 || this.index - k < 0) {\n      return null;\n    }\n    let i = this.index;\n    let n2 = 1;\n    while (n2 <= k) {\n      i = this.previousTokenOnChannel(i - 1, this.channel);\n      n2 += 1;\n    }\n    if (i < 0) {\n      return null;\n    }\n    return this.tokens[i];\n  }\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    let i = this.index;\n    let n2 = 1;\n    while (n2 < k) {\n      if (this.sync(i + 1)) {\n        i = this.nextTokenOnChannel(i + 1, this.channel);\n      }\n      n2 += 1;\n    }\n    return this.tokens[i];\n  }\n  // Count EOF just once.\n  getNumberOfOnChannelTokens() {\n    let n2 = 0;\n    this.fill();\n    for (const t of this.tokens) {\n      if (t.channel === this.channel) {\n        n2 += 1;\n      }\n      if (t.type === Token.EOF) {\n        break;\n      }\n    }\n    return n2;\n  }\n};\n\n// src/tree/xpath/XPathLexer.ts\nvar XPathLexer = class _XPathLexer extends Lexer {\n  static {\n    __name(this, \"XPathLexer\");\n  }\n  static TOKEN_REF = 1;\n  static RULE_REF = 2;\n  static ANYWHERE = 3;\n  static ROOT = 4;\n  static WILDCARD = 5;\n  static BANG = 6;\n  static ID = 7;\n  static STRING = 8;\n  static channelNames = [\n    \"DEFAULT_TOKEN_CHANNEL\",\n    \"HIDDEN\"\n  ];\n  static literalNames = [\n    null,\n    null,\n    null,\n    \"'//'\",\n    \"'/'\",\n    \"'*'\",\n    \"'!'\"\n  ];\n  static symbolicNames = [\n    null,\n    \"TOKEN_REF\",\n    \"RULE_REF\",\n    \"ANYWHERE\",\n    \"ROOT\",\n    \"WILDCARD\",\n    \"BANG\",\n    \"ID\",\n    \"STRING\"\n  ];\n  static modeNames = [\n    \"DEFAULT_MODE\"\n  ];\n  static ruleNames = [\n    \"ANYWHERE\",\n    \"ROOT\",\n    \"WILDCARD\",\n    \"BANG\",\n    \"ID\",\n    \"NameChar\",\n    \"NameStartChar\",\n    \"STRING\"\n  ];\n  constructor(input) {\n    super(input);\n    this.interpreter = new LexerATNSimulator(this, _XPathLexer._ATN, _XPathLexer.decisionsToDFA, new PredictionContextCache());\n  }\n  get grammarFileName() {\n    return \"XPathLexer.g4\";\n  }\n  get literalNames() {\n    return _XPathLexer.literalNames;\n  }\n  get symbolicNames() {\n    return _XPathLexer.symbolicNames;\n  }\n  get ruleNames() {\n    return _XPathLexer.ruleNames;\n  }\n  get serializedATN() {\n    return _XPathLexer._serializedATN;\n  }\n  get channelNames() {\n    return _XPathLexer.channelNames;\n  }\n  get modeNames() {\n    return _XPathLexer.modeNames;\n  }\n  action(localContext, ruleIndex, actionIndex) {\n    switch (ruleIndex) {\n      case 4:\n        this.ID_action(localContext, actionIndex);\n        break;\n    }\n  }\n  ID_action(localContext, actionIndex) {\n    switch (actionIndex) {\n      case 0:\n        const text = this.text;\n        if (text.charAt(0) === text.charAt(0).toUpperCase()) {\n          this.type = _XPathLexer.TOKEN_REF;\n        } else {\n          this.type = _XPathLexer.RULE_REF;\n        }\n        break;\n    }\n  }\n  static _serializedATN = [\n    4,\n    0,\n    8,\n    48,\n    6,\n    -1,\n    2,\n    0,\n    7,\n    0,\n    2,\n    1,\n    7,\n    1,\n    2,\n    2,\n    7,\n    2,\n    2,\n    3,\n    7,\n    3,\n    2,\n    4,\n    7,\n    4,\n    2,\n    5,\n    7,\n    5,\n    2,\n    6,\n    7,\n    6,\n    2,\n    7,\n    7,\n    7,\n    1,\n    0,\n    1,\n    0,\n    1,\n    0,\n    1,\n    1,\n    1,\n    1,\n    1,\n    2,\n    1,\n    2,\n    1,\n    3,\n    1,\n    3,\n    1,\n    4,\n    1,\n    4,\n    5,\n    4,\n    29,\n    8,\n    4,\n    10,\n    4,\n    12,\n    4,\n    32,\n    9,\n    4,\n    1,\n    4,\n    1,\n    4,\n    1,\n    5,\n    1,\n    5,\n    1,\n    6,\n    1,\n    6,\n    1,\n    7,\n    1,\n    7,\n    5,\n    7,\n    42,\n    8,\n    7,\n    10,\n    7,\n    12,\n    7,\n    45,\n    9,\n    7,\n    1,\n    7,\n    1,\n    7,\n    1,\n    43,\n    0,\n    8,\n    1,\n    3,\n    3,\n    4,\n    5,\n    5,\n    7,\n    6,\n    9,\n    7,\n    11,\n    0,\n    13,\n    0,\n    15,\n    8,\n    1,\n    0,\n    2,\n    784,\n    0,\n    0,\n    8,\n    14,\n    27,\n    48,\n    57,\n    65,\n    90,\n    95,\n    95,\n    97,\n    122,\n    127,\n    159,\n    170,\n    170,\n    173,\n    173,\n    181,\n    181,\n    186,\n    186,\n    192,\n    214,\n    216,\n    246,\n    248,\n    705,\n    710,\n    721,\n    736,\n    740,\n    748,\n    748,\n    750,\n    750,\n    768,\n    884,\n    886,\n    887,\n    890,\n    893,\n    895,\n    895,\n    902,\n    902,\n    904,\n    906,\n    908,\n    908,\n    910,\n    929,\n    931,\n    1013,\n    1015,\n    1153,\n    1155,\n    1159,\n    1162,\n    1327,\n    1329,\n    1366,\n    1369,\n    1369,\n    1376,\n    1416,\n    1425,\n    1469,\n    1471,\n    1471,\n    1473,\n    1474,\n    1476,\n    1477,\n    1479,\n    1479,\n    1488,\n    1514,\n    1519,\n    1522,\n    1536,\n    1541,\n    1552,\n    1562,\n    1564,\n    1564,\n    1568,\n    1641,\n    1646,\n    1747,\n    1749,\n    1757,\n    1759,\n    1768,\n    1770,\n    1788,\n    1791,\n    1791,\n    1807,\n    1866,\n    1869,\n    1969,\n    1984,\n    2037,\n    2042,\n    2042,\n    2045,\n    2045,\n    2048,\n    2093,\n    2112,\n    2139,\n    2144,\n    2154,\n    2160,\n    2183,\n    2185,\n    2190,\n    2192,\n    2193,\n    2200,\n    2403,\n    2406,\n    2415,\n    2417,\n    2435,\n    2437,\n    2444,\n    2447,\n    2448,\n    2451,\n    2472,\n    2474,\n    2480,\n    2482,\n    2482,\n    2486,\n    2489,\n    2492,\n    2500,\n    2503,\n    2504,\n    2507,\n    2510,\n    2519,\n    2519,\n    2524,\n    2525,\n    2527,\n    2531,\n    2534,\n    2545,\n    2556,\n    2556,\n    2558,\n    2558,\n    2561,\n    2563,\n    2565,\n    2570,\n    2575,\n    2576,\n    2579,\n    2600,\n    2602,\n    2608,\n    2610,\n    2611,\n    2613,\n    2614,\n    2616,\n    2617,\n    2620,\n    2620,\n    2622,\n    2626,\n    2631,\n    2632,\n    2635,\n    2637,\n    2641,\n    2641,\n    2649,\n    2652,\n    2654,\n    2654,\n    2662,\n    2677,\n    2689,\n    2691,\n    2693,\n    2701,\n    2703,\n    2705,\n    2707,\n    2728,\n    2730,\n    2736,\n    2738,\n    2739,\n    2741,\n    2745,\n    2748,\n    2757,\n    2759,\n    2761,\n    2763,\n    2765,\n    2768,\n    2768,\n    2784,\n    2787,\n    2790,\n    2799,\n    2809,\n    2815,\n    2817,\n    2819,\n    2821,\n    2828,\n    2831,\n    2832,\n    2835,\n    2856,\n    2858,\n    2864,\n    2866,\n    2867,\n    2869,\n    2873,\n    2876,\n    2884,\n    2887,\n    2888,\n    2891,\n    2893,\n    2901,\n    2903,\n    2908,\n    2909,\n    2911,\n    2915,\n    2918,\n    2927,\n    2929,\n    2929,\n    2946,\n    2947,\n    2949,\n    2954,\n    2958,\n    2960,\n    2962,\n    2965,\n    2969,\n    2970,\n    2972,\n    2972,\n    2974,\n    2975,\n    2979,\n    2980,\n    2984,\n    2986,\n    2990,\n    3001,\n    3006,\n    3010,\n    3014,\n    3016,\n    3018,\n    3021,\n    3024,\n    3024,\n    3031,\n    3031,\n    3046,\n    3055,\n    3072,\n    3084,\n    3086,\n    3088,\n    3090,\n    3112,\n    3114,\n    3129,\n    3132,\n    3140,\n    3142,\n    3144,\n    3146,\n    3149,\n    3157,\n    3158,\n    3160,\n    3162,\n    3165,\n    3165,\n    3168,\n    3171,\n    3174,\n    3183,\n    3200,\n    3203,\n    3205,\n    3212,\n    3214,\n    3216,\n    3218,\n    3240,\n    3242,\n    3251,\n    3253,\n    3257,\n    3260,\n    3268,\n    3270,\n    3272,\n    3274,\n    3277,\n    3285,\n    3286,\n    3293,\n    3294,\n    3296,\n    3299,\n    3302,\n    3311,\n    3313,\n    3315,\n    3328,\n    3340,\n    3342,\n    3344,\n    3346,\n    3396,\n    3398,\n    3400,\n    3402,\n    3406,\n    3412,\n    3415,\n    3423,\n    3427,\n    3430,\n    3439,\n    3450,\n    3455,\n    3457,\n    3459,\n    3461,\n    3478,\n    3482,\n    3505,\n    3507,\n    3515,\n    3517,\n    3517,\n    3520,\n    3526,\n    3530,\n    3530,\n    3535,\n    3540,\n    3542,\n    3542,\n    3544,\n    3551,\n    3558,\n    3567,\n    3570,\n    3571,\n    3585,\n    3642,\n    3648,\n    3662,\n    3664,\n    3673,\n    3713,\n    3714,\n    3716,\n    3716,\n    3718,\n    3722,\n    3724,\n    3747,\n    3749,\n    3749,\n    3751,\n    3773,\n    3776,\n    3780,\n    3782,\n    3782,\n    3784,\n    3790,\n    3792,\n    3801,\n    3804,\n    3807,\n    3840,\n    3840,\n    3864,\n    3865,\n    3872,\n    3881,\n    3893,\n    3893,\n    3895,\n    3895,\n    3897,\n    3897,\n    3902,\n    3911,\n    3913,\n    3948,\n    3953,\n    3972,\n    3974,\n    3991,\n    3993,\n    4028,\n    4038,\n    4038,\n    4096,\n    4169,\n    4176,\n    4253,\n    4256,\n    4293,\n    4295,\n    4295,\n    4301,\n    4301,\n    4304,\n    4346,\n    4348,\n    4680,\n    4682,\n    4685,\n    4688,\n    4694,\n    4696,\n    4696,\n    4698,\n    4701,\n    4704,\n    4744,\n    4746,\n    4749,\n    4752,\n    4784,\n    4786,\n    4789,\n    4792,\n    4798,\n    4800,\n    4800,\n    4802,\n    4805,\n    4808,\n    4822,\n    4824,\n    4880,\n    4882,\n    4885,\n    4888,\n    4954,\n    4957,\n    4959,\n    4992,\n    5007,\n    5024,\n    5109,\n    5112,\n    5117,\n    5121,\n    5740,\n    5743,\n    5759,\n    5761,\n    5786,\n    5792,\n    5866,\n    5870,\n    5880,\n    5888,\n    5909,\n    5919,\n    5940,\n    5952,\n    5971,\n    5984,\n    5996,\n    5998,\n    6e3,\n    6002,\n    6003,\n    6016,\n    6099,\n    6103,\n    6103,\n    6108,\n    6109,\n    6112,\n    6121,\n    6155,\n    6169,\n    6176,\n    6264,\n    6272,\n    6314,\n    6320,\n    6389,\n    6400,\n    6430,\n    6432,\n    6443,\n    6448,\n    6459,\n    6470,\n    6509,\n    6512,\n    6516,\n    6528,\n    6571,\n    6576,\n    6601,\n    6608,\n    6617,\n    6656,\n    6683,\n    6688,\n    6750,\n    6752,\n    6780,\n    6783,\n    6793,\n    6800,\n    6809,\n    6823,\n    6823,\n    6832,\n    6845,\n    6847,\n    6862,\n    6912,\n    6988,\n    6992,\n    7001,\n    7019,\n    7027,\n    7040,\n    7155,\n    7168,\n    7223,\n    7232,\n    7241,\n    7245,\n    7293,\n    7296,\n    7304,\n    7312,\n    7354,\n    7357,\n    7359,\n    7376,\n    7378,\n    7380,\n    7418,\n    7424,\n    7957,\n    7960,\n    7965,\n    7968,\n    8005,\n    8008,\n    8013,\n    8016,\n    8023,\n    8025,\n    8025,\n    8027,\n    8027,\n    8029,\n    8029,\n    8031,\n    8061,\n    8064,\n    8116,\n    8118,\n    8124,\n    8126,\n    8126,\n    8130,\n    8132,\n    8134,\n    8140,\n    8144,\n    8147,\n    8150,\n    8155,\n    8160,\n    8172,\n    8178,\n    8180,\n    8182,\n    8188,\n    8203,\n    8207,\n    8234,\n    8238,\n    8255,\n    8256,\n    8276,\n    8276,\n    8288,\n    8292,\n    8294,\n    8303,\n    8305,\n    8305,\n    8319,\n    8319,\n    8336,\n    8348,\n    8400,\n    8412,\n    8417,\n    8417,\n    8421,\n    8432,\n    8450,\n    8450,\n    8455,\n    8455,\n    8458,\n    8467,\n    8469,\n    8469,\n    8473,\n    8477,\n    8484,\n    8484,\n    8486,\n    8486,\n    8488,\n    8488,\n    8490,\n    8493,\n    8495,\n    8505,\n    8508,\n    8511,\n    8517,\n    8521,\n    8526,\n    8526,\n    8544,\n    8584,\n    11264,\n    11492,\n    11499,\n    11507,\n    11520,\n    11557,\n    11559,\n    11559,\n    11565,\n    11565,\n    11568,\n    11623,\n    11631,\n    11631,\n    11647,\n    11670,\n    11680,\n    11686,\n    11688,\n    11694,\n    11696,\n    11702,\n    11704,\n    11710,\n    11712,\n    11718,\n    11720,\n    11726,\n    11728,\n    11734,\n    11736,\n    11742,\n    11744,\n    11775,\n    11823,\n    11823,\n    12293,\n    12295,\n    12321,\n    12335,\n    12337,\n    12341,\n    12344,\n    12348,\n    12353,\n    12438,\n    12441,\n    12442,\n    12445,\n    12447,\n    12449,\n    12538,\n    12540,\n    12543,\n    12549,\n    12591,\n    12593,\n    12686,\n    12704,\n    12735,\n    12784,\n    12799,\n    13312,\n    19903,\n    19968,\n    42124,\n    42192,\n    42237,\n    42240,\n    42508,\n    42512,\n    42539,\n    42560,\n    42607,\n    42612,\n    42621,\n    42623,\n    42737,\n    42775,\n    42783,\n    42786,\n    42888,\n    42891,\n    42954,\n    42960,\n    42961,\n    42963,\n    42963,\n    42965,\n    42969,\n    42994,\n    43047,\n    43052,\n    43052,\n    43072,\n    43123,\n    43136,\n    43205,\n    43216,\n    43225,\n    43232,\n    43255,\n    43259,\n    43259,\n    43261,\n    43309,\n    43312,\n    43347,\n    43360,\n    43388,\n    43392,\n    43456,\n    43471,\n    43481,\n    43488,\n    43518,\n    43520,\n    43574,\n    43584,\n    43597,\n    43600,\n    43609,\n    43616,\n    43638,\n    43642,\n    43714,\n    43739,\n    43741,\n    43744,\n    43759,\n    43762,\n    43766,\n    43777,\n    43782,\n    43785,\n    43790,\n    43793,\n    43798,\n    43808,\n    43814,\n    43816,\n    43822,\n    43824,\n    43866,\n    43868,\n    43881,\n    43888,\n    44010,\n    44012,\n    44013,\n    44016,\n    44025,\n    44032,\n    55203,\n    55216,\n    55238,\n    55243,\n    55291,\n    63744,\n    64109,\n    64112,\n    64217,\n    64256,\n    64262,\n    64275,\n    64279,\n    64285,\n    64296,\n    64298,\n    64310,\n    64312,\n    64316,\n    64318,\n    64318,\n    64320,\n    64321,\n    64323,\n    64324,\n    64326,\n    64433,\n    64467,\n    64829,\n    64848,\n    64911,\n    64914,\n    64967,\n    65008,\n    65019,\n    65024,\n    65039,\n    65056,\n    65071,\n    65075,\n    65076,\n    65101,\n    65103,\n    65136,\n    65140,\n    65142,\n    65276,\n    65279,\n    65279,\n    65296,\n    65305,\n    65313,\n    65338,\n    65343,\n    65343,\n    65345,\n    65370,\n    65382,\n    65470,\n    65474,\n    65479,\n    65482,\n    65487,\n    65490,\n    65495,\n    65498,\n    65500,\n    65529,\n    65531,\n    65536,\n    65547,\n    65549,\n    65574,\n    65576,\n    65594,\n    65596,\n    65597,\n    65599,\n    65613,\n    65616,\n    65629,\n    65664,\n    65786,\n    65856,\n    65908,\n    66045,\n    66045,\n    66176,\n    66204,\n    66208,\n    66256,\n    66272,\n    66272,\n    66304,\n    66335,\n    66349,\n    66378,\n    66384,\n    66426,\n    66432,\n    66461,\n    66464,\n    66499,\n    66504,\n    66511,\n    66513,\n    66517,\n    66560,\n    66717,\n    66720,\n    66729,\n    66736,\n    66771,\n    66776,\n    66811,\n    66816,\n    66855,\n    66864,\n    66915,\n    66928,\n    66938,\n    66940,\n    66954,\n    66956,\n    66962,\n    66964,\n    66965,\n    66967,\n    66977,\n    66979,\n    66993,\n    66995,\n    67001,\n    67003,\n    67004,\n    67072,\n    67382,\n    67392,\n    67413,\n    67424,\n    67431,\n    67456,\n    67461,\n    67463,\n    67504,\n    67506,\n    67514,\n    67584,\n    67589,\n    67592,\n    67592,\n    67594,\n    67637,\n    67639,\n    67640,\n    67644,\n    67644,\n    67647,\n    67669,\n    67680,\n    67702,\n    67712,\n    67742,\n    67808,\n    67826,\n    67828,\n    67829,\n    67840,\n    67861,\n    67872,\n    67897,\n    67968,\n    68023,\n    68030,\n    68031,\n    68096,\n    68099,\n    68101,\n    68102,\n    68108,\n    68115,\n    68117,\n    68119,\n    68121,\n    68149,\n    68152,\n    68154,\n    68159,\n    68159,\n    68192,\n    68220,\n    68224,\n    68252,\n    68288,\n    68295,\n    68297,\n    68326,\n    68352,\n    68405,\n    68416,\n    68437,\n    68448,\n    68466,\n    68480,\n    68497,\n    68608,\n    68680,\n    68736,\n    68786,\n    68800,\n    68850,\n    68864,\n    68903,\n    68912,\n    68921,\n    69248,\n    69289,\n    69291,\n    69292,\n    69296,\n    69297,\n    69373,\n    69404,\n    69415,\n    69415,\n    69424,\n    69456,\n    69488,\n    69509,\n    69552,\n    69572,\n    69600,\n    69622,\n    69632,\n    69702,\n    69734,\n    69749,\n    69759,\n    69818,\n    69821,\n    69821,\n    69826,\n    69826,\n    69837,\n    69837,\n    69840,\n    69864,\n    69872,\n    69881,\n    69888,\n    69940,\n    69942,\n    69951,\n    69956,\n    69959,\n    69968,\n    70003,\n    70006,\n    70006,\n    70016,\n    70084,\n    70089,\n    70092,\n    70094,\n    70106,\n    70108,\n    70108,\n    70144,\n    70161,\n    70163,\n    70199,\n    70206,\n    70209,\n    70272,\n    70278,\n    70280,\n    70280,\n    70282,\n    70285,\n    70287,\n    70301,\n    70303,\n    70312,\n    70320,\n    70378,\n    70384,\n    70393,\n    70400,\n    70403,\n    70405,\n    70412,\n    70415,\n    70416,\n    70419,\n    70440,\n    70442,\n    70448,\n    70450,\n    70451,\n    70453,\n    70457,\n    70459,\n    70468,\n    70471,\n    70472,\n    70475,\n    70477,\n    70480,\n    70480,\n    70487,\n    70487,\n    70493,\n    70499,\n    70502,\n    70508,\n    70512,\n    70516,\n    70656,\n    70730,\n    70736,\n    70745,\n    70750,\n    70753,\n    70784,\n    70853,\n    70855,\n    70855,\n    70864,\n    70873,\n    71040,\n    71093,\n    71096,\n    71104,\n    71128,\n    71133,\n    71168,\n    71232,\n    71236,\n    71236,\n    71248,\n    71257,\n    71296,\n    71352,\n    71360,\n    71369,\n    71424,\n    71450,\n    71453,\n    71467,\n    71472,\n    71481,\n    71488,\n    71494,\n    71680,\n    71738,\n    71840,\n    71913,\n    71935,\n    71942,\n    71945,\n    71945,\n    71948,\n    71955,\n    71957,\n    71958,\n    71960,\n    71989,\n    71991,\n    71992,\n    71995,\n    72003,\n    72016,\n    72025,\n    72096,\n    72103,\n    72106,\n    72151,\n    72154,\n    72161,\n    72163,\n    72164,\n    72192,\n    72254,\n    72263,\n    72263,\n    72272,\n    72345,\n    72349,\n    72349,\n    72368,\n    72440,\n    72704,\n    72712,\n    72714,\n    72758,\n    72760,\n    72768,\n    72784,\n    72793,\n    72818,\n    72847,\n    72850,\n    72871,\n    72873,\n    72886,\n    72960,\n    72966,\n    72968,\n    72969,\n    72971,\n    73014,\n    73018,\n    73018,\n    73020,\n    73021,\n    73023,\n    73031,\n    73040,\n    73049,\n    73056,\n    73061,\n    73063,\n    73064,\n    73066,\n    73102,\n    73104,\n    73105,\n    73107,\n    73112,\n    73120,\n    73129,\n    73440,\n    73462,\n    73472,\n    73488,\n    73490,\n    73530,\n    73534,\n    73538,\n    73552,\n    73561,\n    73648,\n    73648,\n    73728,\n    74649,\n    74752,\n    74862,\n    74880,\n    75075,\n    77712,\n    77808,\n    77824,\n    78933,\n    82944,\n    83526,\n    92160,\n    92728,\n    92736,\n    92766,\n    92768,\n    92777,\n    92784,\n    92862,\n    92864,\n    92873,\n    92880,\n    92909,\n    92912,\n    92916,\n    92928,\n    92982,\n    92992,\n    92995,\n    93008,\n    93017,\n    93027,\n    93047,\n    93053,\n    93071,\n    93760,\n    93823,\n    93952,\n    94026,\n    94031,\n    94087,\n    94095,\n    94111,\n    94176,\n    94177,\n    94179,\n    94180,\n    94192,\n    94193,\n    94208,\n    100343,\n    100352,\n    101589,\n    101632,\n    101640,\n    110576,\n    110579,\n    110581,\n    110587,\n    110589,\n    110590,\n    110592,\n    110882,\n    110898,\n    110898,\n    110928,\n    110930,\n    110933,\n    110933,\n    110948,\n    110951,\n    110960,\n    111355,\n    113664,\n    113770,\n    113776,\n    113788,\n    113792,\n    113800,\n    113808,\n    113817,\n    113821,\n    113822,\n    113824,\n    113827,\n    118528,\n    118573,\n    118576,\n    118598,\n    119141,\n    119145,\n    119149,\n    119170,\n    119173,\n    119179,\n    119210,\n    119213,\n    119362,\n    119364,\n    119808,\n    119892,\n    119894,\n    119964,\n    119966,\n    119967,\n    119970,\n    119970,\n    119973,\n    119974,\n    119977,\n    119980,\n    119982,\n    119993,\n    119995,\n    119995,\n    119997,\n    120003,\n    120005,\n    120069,\n    120071,\n    120074,\n    120077,\n    120084,\n    120086,\n    120092,\n    120094,\n    120121,\n    120123,\n    120126,\n    120128,\n    120132,\n    120134,\n    120134,\n    120138,\n    120144,\n    120146,\n    120485,\n    120488,\n    120512,\n    120514,\n    120538,\n    120540,\n    120570,\n    120572,\n    120596,\n    120598,\n    120628,\n    120630,\n    120654,\n    120656,\n    120686,\n    120688,\n    120712,\n    120714,\n    120744,\n    120746,\n    120770,\n    120772,\n    120779,\n    120782,\n    120831,\n    121344,\n    121398,\n    121403,\n    121452,\n    121461,\n    121461,\n    121476,\n    121476,\n    121499,\n    121503,\n    121505,\n    121519,\n    122624,\n    122654,\n    122661,\n    122666,\n    122880,\n    122886,\n    122888,\n    122904,\n    122907,\n    122913,\n    122915,\n    122916,\n    122918,\n    122922,\n    122928,\n    122989,\n    123023,\n    123023,\n    123136,\n    123180,\n    123184,\n    123197,\n    123200,\n    123209,\n    123214,\n    123214,\n    123536,\n    123566,\n    123584,\n    123641,\n    124112,\n    124153,\n    124896,\n    124902,\n    124904,\n    124907,\n    124909,\n    124910,\n    124912,\n    124926,\n    124928,\n    125124,\n    125136,\n    125142,\n    125184,\n    125259,\n    125264,\n    125273,\n    126464,\n    126467,\n    126469,\n    126495,\n    126497,\n    126498,\n    126500,\n    126500,\n    126503,\n    126503,\n    126505,\n    126514,\n    126516,\n    126519,\n    126521,\n    126521,\n    126523,\n    126523,\n    126530,\n    126530,\n    126535,\n    126535,\n    126537,\n    126537,\n    126539,\n    126539,\n    126541,\n    126543,\n    126545,\n    126546,\n    126548,\n    126548,\n    126551,\n    126551,\n    126553,\n    126553,\n    126555,\n    126555,\n    126557,\n    126557,\n    126559,\n    126559,\n    126561,\n    126562,\n    126564,\n    126564,\n    126567,\n    126570,\n    126572,\n    126578,\n    126580,\n    126583,\n    126585,\n    126588,\n    126590,\n    126590,\n    126592,\n    126601,\n    126603,\n    126619,\n    126625,\n    126627,\n    126629,\n    126633,\n    126635,\n    126651,\n    130032,\n    130041,\n    131072,\n    173791,\n    173824,\n    177977,\n    177984,\n    178205,\n    178208,\n    183969,\n    183984,\n    191456,\n    194560,\n    195101,\n    196608,\n    201546,\n    201552,\n    205743,\n    917505,\n    917505,\n    917536,\n    917631,\n    917760,\n    917999,\n    662,\n    0,\n    65,\n    90,\n    97,\n    122,\n    170,\n    170,\n    181,\n    181,\n    186,\n    186,\n    192,\n    214,\n    216,\n    246,\n    248,\n    705,\n    710,\n    721,\n    736,\n    740,\n    748,\n    748,\n    750,\n    750,\n    880,\n    884,\n    886,\n    887,\n    890,\n    893,\n    895,\n    895,\n    902,\n    902,\n    904,\n    906,\n    908,\n    908,\n    910,\n    929,\n    931,\n    1013,\n    1015,\n    1153,\n    1162,\n    1327,\n    1329,\n    1366,\n    1369,\n    1369,\n    1376,\n    1416,\n    1488,\n    1514,\n    1519,\n    1522,\n    1568,\n    1610,\n    1646,\n    1647,\n    1649,\n    1747,\n    1749,\n    1749,\n    1765,\n    1766,\n    1774,\n    1775,\n    1786,\n    1788,\n    1791,\n    1791,\n    1808,\n    1808,\n    1810,\n    1839,\n    1869,\n    1957,\n    1969,\n    1969,\n    1994,\n    2026,\n    2036,\n    2037,\n    2042,\n    2042,\n    2048,\n    2069,\n    2074,\n    2074,\n    2084,\n    2084,\n    2088,\n    2088,\n    2112,\n    2136,\n    2144,\n    2154,\n    2160,\n    2183,\n    2185,\n    2190,\n    2208,\n    2249,\n    2308,\n    2361,\n    2365,\n    2365,\n    2384,\n    2384,\n    2392,\n    2401,\n    2417,\n    2432,\n    2437,\n    2444,\n    2447,\n    2448,\n    2451,\n    2472,\n    2474,\n    2480,\n    2482,\n    2482,\n    2486,\n    2489,\n    2493,\n    2493,\n    2510,\n    2510,\n    2524,\n    2525,\n    2527,\n    2529,\n    2544,\n    2545,\n    2556,\n    2556,\n    2565,\n    2570,\n    2575,\n    2576,\n    2579,\n    2600,\n    2602,\n    2608,\n    2610,\n    2611,\n    2613,\n    2614,\n    2616,\n    2617,\n    2649,\n    2652,\n    2654,\n    2654,\n    2674,\n    2676,\n    2693,\n    2701,\n    2703,\n    2705,\n    2707,\n    2728,\n    2730,\n    2736,\n    2738,\n    2739,\n    2741,\n    2745,\n    2749,\n    2749,\n    2768,\n    2768,\n    2784,\n    2785,\n    2809,\n    2809,\n    2821,\n    2828,\n    2831,\n    2832,\n    2835,\n    2856,\n    2858,\n    2864,\n    2866,\n    2867,\n    2869,\n    2873,\n    2877,\n    2877,\n    2908,\n    2909,\n    2911,\n    2913,\n    2929,\n    2929,\n    2947,\n    2947,\n    2949,\n    2954,\n    2958,\n    2960,\n    2962,\n    2965,\n    2969,\n    2970,\n    2972,\n    2972,\n    2974,\n    2975,\n    2979,\n    2980,\n    2984,\n    2986,\n    2990,\n    3001,\n    3024,\n    3024,\n    3077,\n    3084,\n    3086,\n    3088,\n    3090,\n    3112,\n    3114,\n    3129,\n    3133,\n    3133,\n    3160,\n    3162,\n    3165,\n    3165,\n    3168,\n    3169,\n    3200,\n    3200,\n    3205,\n    3212,\n    3214,\n    3216,\n    3218,\n    3240,\n    3242,\n    3251,\n    3253,\n    3257,\n    3261,\n    3261,\n    3293,\n    3294,\n    3296,\n    3297,\n    3313,\n    3314,\n    3332,\n    3340,\n    3342,\n    3344,\n    3346,\n    3386,\n    3389,\n    3389,\n    3406,\n    3406,\n    3412,\n    3414,\n    3423,\n    3425,\n    3450,\n    3455,\n    3461,\n    3478,\n    3482,\n    3505,\n    3507,\n    3515,\n    3517,\n    3517,\n    3520,\n    3526,\n    3585,\n    3632,\n    3634,\n    3635,\n    3648,\n    3654,\n    3713,\n    3714,\n    3716,\n    3716,\n    3718,\n    3722,\n    3724,\n    3747,\n    3749,\n    3749,\n    3751,\n    3760,\n    3762,\n    3763,\n    3773,\n    3773,\n    3776,\n    3780,\n    3782,\n    3782,\n    3804,\n    3807,\n    3840,\n    3840,\n    3904,\n    3911,\n    3913,\n    3948,\n    3976,\n    3980,\n    4096,\n    4138,\n    4159,\n    4159,\n    4176,\n    4181,\n    4186,\n    4189,\n    4193,\n    4193,\n    4197,\n    4198,\n    4206,\n    4208,\n    4213,\n    4225,\n    4238,\n    4238,\n    4256,\n    4293,\n    4295,\n    4295,\n    4301,\n    4301,\n    4304,\n    4346,\n    4348,\n    4680,\n    4682,\n    4685,\n    4688,\n    4694,\n    4696,\n    4696,\n    4698,\n    4701,\n    4704,\n    4744,\n    4746,\n    4749,\n    4752,\n    4784,\n    4786,\n    4789,\n    4792,\n    4798,\n    4800,\n    4800,\n    4802,\n    4805,\n    4808,\n    4822,\n    4824,\n    4880,\n    4882,\n    4885,\n    4888,\n    4954,\n    4992,\n    5007,\n    5024,\n    5109,\n    5112,\n    5117,\n    5121,\n    5740,\n    5743,\n    5759,\n    5761,\n    5786,\n    5792,\n    5866,\n    5870,\n    5880,\n    5888,\n    5905,\n    5919,\n    5937,\n    5952,\n    5969,\n    5984,\n    5996,\n    5998,\n    6e3,\n    6016,\n    6067,\n    6103,\n    6103,\n    6108,\n    6108,\n    6176,\n    6264,\n    6272,\n    6276,\n    6279,\n    6312,\n    6314,\n    6314,\n    6320,\n    6389,\n    6400,\n    6430,\n    6480,\n    6509,\n    6512,\n    6516,\n    6528,\n    6571,\n    6576,\n    6601,\n    6656,\n    6678,\n    6688,\n    6740,\n    6823,\n    6823,\n    6917,\n    6963,\n    6981,\n    6988,\n    7043,\n    7072,\n    7086,\n    7087,\n    7098,\n    7141,\n    7168,\n    7203,\n    7245,\n    7247,\n    7258,\n    7293,\n    7296,\n    7304,\n    7312,\n    7354,\n    7357,\n    7359,\n    7401,\n    7404,\n    7406,\n    7411,\n    7413,\n    7414,\n    7418,\n    7418,\n    7424,\n    7615,\n    7680,\n    7957,\n    7960,\n    7965,\n    7968,\n    8005,\n    8008,\n    8013,\n    8016,\n    8023,\n    8025,\n    8025,\n    8027,\n    8027,\n    8029,\n    8029,\n    8031,\n    8061,\n    8064,\n    8116,\n    8118,\n    8124,\n    8126,\n    8126,\n    8130,\n    8132,\n    8134,\n    8140,\n    8144,\n    8147,\n    8150,\n    8155,\n    8160,\n    8172,\n    8178,\n    8180,\n    8182,\n    8188,\n    8305,\n    8305,\n    8319,\n    8319,\n    8336,\n    8348,\n    8450,\n    8450,\n    8455,\n    8455,\n    8458,\n    8467,\n    8469,\n    8469,\n    8473,\n    8477,\n    8484,\n    8484,\n    8486,\n    8486,\n    8488,\n    8488,\n    8490,\n    8493,\n    8495,\n    8505,\n    8508,\n    8511,\n    8517,\n    8521,\n    8526,\n    8526,\n    8544,\n    8584,\n    11264,\n    11492,\n    11499,\n    11502,\n    11506,\n    11507,\n    11520,\n    11557,\n    11559,\n    11559,\n    11565,\n    11565,\n    11568,\n    11623,\n    11631,\n    11631,\n    11648,\n    11670,\n    11680,\n    11686,\n    11688,\n    11694,\n    11696,\n    11702,\n    11704,\n    11710,\n    11712,\n    11718,\n    11720,\n    11726,\n    11728,\n    11734,\n    11736,\n    11742,\n    11823,\n    11823,\n    12293,\n    12295,\n    12321,\n    12329,\n    12337,\n    12341,\n    12344,\n    12348,\n    12353,\n    12438,\n    12445,\n    12447,\n    12449,\n    12538,\n    12540,\n    12543,\n    12549,\n    12591,\n    12593,\n    12686,\n    12704,\n    12735,\n    12784,\n    12799,\n    13312,\n    19903,\n    19968,\n    42124,\n    42192,\n    42237,\n    42240,\n    42508,\n    42512,\n    42527,\n    42538,\n    42539,\n    42560,\n    42606,\n    42623,\n    42653,\n    42656,\n    42735,\n    42775,\n    42783,\n    42786,\n    42888,\n    42891,\n    42954,\n    42960,\n    42961,\n    42963,\n    42963,\n    42965,\n    42969,\n    42994,\n    43009,\n    43011,\n    43013,\n    43015,\n    43018,\n    43020,\n    43042,\n    43072,\n    43123,\n    43138,\n    43187,\n    43250,\n    43255,\n    43259,\n    43259,\n    43261,\n    43262,\n    43274,\n    43301,\n    43312,\n    43334,\n    43360,\n    43388,\n    43396,\n    43442,\n    43471,\n    43471,\n    43488,\n    43492,\n    43494,\n    43503,\n    43514,\n    43518,\n    43520,\n    43560,\n    43584,\n    43586,\n    43588,\n    43595,\n    43616,\n    43638,\n    43642,\n    43642,\n    43646,\n    43695,\n    43697,\n    43697,\n    43701,\n    43702,\n    43705,\n    43709,\n    43712,\n    43712,\n    43714,\n    43714,\n    43739,\n    43741,\n    43744,\n    43754,\n    43762,\n    43764,\n    43777,\n    43782,\n    43785,\n    43790,\n    43793,\n    43798,\n    43808,\n    43814,\n    43816,\n    43822,\n    43824,\n    43866,\n    43868,\n    43881,\n    43888,\n    44002,\n    44032,\n    55203,\n    55216,\n    55238,\n    55243,\n    55291,\n    63744,\n    64109,\n    64112,\n    64217,\n    64256,\n    64262,\n    64275,\n    64279,\n    64285,\n    64285,\n    64287,\n    64296,\n    64298,\n    64310,\n    64312,\n    64316,\n    64318,\n    64318,\n    64320,\n    64321,\n    64323,\n    64324,\n    64326,\n    64433,\n    64467,\n    64829,\n    64848,\n    64911,\n    64914,\n    64967,\n    65008,\n    65019,\n    65136,\n    65140,\n    65142,\n    65276,\n    65313,\n    65338,\n    65345,\n    65370,\n    65382,\n    65470,\n    65474,\n    65479,\n    65482,\n    65487,\n    65490,\n    65495,\n    65498,\n    65500,\n    65536,\n    65547,\n    65549,\n    65574,\n    65576,\n    65594,\n    65596,\n    65597,\n    65599,\n    65613,\n    65616,\n    65629,\n    65664,\n    65786,\n    65856,\n    65908,\n    66176,\n    66204,\n    66208,\n    66256,\n    66304,\n    66335,\n    66349,\n    66378,\n    66384,\n    66421,\n    66432,\n    66461,\n    66464,\n    66499,\n    66504,\n    66511,\n    66513,\n    66517,\n    66560,\n    66717,\n    66736,\n    66771,\n    66776,\n    66811,\n    66816,\n    66855,\n    66864,\n    66915,\n    66928,\n    66938,\n    66940,\n    66954,\n    66956,\n    66962,\n    66964,\n    66965,\n    66967,\n    66977,\n    66979,\n    66993,\n    66995,\n    67001,\n    67003,\n    67004,\n    67072,\n    67382,\n    67392,\n    67413,\n    67424,\n    67431,\n    67456,\n    67461,\n    67463,\n    67504,\n    67506,\n    67514,\n    67584,\n    67589,\n    67592,\n    67592,\n    67594,\n    67637,\n    67639,\n    67640,\n    67644,\n    67644,\n    67647,\n    67669,\n    67680,\n    67702,\n    67712,\n    67742,\n    67808,\n    67826,\n    67828,\n    67829,\n    67840,\n    67861,\n    67872,\n    67897,\n    67968,\n    68023,\n    68030,\n    68031,\n    68096,\n    68096,\n    68112,\n    68115,\n    68117,\n    68119,\n    68121,\n    68149,\n    68192,\n    68220,\n    68224,\n    68252,\n    68288,\n    68295,\n    68297,\n    68324,\n    68352,\n    68405,\n    68416,\n    68437,\n    68448,\n    68466,\n    68480,\n    68497,\n    68608,\n    68680,\n    68736,\n    68786,\n    68800,\n    68850,\n    68864,\n    68899,\n    69248,\n    69289,\n    69296,\n    69297,\n    69376,\n    69404,\n    69415,\n    69415,\n    69424,\n    69445,\n    69488,\n    69505,\n    69552,\n    69572,\n    69600,\n    69622,\n    69635,\n    69687,\n    69745,\n    69746,\n    69749,\n    69749,\n    69763,\n    69807,\n    69840,\n    69864,\n    69891,\n    69926,\n    69956,\n    69956,\n    69959,\n    69959,\n    69968,\n    70002,\n    70006,\n    70006,\n    70019,\n    70066,\n    70081,\n    70084,\n    70106,\n    70106,\n    70108,\n    70108,\n    70144,\n    70161,\n    70163,\n    70187,\n    70207,\n    70208,\n    70272,\n    70278,\n    70280,\n    70280,\n    70282,\n    70285,\n    70287,\n    70301,\n    70303,\n    70312,\n    70320,\n    70366,\n    70405,\n    70412,\n    70415,\n    70416,\n    70419,\n    70440,\n    70442,\n    70448,\n    70450,\n    70451,\n    70453,\n    70457,\n    70461,\n    70461,\n    70480,\n    70480,\n    70493,\n    70497,\n    70656,\n    70708,\n    70727,\n    70730,\n    70751,\n    70753,\n    70784,\n    70831,\n    70852,\n    70853,\n    70855,\n    70855,\n    71040,\n    71086,\n    71128,\n    71131,\n    71168,\n    71215,\n    71236,\n    71236,\n    71296,\n    71338,\n    71352,\n    71352,\n    71424,\n    71450,\n    71488,\n    71494,\n    71680,\n    71723,\n    71840,\n    71903,\n    71935,\n    71942,\n    71945,\n    71945,\n    71948,\n    71955,\n    71957,\n    71958,\n    71960,\n    71983,\n    71999,\n    71999,\n    72001,\n    72001,\n    72096,\n    72103,\n    72106,\n    72144,\n    72161,\n    72161,\n    72163,\n    72163,\n    72192,\n    72192,\n    72203,\n    72242,\n    72250,\n    72250,\n    72272,\n    72272,\n    72284,\n    72329,\n    72349,\n    72349,\n    72368,\n    72440,\n    72704,\n    72712,\n    72714,\n    72750,\n    72768,\n    72768,\n    72818,\n    72847,\n    72960,\n    72966,\n    72968,\n    72969,\n    72971,\n    73008,\n    73030,\n    73030,\n    73056,\n    73061,\n    73063,\n    73064,\n    73066,\n    73097,\n    73112,\n    73112,\n    73440,\n    73458,\n    73474,\n    73474,\n    73476,\n    73488,\n    73490,\n    73523,\n    73648,\n    73648,\n    73728,\n    74649,\n    74752,\n    74862,\n    74880,\n    75075,\n    77712,\n    77808,\n    77824,\n    78895,\n    78913,\n    78918,\n    82944,\n    83526,\n    92160,\n    92728,\n    92736,\n    92766,\n    92784,\n    92862,\n    92880,\n    92909,\n    92928,\n    92975,\n    92992,\n    92995,\n    93027,\n    93047,\n    93053,\n    93071,\n    93760,\n    93823,\n    93952,\n    94026,\n    94032,\n    94032,\n    94099,\n    94111,\n    94176,\n    94177,\n    94179,\n    94179,\n    94208,\n    100343,\n    100352,\n    101589,\n    101632,\n    101640,\n    110576,\n    110579,\n    110581,\n    110587,\n    110589,\n    110590,\n    110592,\n    110882,\n    110898,\n    110898,\n    110928,\n    110930,\n    110933,\n    110933,\n    110948,\n    110951,\n    110960,\n    111355,\n    113664,\n    113770,\n    113776,\n    113788,\n    113792,\n    113800,\n    113808,\n    113817,\n    119808,\n    119892,\n    119894,\n    119964,\n    119966,\n    119967,\n    119970,\n    119970,\n    119973,\n    119974,\n    119977,\n    119980,\n    119982,\n    119993,\n    119995,\n    119995,\n    119997,\n    120003,\n    120005,\n    120069,\n    120071,\n    120074,\n    120077,\n    120084,\n    120086,\n    120092,\n    120094,\n    120121,\n    120123,\n    120126,\n    120128,\n    120132,\n    120134,\n    120134,\n    120138,\n    120144,\n    120146,\n    120485,\n    120488,\n    120512,\n    120514,\n    120538,\n    120540,\n    120570,\n    120572,\n    120596,\n    120598,\n    120628,\n    120630,\n    120654,\n    120656,\n    120686,\n    120688,\n    120712,\n    120714,\n    120744,\n    120746,\n    120770,\n    120772,\n    120779,\n    122624,\n    122654,\n    122661,\n    122666,\n    122928,\n    122989,\n    123136,\n    123180,\n    123191,\n    123197,\n    123214,\n    123214,\n    123536,\n    123565,\n    123584,\n    123627,\n    124112,\n    124139,\n    124896,\n    124902,\n    124904,\n    124907,\n    124909,\n    124910,\n    124912,\n    124926,\n    124928,\n    125124,\n    125184,\n    125251,\n    125259,\n    125259,\n    126464,\n    126467,\n    126469,\n    126495,\n    126497,\n    126498,\n    126500,\n    126500,\n    126503,\n    126503,\n    126505,\n    126514,\n    126516,\n    126519,\n    126521,\n    126521,\n    126523,\n    126523,\n    126530,\n    126530,\n    126535,\n    126535,\n    126537,\n    126537,\n    126539,\n    126539,\n    126541,\n    126543,\n    126545,\n    126546,\n    126548,\n    126548,\n    126551,\n    126551,\n    126553,\n    126553,\n    126555,\n    126555,\n    126557,\n    126557,\n    126559,\n    126559,\n    126561,\n    126562,\n    126564,\n    126564,\n    126567,\n    126570,\n    126572,\n    126578,\n    126580,\n    126583,\n    126585,\n    126588,\n    126590,\n    126590,\n    126592,\n    126601,\n    126603,\n    126619,\n    126625,\n    126627,\n    126629,\n    126633,\n    126635,\n    126651,\n    131072,\n    173791,\n    173824,\n    177977,\n    177984,\n    178205,\n    178208,\n    183969,\n    183984,\n    191456,\n    194560,\n    195101,\n    196608,\n    201546,\n    201552,\n    205743,\n    47,\n    0,\n    1,\n    1,\n    0,\n    0,\n    0,\n    0,\n    3,\n    1,\n    0,\n    0,\n    0,\n    0,\n    5,\n    1,\n    0,\n    0,\n    0,\n    0,\n    7,\n    1,\n    0,\n    0,\n    0,\n    0,\n    9,\n    1,\n    0,\n    0,\n    0,\n    0,\n    15,\n    1,\n    0,\n    0,\n    0,\n    1,\n    17,\n    1,\n    0,\n    0,\n    0,\n    3,\n    20,\n    1,\n    0,\n    0,\n    0,\n    5,\n    22,\n    1,\n    0,\n    0,\n    0,\n    7,\n    24,\n    1,\n    0,\n    0,\n    0,\n    9,\n    26,\n    1,\n    0,\n    0,\n    0,\n    11,\n    35,\n    1,\n    0,\n    0,\n    0,\n    13,\n    37,\n    1,\n    0,\n    0,\n    0,\n    15,\n    39,\n    1,\n    0,\n    0,\n    0,\n    17,\n    18,\n    5,\n    47,\n    0,\n    0,\n    18,\n    19,\n    5,\n    47,\n    0,\n    0,\n    19,\n    2,\n    1,\n    0,\n    0,\n    0,\n    20,\n    21,\n    5,\n    47,\n    0,\n    0,\n    21,\n    4,\n    1,\n    0,\n    0,\n    0,\n    22,\n    23,\n    5,\n    42,\n    0,\n    0,\n    23,\n    6,\n    1,\n    0,\n    0,\n    0,\n    24,\n    25,\n    5,\n    33,\n    0,\n    0,\n    25,\n    8,\n    1,\n    0,\n    0,\n    0,\n    26,\n    30,\n    3,\n    13,\n    6,\n    0,\n    27,\n    29,\n    3,\n    11,\n    5,\n    0,\n    28,\n    27,\n    1,\n    0,\n    0,\n    0,\n    29,\n    32,\n    1,\n    0,\n    0,\n    0,\n    30,\n    28,\n    1,\n    0,\n    0,\n    0,\n    30,\n    31,\n    1,\n    0,\n    0,\n    0,\n    31,\n    33,\n    1,\n    0,\n    0,\n    0,\n    32,\n    30,\n    1,\n    0,\n    0,\n    0,\n    33,\n    34,\n    6,\n    4,\n    0,\n    0,\n    34,\n    10,\n    1,\n    0,\n    0,\n    0,\n    35,\n    36,\n    7,\n    0,\n    0,\n    0,\n    36,\n    12,\n    1,\n    0,\n    0,\n    0,\n    37,\n    38,\n    7,\n    1,\n    0,\n    0,\n    38,\n    14,\n    1,\n    0,\n    0,\n    0,\n    39,\n    43,\n    5,\n    39,\n    0,\n    0,\n    40,\n    42,\n    9,\n    0,\n    0,\n    0,\n    41,\n    40,\n    1,\n    0,\n    0,\n    0,\n    42,\n    45,\n    1,\n    0,\n    0,\n    0,\n    43,\n    44,\n    1,\n    0,\n    0,\n    0,\n    43,\n    41,\n    1,\n    0,\n    0,\n    0,\n    44,\n    46,\n    1,\n    0,\n    0,\n    0,\n    45,\n    43,\n    1,\n    0,\n    0,\n    0,\n    46,\n    47,\n    5,\n    39,\n    0,\n    0,\n    47,\n    16,\n    1,\n    0,\n    0,\n    0,\n    3,\n    0,\n    30,\n    43,\n    1,\n    1,\n    4,\n    0\n  ];\n  static __ATN;\n  static get _ATN() {\n    if (!_XPathLexer.__ATN) {\n      _XPathLexer.__ATN = new ATNDeserializer().deserialize(_XPathLexer._serializedATN);\n    }\n    return _XPathLexer.__ATN;\n  }\n  static vocabulary = new Vocabulary(_XPathLexer.literalNames, _XPathLexer.symbolicNames, []);\n  get vocabulary() {\n    return _XPathLexer.vocabulary;\n  }\n  static decisionsToDFA = _XPathLexer._ATN.decisionToState.map((ds, index) => {\n    return new DFA(ds, index);\n  });\n};\n\n// src/tree/xpath/XPathLexerErrorListener.ts\nvar XPathLexerErrorListener = class extends BaseErrorListener {\n  static {\n    __name(this, \"XPathLexerErrorListener\");\n  }\n  syntaxError(_recognizer, _offendingSymbol, _line, _charPositionInLine, _msg, _e) {\n  }\n};\n\n// src/tree/xpath/XPathElement.ts\nvar XPathElement = class {\n  static {\n    __name(this, \"XPathElement\");\n  }\n  invert;\n  nodeName;\n  /**\n   * Construct element like `/ID` or `ID` or `/*` etc... `nodeName` is undefined if just node\n   *\n   * @param nodeName The name of the node; may be undefined for any node.\n   */\n  constructor(nodeName) {\n    this.nodeName = nodeName;\n    this.invert = false;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathRuleAnywhereElement.ts\nvar XPathRuleAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathRuleAnywhereElement\");\n  }\n  ruleIndex;\n  constructor(ruleName, ruleIndex) {\n    super(ruleName);\n    this.ruleIndex = ruleIndex;\n  }\n  evaluate(t) {\n    return Trees.findAllRuleNodes(t, this.ruleIndex);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathRuleAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathRuleElement.ts\nvar XPathRuleElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathRuleElement\");\n  }\n  ruleIndex;\n  constructor(ruleName, ruleIndex) {\n    super(ruleName);\n    this.ruleIndex = ruleIndex;\n  }\n  evaluate(t) {\n    const nodes = [];\n    for (const c of Trees.getChildren(t)) {\n      if (c instanceof ParserRuleContext) {\n        if (c.ruleIndex === this.ruleIndex && !this.invert || c.ruleIndex !== this.ruleIndex && this.invert) {\n          nodes.push(c);\n        }\n      }\n    }\n    return nodes;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathRuleElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathTokenAnywhereElement.ts\nvar XPathTokenAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathTokenAnywhereElement\");\n  }\n  tokenType;\n  constructor(tokenName, tokenType) {\n    super(tokenName);\n    this.tokenType = tokenType;\n  }\n  evaluate(t) {\n    return Trees.findAllTokenNodes(t, this.tokenType);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathTokenAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathTokenElement.ts\nvar XPathTokenElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathTokenElement\");\n  }\n  tokenType;\n  constructor(tokenName, tokenType) {\n    super(tokenName);\n    this.tokenType = tokenType;\n  }\n  evaluate(t) {\n    const nodes = [];\n    for (const c of Trees.getChildren(t)) {\n      if (c instanceof TerminalNode && c.symbol) {\n        if (c.symbol.type === this.tokenType && !this.invert || c.symbol.type !== this.tokenType && this.invert) {\n          nodes.push(c);\n        }\n      }\n    }\n    return nodes;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathTokenElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathWildcardAnywhereElement.ts\nvar XPathWildcardAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathWildcardAnywhereElement\");\n  }\n  constructor() {\n    super(XPath.WILDCARD);\n  }\n  evaluate(t) {\n    if (this.invert) {\n      return [];\n    }\n    return Trees.descendants(t);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathWildcardAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathWildcardElement.ts\nvar XPathWildcardElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathWildcardElement\");\n  }\n  constructor() {\n    super(XPath.WILDCARD);\n  }\n  evaluate(t) {\n    const kids = [];\n    if (this.invert) {\n      return kids;\n    }\n    for (const c of Trees.getChildren(t)) {\n      kids.push(c);\n    }\n    return kids;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathWildcardElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPath.ts\nvar XPath = class _XPath {\n  static {\n    __name(this, \"XPath\");\n  }\n  static WILDCARD = \"*\";\n  // word not operator/separator\n  static NOT = \"!\";\n  // word for invert operator\n  path;\n  elements;\n  parser;\n  constructor(parser, path) {\n    this.parser = parser;\n    this.path = path;\n    this.elements = this.split(path);\n  }\n  static findAll(tree, xpath, parser) {\n    const p = new _XPath(parser, xpath);\n    return p.evaluate(tree);\n  }\n  // TODO: check for invalid token/rule names, bad syntax\n  split(path) {\n    const lexer = new XPathLexer(CharStream.fromString(path));\n    lexer.recover = (e) => {\n      throw e;\n    };\n    lexer.removeErrorListeners();\n    lexer.addErrorListener(new XPathLexerErrorListener());\n    const tokenStream = new CommonTokenStream(lexer);\n    try {\n      tokenStream.fill();\n    } catch (e) {\n      if (e instanceof LexerNoViableAltException) {\n        const pos = lexer.column;\n        const msg = \"Invalid tokens or characters at index \" + pos + \" in path '\" + path + \"' -- \" + e.message;\n        throw new RangeError(msg);\n      }\n      throw e;\n    }\n    const tokens = tokenStream.getTokens();\n    const elements = [];\n    const n2 = tokens.length;\n    let i = 0;\n    loop:\n      while (i < n2) {\n        const el = tokens[i];\n        let next;\n        switch (el.type) {\n          case XPathLexer.ROOT:\n          case XPathLexer.ANYWHERE:\n            const anywhere = el.type === XPathLexer.ANYWHERE;\n            i++;\n            next = tokens[i];\n            const invert = next.type === XPathLexer.BANG;\n            if (invert) {\n              i++;\n              next = tokens[i];\n            }\n            const pathElement = this.getXPathElement(next, anywhere);\n            pathElement.invert = invert;\n            elements.push(pathElement);\n            i++;\n            break;\n          case XPathLexer.TOKEN_REF:\n          case XPathLexer.RULE_REF:\n          case XPathLexer.WILDCARD:\n            elements.push(this.getXPathElement(el, false));\n            ++i;\n            break;\n          case Token.EOF:\n            break loop;\n          default:\n            throw new Error(\"Unknown path element \" + el);\n        }\n      }\n    return elements;\n  }\n  /**\n   * Return a list of all nodes starting at `t` as root that satisfy the\n   * path. The root `/` is relative to the node passed to {@link evaluate}.\n   */\n  evaluate(t) {\n    const dummyRoot = new ParserRuleContext(null);\n    dummyRoot.addChild(t);\n    let work = /* @__PURE__ */ new Set([dummyRoot]);\n    let i = 0;\n    while (i < this.elements.length) {\n      const next = /* @__PURE__ */ new Set();\n      for (const node of work) {\n        if (node.getChildCount() > 0) {\n          const matching = this.elements[i].evaluate(node);\n          matching.forEach((tree) => {\n            next.add(tree);\n          }, next);\n        }\n      }\n      i++;\n      work = next;\n    }\n    return work;\n  }\n  /**\n   * Convert word like `*` or `ID` or `expr` to a path\n   * element. `anywhere` is `true` if `//` precedes the\n   * word.\n   */\n  getXPathElement(wordToken, anywhere) {\n    if (wordToken.type === Token.EOF) {\n      throw new Error(\"Missing path element at end of path\");\n    }\n    const word = wordToken.text;\n    if (word == null) {\n      throw new Error(\"Expected wordToken to have text content.\");\n    }\n    const ttype = this.parser.getTokenType(word);\n    const ruleIndex = this.parser.getRuleIndex(word);\n    switch (wordToken.type) {\n      case XPathLexer.WILDCARD:\n        return anywhere ? new XPathWildcardAnywhereElement() : new XPathWildcardElement();\n      case XPathLexer.TOKEN_REF:\n      case XPathLexer.STRING:\n        if (ttype === Token.INVALID_TYPE) {\n          throw new Error(word + \" at index \" + wordToken.start + \" isn't a valid token name\");\n        }\n        return anywhere ? new XPathTokenAnywhereElement(word, ttype) : new XPathTokenElement(word, ttype);\n      default:\n        if (ruleIndex === -1) {\n          throw new Error(word + \" at index \" + wordToken.start + \" isn't a valid rule name\");\n        }\n        return anywhere ? new XPathRuleAnywhereElement(word, ruleIndex) : new XPathRuleElement(word, ruleIndex);\n    }\n  }\n};\n\n// src/tree/pattern/Chunk.ts\nvar Chunk = class {\n  static {\n    __name(this, \"Chunk\");\n  }\n};\n\n// src/tree/pattern/ParseTreeMatch.ts\nvar ParseTreeMatch = class {\n  static {\n    __name(this, \"ParseTreeMatch\");\n  }\n  /**\n   * This is the backing field for {@link #getTree()}.\n   */\n  tree;\n  /**\n   * This is the backing field for {@link #getPattern()}.\n   */\n  pattern;\n  /**\n   * This is the backing field for {@link #getLabels()}.\n   */\n  labels;\n  /**\n   * This is the backing field for {@link #getMismatchedNode()}.\n   */\n  mismatchedNode;\n  /**\n   * Constructs a new instance of {@link ParseTreeMatch} from the specified\n   * parse tree and pattern.\n   *\n   * @param tree The parse tree to match against the pattern.\n   * @param pattern The parse tree pattern.\n   * @param labels A mapping from label names to collections of\n   * {@link ParseTree} objects located by the tree pattern matching process.\n   * @param mismatchedNode The first node which failed to match the tree\n   * pattern during the matching process.\n   */\n  constructor(tree, pattern, labels, mismatchedNode) {\n    this.tree = tree;\n    this.pattern = pattern;\n    this.labels = labels;\n    this.mismatchedNode = mismatchedNode;\n  }\n  /**\n   * Get the last node associated with a specific `label`.\n   *\n   * For example, for pattern `<id:ID>`, `get(\"id\")` returns the\n   * node matched for that `ID`. If more than one node\n   * matched the specified label, only the last is returned. If there is\n   * no node associated with the label, this returns `null`.\n   *\n   * Pattern tags like `<ID>` and `<expr>` without labels are\n   * considered to be labeled with `ID` and `expr`, respectively.\n   *\n   * @param label The label to check.\n   *\n   * @returns The last {@link ParseTree} to match a tag with the specified\n   * label, or `null` if no parse tree matched a tag with the label.\n   */\n  get(label) {\n    const parseTrees = this.labels.get(label);\n    if (!parseTrees || parseTrees.length === 0) {\n      return null;\n    }\n    return parseTrees[parseTrees.length - 1];\n  }\n  /**\n   * Return all nodes matching a rule or token tag with the specified label.\n   *\n   * If the `label` is the name of a parser rule or token in the\n   * grammar, the resulting list will contain both the parse trees matching\n   * rule or tags explicitly labeled with the label and the complete set of\n   * parse trees matching the labeled and unlabeled tags in the pattern for\n   * the parser rule or token. For example, if `label` is `\"foo\"`,\n   * the result will contain *all* of the following.\n   *\n   * - Parse tree nodes matching tags of the form `<foo:anyRuleName>` and\n   * `<foo:AnyTokenName>`.\n   * - Parse tree nodes matching tags of the form `<anyLabel:foo>`.\n   * - Parse tree nodes matching tags of the form `<foo>`.\n   *\n   * @param label The label.\n   *\n   * @returns A collection of all {@link ParseTree} nodes matching tags with\n   * the specified `label`. If no nodes matched the label, an empty list\n   * is returned.\n   */\n  getAll(label) {\n    const nodes = this.labels.get(label);\n    return nodes ?? [];\n  }\n  /**\n   * Return a mapping from label -> [list of nodes].\n   *\n   * The map includes special entries corresponding to the names of rules and\n   * tokens referenced in tags in the original pattern. For additional\n   * information, see the description of {@link getAll(String)}.\n   *\n   * @returns A mapping from labels to parse tree nodes. If the parse tree\n   * pattern did not contain any rule or token tags, this map will be empty.\n   */\n  getLabels() {\n    return this.labels;\n  }\n  /**\n   * Get the node at which we first detected a mismatch.\n   *\n   * @returns the node at which we first detected a mismatch, or `null`\n   * if the match was successful.\n   */\n  getMismatchedNode() {\n    return this.mismatchedNode;\n  }\n  /**\n   * Gets a value indicating whether the match operation succeeded.\n   *\n   * @returns `true` if the match operation succeeded; otherwise, `false`.\n   */\n  succeeded() {\n    return !this.mismatchedNode;\n  }\n  /**\n   * Get the tree pattern we are matching against.\n   *\n   * @returns The tree pattern we are matching against.\n   */\n  getPattern() {\n    return this.pattern;\n  }\n  /**\n   * Get the parse tree we are trying to match to a pattern.\n   *\n   * @returns The {@link ParseTree} we are trying to match to a pattern.\n   */\n  getTree() {\n    return this.tree;\n  }\n  toString() {\n    return `Match ${this.succeeded() ? \"succeeded\" : \"failed\"}; found ${this.getLabels().size} labels`;\n  }\n};\n\n// src/tree/pattern/ParseTreePattern.ts\nvar ParseTreePattern = class {\n  static {\n    __name(this, \"ParseTreePattern\");\n  }\n  /**\n   * This is the backing field for {@link #getPatternRuleIndex()}.\n   */\n  patternRuleIndex;\n  /**\n   * This is the backing field for {@link #getPattern()}.\n   */\n  pattern;\n  /**\n   * This is the backing field for {@link #getPatternTree()}.\n   */\n  patternTree;\n  /**\n   * This is the backing field for {@link #getMatcher()}.\n   */\n  matcher;\n  /**\n   * Construct a new instance of the {@link ParseTreePattern} class.\n   *\n   * @param matcher The {@link ParseTreePatternMatcher} which created this\n   * tree pattern.\n   * @param pattern The tree pattern in concrete syntax form.\n   * @param patternRuleIndex The parser rule which serves as the root of the\n   * tree pattern.\n   * @param patternTree The tree pattern in {@link ParseTree} form.\n   */\n  constructor(matcher, pattern, patternRuleIndex, patternTree) {\n    this.matcher = matcher;\n    this.patternRuleIndex = patternRuleIndex;\n    this.pattern = pattern;\n    this.patternTree = patternTree;\n  }\n  /**\n   * Match a specific parse tree against this tree pattern.\n   *\n   * @param tree The parse tree to match against this tree pattern.\n   * @returns A {@link ParseTreeMatch} object describing the result of the\n   * match operation. The {@link ParseTreeMatch#succeeded()} method can be\n   * used to determine whether or not the match was successful.\n   */\n  match(tree) {\n    return this.matcher.match(tree, this);\n  }\n  /**\n   * Determine whether or not a parse tree matches this tree pattern.\n   *\n   * @param tree The parse tree to match against this tree pattern.\n   * @returns `true` if `tree` is a match for the current tree\n   * pattern; otherwise, `false`.\n   */\n  matches(tree) {\n    return this.matcher.match(tree, this).succeeded();\n  }\n  /**\n   * Find all nodes using XPath and then try to match those subtrees against\n   * this tree pattern.\n   *\n   * @param tree The {@link ParseTree} to match against this pattern.\n   * @param xpath An expression matching the nodes\n   *\n   * @returns A collection of {@link ParseTreeMatch} objects describing the\n   * successful matches. Unsuccessful matches are omitted from the result,\n   * regardless of the reason for the failure.\n   */\n  findAll(tree, xpath) {\n    const subtrees = XPath.findAll(tree, xpath, this.matcher.getParser());\n    const matches = new Array();\n    for (const t of subtrees) {\n      const match = this.match(t);\n      if (match.succeeded()) {\n        matches.push(match);\n      }\n    }\n    return matches;\n  }\n  /**\n   * Get the {@link ParseTreePatternMatcher} which created this tree pattern.\n   *\n   * @returns The {@link ParseTreePatternMatcher} which created this tree\n   * pattern.\n   */\n  getMatcher() {\n    return this.matcher;\n  }\n  /**\n   * Get the tree pattern in concrete syntax form.\n   *\n   * @returns The tree pattern in concrete syntax form.\n   */\n  getPattern() {\n    return this.pattern;\n  }\n  /**\n   * Get the parser rule which serves as the outermost rule for the tree\n   * pattern.\n   *\n   * @returns The parser rule which serves as the outermost rule for the tree\n   * pattern.\n   */\n  getPatternRuleIndex() {\n    return this.patternRuleIndex;\n  }\n  /**\n   * Get the tree pattern as a {@link ParseTree}. The rule and token tags from\n   * the pattern are present in the parse tree as terminal nodes with a symbol\n   * of type {@link RuleTagToken} or {@link TokenTagToken}.\n   *\n   * @returns The tree pattern as a {@link ParseTree}.\n   */\n  getPatternTree() {\n    return this.patternTree;\n  }\n};\n\n// src/InputMismatchException.ts\nvar InputMismatchException = class extends RecognitionException {\n  static {\n    __name(this, \"InputMismatchException\");\n  }\n  constructor(recognizer) {\n    super({ message: \"\", recognizer, input: recognizer.inputStream, ctx: recognizer.context });\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n};\n\n// src/FailedPredicateException.ts\nvar FailedPredicateException = class extends RecognitionException {\n  static {\n    __name(this, \"FailedPredicateException\");\n  }\n  ruleIndex = 0;\n  predicateIndex = 0;\n  predicate;\n  constructor(recognizer, predicate, message = null) {\n    super({\n      message: formatMessage(predicate ?? \"no predicate\", message ?? null),\n      recognizer,\n      input: recognizer.inputStream,\n      ctx: recognizer.context\n    });\n    const s = recognizer.atn.states[recognizer.state];\n    const trans = s.transitions[0];\n    if (trans instanceof PredicateTransition) {\n      this.ruleIndex = trans.ruleIndex;\n      this.predicateIndex = trans.predIndex;\n    } else {\n      this.ruleIndex = 0;\n      this.predicateIndex = 0;\n    }\n    this.predicate = predicate;\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n};\nvar formatMessage = /* @__PURE__ */ __name((predicate, message) => {\n  if (message !== null) {\n    return message;\n  }\n  return \"failed predicate: {\" + predicate + \"}?\";\n}, \"formatMessage\");\n\n// src/DefaultErrorStrategy.ts\nvar DefaultErrorStrategy = class {\n  static {\n    __name(this, \"DefaultErrorStrategy\");\n  }\n  /**\n   * Indicates whether the error strategy is currently \"recovering from an\n   * error\". This is used to suppress reporting multiple error messages while\n   * attempting to recover from a detected syntax error.\n   *\n   * @see #inErrorRecoveryMode\n   */\n  errorRecoveryMode = false;\n  /**\n   * The index into the input stream where the last error occurred.\n   * \tThis is used to prevent infinite loops where an error is found\n   *  but no token is consumed during recovery...another error is found,\n   *  ad nauseam.  This is a failsafe mechanism to guarantee that at least\n   *  one token/tree node is consumed for two errors.\n   */\n  lastErrorIndex = -1;\n  lastErrorStates = new IntervalSet();\n  /**\n   * This field is used to propagate information about the lookahead following\n   * the previous match. Since prediction prefers completing the current rule\n   * to error recovery efforts, error reporting may occur later than the\n   * original point where it was discoverable. The original context is used to\n   * compute the true expected sets as though the reporting occurred as early\n   * as possible.\n   */\n  nextTokensContext = null;\n  nextTokenState = 0;\n  /**\n   * The default implementation simply calls {@link endErrorCondition} to\n   * ensure that the handler is not in error recovery mode.\n   */\n  reset(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n  /**\n   * This method is called to enter error recovery mode when a recognition\n   * exception is reported.\n   *\n   * @param _recognizer the parser instance\n   */\n  beginErrorCondition(_recognizer) {\n    this.errorRecoveryMode = true;\n  }\n  inErrorRecoveryMode(_recognizer) {\n    return this.errorRecoveryMode;\n  }\n  /**\n   * This method is called to leave error recovery mode after recovering from\n   * a recognition exception.\n   */\n  endErrorCondition(_recognizer) {\n    this.errorRecoveryMode = false;\n    this.lastErrorStates = new IntervalSet();\n    this.lastErrorIndex = -1;\n  }\n  /**\n   * The default implementation simply calls {@link endErrorCondition}.\n   */\n  reportMatch(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n  /**\n   * The default implementation returns immediately if the handler is already\n   * in error recovery mode. Otherwise, it calls {@link beginErrorCondition}\n   * and dispatches the reporting task based on the runtime type of `e`\n   * according to the following table.\n   *\n   * - {@link NoViableAltException}: Dispatches the call to {@link reportNoViableAlternative}\n   * - {@link InputMismatchException}: Dispatches the call to {@link reportInputMismatch}\n   * - {@link FailedPredicateException}: Dispatches the call to {@link reportFailedPredicate}\n   * - All other types: calls {@link Parser.notifyErrorListeners} to report the exception\n   */\n  reportError(recognizer, e) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    if (e instanceof NoViableAltException) {\n      this.reportNoViableAlternative(recognizer, e);\n    } else if (e instanceof InputMismatchException) {\n      this.reportInputMismatch(recognizer, e);\n    } else if (e instanceof FailedPredicateException) {\n      this.reportFailedPredicate(recognizer, e);\n    } else {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n    }\n  }\n  /**\n   * The default implementation resynchronizes the parser by consuming tokens\n   * until we find one in the resynchronization set--loosely the set of tokens\n   * that can follow the current rule.\n   *\n   */\n  recover(recognizer, _e) {\n    if (this.lastErrorIndex === recognizer.inputStream?.index && this.lastErrorStates.contains(recognizer.state)) {\n      recognizer.consume();\n    }\n    this.lastErrorIndex = recognizer.inputStream?.index ?? 0;\n    this.lastErrorStates.addOne(recognizer.state);\n    const followSet = this.getErrorRecoverySet(recognizer);\n    this.consumeUntil(recognizer, followSet);\n  }\n  /**\n   * The default implementation of {@link ANTLRErrorStrategy.sync} makes sure\n   * that the current lookahead symbol is consistent with what were expecting\n   * at this point in the ATN. You can call this anytime but ANTLR only\n   * generates code to check before subrules/loops and each iteration.\n   *\n   * Implements Jim Idle's magic sync mechanism in closures and optional\n   * subrules. E.g.,\n   *\n   * ```\n   * a : sync ( stuff sync )* ;\n   * sync : {consume to what can follow sync} ;\n   * ```\n   *\n   * At the start of a sub rule upon error, {@link sync} performs single\n   * token deletion, if possible. If it can't do that, it bails on the current\n   * rule and uses the default error recovery, which consumes until the\n   * resynchronization set of the current rule.\n   *\n   * If the sub rule is optional (`(...)?`, `(...)*`, or block\n   * with an empty alternative), then the expected set includes what follows\n   * the subrule.\n   *\n   * During loop iteration, it consumes until it sees a token that can start a\n   * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n   * stay in the loop as long as possible.\n   *\n   * **ORIGINS**\n   *\n   * Previous versions of ANTLR did a poor job of their recovery within loops.\n   * A single mismatch token or missing token would force the parser to bail\n   * out of the entire rules surrounding the loop. So, for rule\n   *\n   * ```\n   * classDef : 'class' ID '{' member* '}'\n   * ```\n   *\n   * input with an extra token between members would force the parser to\n   * consume until it found the next class definition rather than the next\n   * member definition of the current class.\n   *\n   * This functionality cost a little bit of effort because the parser has to\n   * compare token set at the start of the loop and at each iteration. If for\n   * some reason speed is suffering for you, you can turn off this\n   * functionality by simply overriding this method as a blank { }.\n   *\n   */\n  sync(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    const s = recognizer.atn.states[recognizer.state];\n    const la = recognizer.tokenStream.LA(1);\n    const nextTokens = recognizer.atn.nextTokens(s);\n    if (nextTokens.contains(la)) {\n      this.nextTokensContext = null;\n      this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n      return;\n    }\n    if (nextTokens.contains(Token.EPSILON)) {\n      if (this.nextTokensContext === null) {\n        this.nextTokensContext = recognizer.context;\n        this.nextTokenState = recognizer.state;\n      }\n      return;\n    }\n    switch (s.constructor.stateType) {\n      case ATNState.BLOCK_START:\n      case ATNState.STAR_BLOCK_START:\n      case ATNState.PLUS_BLOCK_START:\n      case ATNState.STAR_LOOP_ENTRY: {\n        if (this.singleTokenDeletion(recognizer) !== null) {\n          return;\n        }\n        throw new InputMismatchException(recognizer);\n      }\n      case ATNState.PLUS_LOOP_BACK:\n      case ATNState.STAR_LOOP_BACK: {\n        this.reportUnwantedToken(recognizer);\n        const expecting = new IntervalSet();\n        expecting.addSet(recognizer.getExpectedTokens());\n        const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n        break;\n      }\n      default:\n    }\n  }\n  /**\n   * This is called by {@link reportError} when the exception is a\n   * {@link NoViableAltException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportNoViableAlternative(recognizer, e) {\n    if (e.message.length > 0) {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n      return;\n    }\n    const tokens = recognizer.tokenStream;\n    let input;\n    if (tokens !== null && e.startToken) {\n      if (e.startToken.type === Token.EOF) {\n        input = \"<EOF>\";\n      } else {\n        input = tokens.getTextFromRange(e.startToken, e.offendingToken);\n      }\n    } else {\n      input = \"<unknown input>\";\n    }\n    const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This is called by {@link reportError} when the exception is an {@link InputMismatchException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportInputMismatch(recognizer, e) {\n    if (e.message.length > 0) {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n      return;\n    }\n    const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) + \" expecting \" + e.getExpectedTokens().toStringWithVocabulary(recognizer.vocabulary);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This is called by {@link reportError} when the exception is a\n   * {@link FailedPredicateException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportFailedPredicate(recognizer, e) {\n    const ruleName = recognizer.ruleNames[recognizer.context.ruleIndex];\n    const msg = \"rule \" + ruleName + \" \" + e.message;\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This method is called to report a syntax error which requires the removal\n   * of a token from the input stream. At the time this method is called, the\n   * erroneous symbol is current `LT(1)` symbol and has not yet been\n   * removed from the input stream. When this method returns,\n   * `recognizer` is in error recovery mode.\n   *\n   * This method is called when {@link singleTokenDeletion} identifies\n   * single-token deletion as a viable recovery strategy for a mismatched\n   * input error.\n   *\n   * The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser.notifyErrorListeners}.\n   *\n   * @param recognizer the parser instance\n   */\n  reportUnwantedToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const tokenName = this.getTokenErrorDisplay(t);\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg = \"extraneous input \" + tokenName + \" expecting \" + expecting.toStringWithVocabulary(recognizer.vocabulary);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n  /**\n   * This method is called to report a syntax error which requires the\n   * insertion of a missing token into the input stream. At the time this\n   * method is called, the missing token has not yet been inserted. When this\n   * method returns, `recognizer` is in error recovery mode.\n   *\n   * This method is called when {@link singleTokenInsertion} identifies\n   * single-token insertion as a viable recovery strategy for a mismatched\n   * input error.\n   *\n   * The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser.notifyErrorListeners}.\n   *\n   * @param recognizer the parser instance\n   */\n  reportMissingToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg = \"missing \" + expecting.toStringWithVocabulary(recognizer.vocabulary) + \" at \" + this.getTokenErrorDisplay(t);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n  /**\n   * The default implementation attempts to recover from the mismatched input\n   * by using single token insertion and deletion as described below. If the\n   * recovery attempt fails, this method throws an\n   * {@link InputMismatchException}.\n   *\n   * **EXTRA TOKEN** (single token deletion)\n   *\n   * `LA(1)` is not what we are looking for. If `LA(2)` has the\n   * right token, however, then assume `LA(1)` is some extra spurious\n   * token and delete it. Then consume and return the next token (which was\n   * the `LA(2)` token) as the successful result of the match operation.\n   *\n   * This recovery strategy is implemented by {@link singleTokenDeletion}.\n   *\n   * **MISSING TOKEN** (single token insertion)\n   *\n   * If current token (at `LA(1)`) is consistent with what could come\n   * after the expected `LA(1)` token, then assume the token is missing\n   * and use the parser's {@link TokenFactory} to create it on the fly. The\n   * \"insertion\" is performed by returning the created token as the successful\n   * result of the match operation.\n   *\n   * This recovery strategy is implemented by {@link singleTokenInsertion}.\n   *\n   * **EXAMPLE**\n   *\n   * For example, Input `i=(3;` is clearly missing the `')'`. When\n   * the parser returns from the nested call to `expr`, it will have\n   * call chain:\n   *\n   * ```\n   * stat -> expr -> atom\n   * ```\n   *\n   * and it will be trying to match the `')'` at this point in the\n   * derivation:\n   *\n   * ```\n   * => ID '=' '(' INT ')' ('+' atom)* ';'\n   * ^\n   * ```\n   *\n   * The attempt to match `')'` will fail when it sees `';'` and\n   * call {@link recoverInline}. To recover, it sees that `LA(1)==';'`\n   * is in the set of tokens that can follow the `')'` token reference\n   * in rule `atom`. It can assume that you forgot the `')'`.\n   */\n  recoverInline(recognizer) {\n    const matchedSymbol = this.singleTokenDeletion(recognizer);\n    if (matchedSymbol) {\n      recognizer.consume();\n      return matchedSymbol;\n    }\n    if (this.singleTokenInsertion(recognizer)) {\n      return this.getMissingSymbol(recognizer);\n    }\n    throw new InputMismatchException(recognizer);\n  }\n  /**\n   * This method implements the single-token insertion inline error recovery\n   * strategy. It is called by {@link recoverInline} if the single-token\n   * deletion strategy fails to recover from the mismatched input. If this\n   * method returns `true`, `recognizer` will be in error recovery\n   * mode.\n   *\n   * This method determines whether or not single-token insertion is viable by\n   * checking if the `LA(1)` input symbol could be successfully matched\n   * if it were instead the `LA(2)` symbol. If this method returns\n   * `true`, the caller is responsible for creating and inserting a\n   * token with the correct type to produce this behavior.\n   *\n   * @param recognizer the parser instance\n   * @returns `true` if single-token insertion is a viable recovery\n   * strategy for the current mismatched input, otherwise `false`\n   */\n  singleTokenInsertion(recognizer) {\n    const currentSymbolType = recognizer.tokenStream?.LA(1) ?? -1;\n    const atn = recognizer.atn;\n    const currentState = atn.states[recognizer.state];\n    const next = currentState.transitions[0].target;\n    const expectingAtLL2 = atn.nextTokens(next, recognizer.context ?? void 0);\n    if (expectingAtLL2.contains(currentSymbolType)) {\n      this.reportMissingToken(recognizer);\n      return true;\n    }\n    return false;\n  }\n  /**\n   * This method implements the single-token deletion inline error recovery\n   * strategy. It is called by {@link recoverInline} to attempt to recover\n   * from mismatched input. If this method returns null, the parser and error\n   * handler state will not have changed. If this method returns non-null,\n   * `recognizer` will *not* be in error recovery mode since the\n   * returned token was a successful match.\n   *\n   * If the single-token deletion is successful, this method calls\n   * {@link reportUnwantedToken} to report the error, followed by\n   * {@link Parser.consume} to actually \"delete\" the extraneous token. Then,\n   * before returning {@link reportMatch} is called to signal a successful\n   * match.\n   *\n   * @param recognizer the parser instance\n   * @returns the successfully matched {@link Token} instance if single-token\n   * deletion successfully recovers from the mismatched input, otherwise\n   * `null`\n   */\n  singleTokenDeletion(recognizer) {\n    const nextTokenType = recognizer.tokenStream?.LA(2) ?? -1;\n    const expecting = this.getExpectedTokens(recognizer);\n    if (expecting.contains(nextTokenType)) {\n      this.reportUnwantedToken(recognizer);\n      recognizer.consume();\n      const matchedSymbol = recognizer.getCurrentToken();\n      this.reportMatch(recognizer);\n      return matchedSymbol;\n    }\n    return null;\n  }\n  /**\n   * Conjure up a missing token during error recovery.\n   *\n   * The recognizer attempts to recover from single missing\n   * symbols. But, actions might refer to that missing symbol.\n   * For example, x=ID {f($x);}. The action clearly assumes\n   * that there has been an identifier matched previously and that\n   * $x points at that token. If that token is missing, but\n   * the next token in the stream is what we want we assume that\n   * this token is missing and we keep going. Because we\n   * have to return some token to replace the missing token,\n   * we have to conjure one up. This method gives the user control\n   * over the tokens returned for missing tokens. Mostly,\n   * you will want to create something special for identifier\n   * tokens. For literals such as '{' and ',', the default\n   * action in the parser or tree parser works. It simply creates\n   * a CommonToken of the appropriate type. The text will be the token.\n   * If you change what tokens must be created by the lexer,\n   * override this method to create the appropriate tokens.\n   */\n  getMissingSymbol(recognizer) {\n    const currentSymbol = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    let expectedTokenType = Token.INVALID_TYPE;\n    if (expecting.length !== 0) {\n      expectedTokenType = expecting.minElement;\n    }\n    let tokenText;\n    if (expectedTokenType === Token.EOF) {\n      tokenText = \"<missing EOF>\";\n    } else {\n      tokenText = \"<missing \" + recognizer.vocabulary.getDisplayName(expectedTokenType) + \">\";\n    }\n    let current = currentSymbol;\n    const lookBack = recognizer.tokenStream?.LT(-1);\n    if (current.type === Token.EOF && lookBack !== null) {\n      current = lookBack;\n    }\n    return recognizer.getTokenFactory().create(\n      current.source,\n      expectedTokenType,\n      tokenText,\n      Token.DEFAULT_CHANNEL,\n      -1,\n      -1,\n      current.line,\n      current.column\n    );\n  }\n  getExpectedTokens(recognizer) {\n    return recognizer.getExpectedTokens();\n  }\n  /**\n   * How should a token be displayed in an error message? The default\n   * is to display just the text, but during development you might\n   * want to have a lot of information spit out. Override in that case\n   * to use t.toString() (which, for CommonToken, dumps everything about\n   * the token). This is better than forcing you to override a method in\n   * your token objects because you don't have to go modify your lexer\n   * so that it creates a new Java type.\n   */\n  getTokenErrorDisplay(t) {\n    if (t === null) {\n      return \"<no token>\";\n    }\n    let s = t.text;\n    if (!s) {\n      if (t.type === Token.EOF) {\n        s = \"<EOF>\";\n      } else {\n        s = \"<\" + t.type + \">\";\n      }\n    }\n    return this.escapeWSAndQuote(s);\n  }\n  escapeWSAndQuote(s) {\n    s = s.replace(/\\n/g, \"\\\\n\");\n    s = s.replace(/\\r/g, \"\\\\r\");\n    s = s.replace(/\\t/g, \"\\\\t\");\n    return \"'\" + s + \"'\";\n  }\n  /**\n   * Compute the error recovery set for the current rule. During\n   * rule invocation, the parser pushes the set of tokens that can\n   * follow that rule reference on the stack; this amounts to\n   * computing FIRST of what follows the rule reference in the\n   * enclosing rule. See LinearApproximator.FIRST().\n   * This local follow set only includes tokens\n   * from within the rule; i.e., the FIRST computation done by\n   * ANTLR stops at the end of a rule.\n   *\n   * EXAMPLE\n   *\n   * When you find a \"no viable alt exception\", the input is not\n   * consistent with any of the alternatives for rule r. The best\n   * thing to do is to consume tokens until you see something that\n   * can legally follow a call to r//or* any rule that called r.\n   * You don't want the exact set of viable next tokens because the\n   * input might just be missing a token--you might consume the\n   * rest of the input looking for one of the missing tokens.\n   *\n   * Consider grammar:\n   *\n   * a : '[' b ']'\n   * | '(' b ')'\n   * ;\n   * b : c '^' INT ;\n   * c : ID\n   * | INT\n   * ;\n   *\n   * At each rule invocation, the set of tokens that could follow\n   * that rule is pushed on a stack. Here are the various\n   * context-sensitive follow sets:\n   *\n   * FOLLOW(b1_in_a) = FIRST(']') = ']'\n   * FOLLOW(b2_in_a) = FIRST(')') = ')'\n   * FOLLOW(c_in_b) = FIRST('^') = '^'\n   *\n   * Upon erroneous input \"[]\", the call chain is\n   *\n   * a -> b -> c\n   *\n   * and, hence, the follow context stack is:\n   *\n   * depth follow set start of rule execution\n   * 0 <EOF> a (from main())\n   * 1 ']' b\n   * 2 '^' c\n   *\n   * Notice that ')' is not included, because b would have to have\n   * been called from a different context in rule a for ')' to be\n   * included.\n   *\n   * For error recovery, we cannot consider FOLLOW(c)\n   * (context-sensitive or otherwise). We need the combined set of\n   * all context-sensitive FOLLOW sets--the set of all tokens that\n   * could follow any reference in the call chain. We need to\n   * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n   * we resync'd to that token, we'd consume until EOF. We need to\n   * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n   * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n   * not consume anything. After printing an error, rule c would\n   * return normally. Rule b would not find the required '^' though.\n   * At this point, it gets a mismatched token error and throws an\n   * exception (since LA(1) is not in the viable following token\n   * set). The rule exception handler tries to recover, but finds\n   * the same recovery set and doesn't consume anything. Rule b\n   * exits normally returning to rule a. Now it finds the ']' (and\n   * with the successful match exits errorRecovery mode).\n   *\n   * So, you can see that the parser walks up the call chain looking\n   * for the token that was a member of the recovery set.\n   *\n   * Errors are not generated in errorRecovery mode.\n   *\n   * ANTLR's error recovery mechanism is based upon original ideas:\n   *\n   * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n   *\n   * and\n   *\n   * \"A note on error recovery in recursive descent parsers\":\n   * http://portal.acm.org/citation.cfm?id=947902.947905\n   *\n   * Later, Josef Grosch had some good ideas:\n   *\n   * \"Efficient and Comfortable Error Recovery in Recursive Descent\n   * Parsers\":\n   * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n   *\n   * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n   * at run-time upon error to avoid overhead during parsing.\n   */\n  getErrorRecoverySet(recognizer) {\n    const atn = recognizer.atn;\n    let ctx = recognizer.context;\n    const recoverSet = new IntervalSet();\n    while (ctx !== null && ctx.invokingState >= 0) {\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      const follow = atn.nextTokens(rt.followState);\n      recoverSet.addSet(follow);\n      ctx = ctx.parent;\n    }\n    recoverSet.removeOne(Token.EPSILON);\n    return recoverSet;\n  }\n  /** Consume tokens until one matches the given token set. */\n  consumeUntil(recognizer, set) {\n    let ttype = recognizer.tokenStream?.LA(1) ?? -1;\n    while (ttype !== Token.EOF && !set.contains(ttype)) {\n      recognizer.consume();\n      ttype = recognizer.tokenStream?.LA(1) ?? -1;\n    }\n  }\n};\n\n// src/BailErrorStrategy.ts\nvar BailErrorStrategy = class extends DefaultErrorStrategy {\n  static {\n    __name(this, \"BailErrorStrategy\");\n  }\n  /**\n   * Instead of recovering from exception `e`, re-throw it wrapped\n   * in a {@link ParseCancellationException} so it is not caught by the\n   * rule function catches. Use {@link Exception//getCause()} to get the\n   * original {@link RecognitionException}.\n   */\n  recover(recognizer, e) {\n    throw new ParseCancellationException(e);\n  }\n  /**\n   * Make sure we don't attempt to recover inline; if the parser\n   * successfully recovers, it won't throw an exception.\n   */\n  recoverInline(recognizer) {\n    const exception = new InputMismatchException(recognizer);\n    throw new ParseCancellationException(exception);\n  }\n  // Make sure we don't attempt to recover from problems in subrules.\n  sync(_recognizer) {\n  }\n};\n\n// src/ListTokenSource.ts\nvar ListTokenSource = class {\n  static {\n    __name(this, \"ListTokenSource\");\n  }\n  /**\n   * The name of the input source. If this value is `null`, a call to\n   * {@link #getSourceName} should return the source name used to create the\n   * the next token in {@link #tokens} (or the previous token if the end of\n   * the input has been reached).\n   */\n  sourceName;\n  tokenFactory = CommonTokenFactory.DEFAULT;\n  /**\n   * The wrapped collection of {@link Token} objects to return.\n   */\n  tokens;\n  /**\n   * The index into {@link tokens} of token to return by the next call to\n   * {@link #nextToken}. The end of the input is indicated by this value\n   * being greater than or equal to the number of items in {@link #tokens}.\n   */\n  i;\n  /**\n   * This field caches the EOF token for the token source.\n   */\n  eofToken;\n  constructor(tokens, sourceName) {\n    this.tokens = tokens;\n    this.sourceName = sourceName ?? \"\";\n  }\n  get column() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].column;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.column;\n    }\n    if (this.tokens.length > 0) {\n      const lastToken = this.tokens[this.tokens.length - 1];\n      const tokenText = lastToken.text;\n      if (tokenText) {\n        const lastNewLine = tokenText.lastIndexOf(\"\\n\");\n        if (lastNewLine >= 0) {\n          return tokenText.length - lastNewLine - 1;\n        }\n      }\n      return lastToken.column + lastToken.stop - lastToken.start + 1;\n    }\n    return 0;\n  }\n  nextToken() {\n    if (this.i >= this.tokens.length) {\n      if (this.eofToken === null) {\n        let start = -1;\n        if (this.tokens.length > 0) {\n          const previousStop = this.tokens[this.tokens.length - 1].stop;\n          if (previousStop !== -1) {\n            start = previousStop + 1;\n          }\n        }\n        const stop = Math.max(-1, start - 1);\n        this.eofToken = this.tokenFactory.create(\n          [this, this.inputStream],\n          Token.EOF,\n          \"EOF\",\n          Token.DEFAULT_CHANNEL,\n          start,\n          stop,\n          this.line,\n          this.column\n        );\n      }\n      return this.eofToken;\n    }\n    const t = this.tokens[this.i];\n    if (this.i === this.tokens.length - 1 && t.type === Token.EOF) {\n      this.eofToken = t;\n    }\n    this.i++;\n    return t;\n  }\n  get line() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].line;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.line;\n    }\n    if (this.tokens.length > 0) {\n      const lastToken = this.tokens[this.tokens.length - 1];\n      let line = lastToken.line;\n      const tokenText = lastToken.text;\n      if (tokenText) {\n        for (const char of tokenText) {\n          if (char === \"\\n\") {\n            line++;\n          }\n        }\n      }\n      return line;\n    }\n    return 1;\n  }\n  get inputStream() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].inputStream;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.inputStream;\n    }\n    if (this.tokens.length > 0) {\n      return this.tokens[this.tokens.length - 1].inputStream;\n    }\n    return null;\n  }\n  getSourceName() {\n    if (this.sourceName !== null) {\n      return this.sourceName;\n    }\n    const inputStream = this.inputStream;\n    if (inputStream !== null) {\n      return inputStream.getSourceName();\n    }\n    return \"List\";\n  }\n};\n\n// src/InterpreterRuleContext.ts\nvar InterpreterRuleContext = class extends ParserRuleContext {\n  static {\n    __name(this, \"InterpreterRuleContext\");\n  }\n  /** This is the backing field for {@link #getRuleIndex}. */\n  #ruleIndex;\n  constructor(ruleIndex, parent, invokingStateNumber) {\n    super(parent, invokingStateNumber);\n    this.#ruleIndex = ruleIndex;\n  }\n  get ruleIndex() {\n    return this.#ruleIndex;\n  }\n};\n\n// src/TraceListener.ts\nvar TraceListener = class {\n  static {\n    __name(this, \"TraceListener\");\n  }\n  parser;\n  constructor(parser) {\n    this.parser = parser;\n  }\n  enterEveryRule(ctx) {\n    console.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser.inputStream?.LT(1)?.text);\n  }\n  visitTerminal(node) {\n    console.log(\"consume \" + node.getSymbol() + \" rule \" + this.parser.ruleNames[this.parser.context.ruleIndex]);\n  }\n  exitEveryRule(ctx) {\n    console.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser.inputStream?.LT(1)?.text);\n  }\n  visitErrorNode(_node) {\n  }\n};\n\n// src/Parser.ts\nvar Parser = class extends Recognizer {\n  static {\n    __name(this, \"Parser\");\n  }\n  /** For testing only. */\n  printer = null;\n  /**\n   * Specifies whether or not the parser should construct a parse tree during\n   * the parsing process. The default value is `true`.\n   *\n   * @see #getBuildParseTree\n   * @see #setBuildParseTree\n   */\n  buildParseTrees = true;\n  /**\n   * The error handling strategy for the parser. The default value is a new\n   * instance of {@link DefaultErrorStrategy}.\n   *\n   * @see #getErrorHandler\n   * @see #setErrorHandler\n   */\n  errorHandler = new DefaultErrorStrategy();\n  /**\n   * The {@link ParserRuleContext} object for the currently executing rule.\n   * This is always non-null during the parsing process.\n   */\n  // TODO: make private\n  context = null;\n  precedenceStack = [];\n  /**\n   * The list of {@link ParseTreeListener} listeners registered to receive\n   * events during the parse.\n   *\n   * @see #addParseListener\n   */\n  parseListeners = null;\n  /**\n   * The number of syntax errors reported during parsing. This value is\n   * incremented each time {@link #notifyErrorListeners} is called.\n   */\n  syntaxErrors = 0;\n  /** Indicates parser has matched EOF token. See {@link #exitRule()}. */\n  matchedEOF = false;\n  /**\n   * When {@link #setTrace}`(true)` is called, a reference to the\n   * {@link TraceListener} is stored here so it can be easily removed in a\n   * later call to {@link #setTrace}`(false)`. The listener itself is\n   * implemented as a parser listener so this field is not directly used by\n   * other parser methods.\n   */\n  #tracer = null;\n  /**\n   * This field holds the deserialized {@link ATN} with bypass alternatives, created\n   * lazily upon first demand. In 4.10 I changed from map<serializedATNstring, ATN>\n   * since we only need one per parser object and also it complicates other targets\n   * that don't use ATN strings.\n   *\n   * @see ATNDeserializationOptions#isGenerateRuleBypassTransitions()\n   */\n  #bypassAltsAtnCache = null;\n  #inputStream;\n  /**\n   * This is all the parsing support code essentially. Most of it is error recovery stuff.\n   */\n  constructor(input) {\n    super();\n    this.precedenceStack.push(0);\n    this.syntaxErrors = 0;\n    this.#inputStream = input;\n  }\n  /** reset the parser's state */\n  reset(rewindInputStream = true) {\n    if (rewindInputStream) {\n      this.inputStream.seek(0);\n    }\n    this.errorHandler.reset(this);\n    this.context = null;\n    this.syntaxErrors = 0;\n    this.matchedEOF = false;\n    this.setTrace(false);\n    this.precedenceStack = [];\n    this.precedenceStack.push(0);\n    if (this.interpreter) {\n      this.interpreter.reset();\n    }\n  }\n  /**\n   * Match current input symbol against `ttype`. If the symbol type\n   * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link consume} are\n   * called to complete the match process.\n   *\n   * If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link buildParseTree} is\n   * `true` and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.\n   *\n   * @param ttype the token type to match\n   * @returns the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * `ttype` and the error strategy could not recover from the\n   * mismatched symbol\n   */\n  match(ttype) {\n    let t = this.getCurrentToken();\n    if (t.type === ttype) {\n      if (ttype === Token.EOF) {\n        this.matchedEOF = true;\n      }\n      this.errorHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this.errorHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        this.context.addErrorNode(this.createErrorNode(this.context, t));\n      }\n    }\n    return t;\n  }\n  /**\n   * Match current input symbol as a wildcard. If the symbol type matches\n   * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n   * and {@link consume} are called to complete the match process.\n   *\n   * If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link buildParseTree} is\n   * `true` and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.\n   *\n   * @returns the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * a wildcard and the error strategy could not recover from the mismatched\n   * symbol\n   */\n  matchWildcard() {\n    let t = this.getCurrentToken();\n    if (t.type > 0) {\n      this.errorHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this.errorHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        this.context.addErrorNode(this.createErrorNode(this.context, t));\n      }\n    }\n    return t;\n  }\n  getParseListeners() {\n    return this.parseListeners ?? [];\n  }\n  /**\n   * Registers `listener` to receive events during the parsing process.\n   *\n   * To support output-preserving grammar transformations (including but not\n   * limited to left-recursion removal, automated left-factoring, and\n   * optimized code generation), calls to listener methods during the parse\n   * may differ substantially from calls made by\n   * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n   * particular, rule entry and exit events may occur in a different order\n   * during the parse than after the parser. In addition, calls to certain\n   * rule entry methods may be omitted.\n   *\n   * With the following specific exceptions, calls to listener events are\n   * deterministic*, i.e. for identical input the calls to listener\n   * methods will be the same.\n   *\n   * - Alterations to the grammar used to generate code may change the\n   * behavior of the listener calls.\n   * - Alterations to the command line options passed to ANTLR 4 when\n   * generating the parser may change the behavior of the listener calls.\n   * - Changing the version of the ANTLR Tool used to generate the parser\n   * may change the behavior of the listener calls.\n   *\n   * @param listener the listener to add\n   *\n   * @throws NullPointerException if {@code} listener is `null`\n   */\n  addParseListener(listener) {\n    if (listener === null) {\n      throw new Error(\"listener\");\n    }\n    if (this.parseListeners === null) {\n      this.parseListeners = [];\n    }\n    this.parseListeners.push(listener);\n  }\n  /**\n   * Remove `listener` from the list of parse listeners.\n   *\n   * If `listener` is `null` or has not been added as a parse\n   * listener, this method does nothing.\n   *\n   * @param listener the listener to remove\n   */\n  removeParseListener(listener) {\n    if (this.parseListeners !== null && listener !== null) {\n      const idx = this.parseListeners.indexOf(listener);\n      if (idx >= 0) {\n        this.parseListeners.splice(idx, 1);\n      }\n      if (this.parseListeners.length === 0) {\n        this.parseListeners = null;\n      }\n    }\n  }\n  // Remove all parse listeners.\n  removeParseListeners() {\n    this.parseListeners = null;\n  }\n  // Notify any parse listeners of an enter rule event.\n  triggerEnterRuleEvent() {\n    if (this.parseListeners !== null) {\n      const ctx = this.context;\n      this.parseListeners.forEach((listener) => {\n        listener.enterEveryRule(ctx);\n        ctx.enterRule(listener);\n      });\n    }\n  }\n  /**\n   * Notify any parse listeners of an exit rule event.\n   *\n   * @see //addParseListener\n   */\n  triggerExitRuleEvent() {\n    if (this.parseListeners !== null) {\n      const ctx = this.context;\n      this.parseListeners.slice(0).reverse().forEach((listener) => {\n        ctx.exitRule(listener);\n        listener.exitEveryRule(ctx);\n      });\n    }\n  }\n  getTokenFactory() {\n    return this.inputStream.tokenSource.tokenFactory;\n  }\n  // Tell our token source and error strategy about a new way to create tokens.\n  setTokenFactory(factory) {\n    this.inputStream.tokenSource.tokenFactory = factory;\n  }\n  /**\n   * The preferred method of getting a tree pattern. For example, here's a\n   * sample use:\n   *\n   * ```\n   * const t = parser.expr();\n   * const p = parser.compileParseTreePattern(\"<ID>+0\", MyParser.RULE_expr);\n   * const m = p.match(t);\n   * const id = m.get(\"ID\");\n   * ```\n   */\n  compileParseTreePattern(pattern, patternRuleIndex, lexer) {\n    if (!lexer) {\n      if (this.tokenStream !== null) {\n        const tokenSource = this.tokenStream.tokenSource;\n        if (tokenSource instanceof Lexer) {\n          lexer = tokenSource;\n        }\n      }\n    }\n    if (!lexer) {\n      throw new Error(\"Parser can't discover a lexer to use\");\n    }\n    const m2 = new ParseTreePatternMatcher(lexer, this);\n    return m2.compile(pattern, patternRuleIndex);\n  }\n  /**\n   * The ATN with bypass alternatives is expensive to create so we create it\n   * lazily.\n   *\n   * @throws UnsupportedOperationException if the current parser does not\n   * implement the {@link getSerializedATN()} method.\n   */\n  getATNWithBypassAlts() {\n    const serializedAtn = this.getSerializedATN();\n    if (serializedAtn === null) {\n      throw new Error(\"The current parser does not support an ATN with bypass alternatives.\");\n    }\n    if (this.#bypassAltsAtnCache !== null) {\n      return this.#bypassAltsAtnCache;\n    }\n    const deserializationOptions = { readOnly: false, verifyATN: true, generateRuleBypassTransitions: true };\n    this.#bypassAltsAtnCache = new ATNDeserializer(deserializationOptions).deserialize(serializedAtn);\n    return this.#bypassAltsAtnCache;\n  }\n  /**\n   * Gets the number of syntax errors reported during parsing. This value is\n   * incremented each time {@link notifyErrorListeners} is called.\n   */\n  get numberOfSyntaxErrors() {\n    return this.syntaxErrors;\n  }\n  get inputStream() {\n    return this.#inputStream;\n  }\n  set inputStream(input) {\n    this.tokenStream = input;\n  }\n  get tokenStream() {\n    return this.#inputStream;\n  }\n  /** Set the token stream and reset the parser. */\n  set tokenStream(input) {\n    this.reset(false);\n    this.#inputStream = input;\n  }\n  /**\n   * Match needs to return the current input symbol, which gets put\n   * into the label for the associated token ref; e.g., x=ID.\n   */\n  getCurrentToken() {\n    return this.inputStream.LT(1);\n  }\n  notifyErrorListeners(msg, offendingToken, err) {\n    offendingToken = offendingToken ?? null;\n    err = err ?? null;\n    if (offendingToken === null) {\n      offendingToken = this.getCurrentToken();\n    }\n    this.syntaxErrors += 1;\n    const line = offendingToken.line;\n    const column = offendingToken.column;\n    this.errorListenerDispatch.syntaxError(this, offendingToken, line, column, msg, err);\n  }\n  /**\n   * Consume and return the {@link getCurrentToken current symbol}.\n   *\n   * E.g., given the following input with `A` being the current\n   * lookahead symbol, this function moves the cursor to `B` and returns\n   * `A`.\n   *\n   * ```\n   * A B\n   * ^\n   * ```\n   *\n   * If the parser is not in error recovery mode, the consumed symbol is added\n   * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n   * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n   * If the parser *is* in error recovery mode, the consumed symbol is\n   * added to the parse tree using\n   * {@link ParserRuleContext//addErrorNode(Token)}, and\n   * {@link ParseTreeListener//visitErrorNode} is called on any parse\n   * listeners.\n   */\n  consume() {\n    const o = this.getCurrentToken();\n    if (o.type !== Token.EOF) {\n      this.tokenStream.consume();\n    }\n    const hasListener = this.parseListeners !== null && this.parseListeners.length > 0;\n    if (this.buildParseTrees || hasListener) {\n      let node;\n      if (this.errorHandler.inErrorRecoveryMode(this)) {\n        node = this.context.addErrorNode(this.createErrorNode(this.context, o));\n      } else {\n        node = this.context.addTokenNode(o);\n      }\n      if (hasListener) {\n        this.parseListeners.forEach((listener) => {\n          if (node instanceof ErrorNode) {\n            listener.visitErrorNode(node);\n          } else {\n            listener.visitTerminal(node);\n          }\n        });\n      }\n    }\n    return o;\n  }\n  addContextToParseTree() {\n    if (this.context?.parent) {\n      this.context.parent.addChild(this.context);\n    }\n  }\n  /**\n   * Always called by generated parsers upon entry to a rule. Access field\n   * {@link context} get the current context.\n   */\n  enterRule(localctx, state, _ruleIndex) {\n    this.state = state;\n    this.context = localctx;\n    this.context.start = this.inputStream.LT(1);\n    if (this.buildParseTrees) {\n      this.addContextToParseTree();\n    }\n    this.triggerEnterRuleEvent();\n  }\n  exitRule() {\n    if (this.matchedEOF) {\n      this.context.stop = this.inputStream.LT(1);\n    } else {\n      this.context.stop = this.inputStream.LT(-1);\n    }\n    this.triggerExitRuleEvent();\n    this.state = this.context.invokingState;\n    this.context = this.context.parent;\n  }\n  enterOuterAlt(localctx, altNum) {\n    localctx.setAltNumber(altNum);\n    if (this.buildParseTrees && this.context !== localctx) {\n      if (this.context?.parent) {\n        this.context.parent.removeLastChild();\n        this.context.parent.addChild(localctx);\n      }\n    }\n    this.context = localctx;\n  }\n  /**\n   * Get the precedence level for the top-most precedence rule.\n   *\n   * @returns The precedence level for the top-most precedence rule, or -1 if\n   * the parser context is not nested within a precedence rule.\n   */\n  getPrecedence() {\n    if (this.precedenceStack.length === 0) {\n      return -1;\n    }\n    return this.precedenceStack[this.precedenceStack.length - 1];\n  }\n  enterRecursionRule(localctx, state, ruleIndex, precedence) {\n    this.state = state;\n    this.precedenceStack.push(precedence);\n    this.context = localctx;\n    this.context.start = this.inputStream.LT(1);\n    this.triggerEnterRuleEvent();\n  }\n  /** Like {@link enterRule} but for recursive rules. */\n  pushNewRecursionContext(localctx, state, _ruleIndex) {\n    const previous = this.context;\n    previous.parent = localctx;\n    previous.invokingState = state;\n    previous.stop = this.inputStream.LT(-1);\n    this.context = localctx;\n    this.context.start = previous.start;\n    if (this.buildParseTrees) {\n      this.context.addChild(previous);\n    }\n    this.triggerEnterRuleEvent();\n  }\n  unrollRecursionContexts(parent) {\n    this.precedenceStack.pop();\n    this.context.stop = this.inputStream.LT(-1);\n    const retCtx = this.context;\n    const parseListeners = this.getParseListeners();\n    if (parseListeners !== null && parseListeners.length > 0) {\n      while (this.context !== parent) {\n        this.triggerExitRuleEvent();\n        this.context = this.context.parent;\n      }\n    } else {\n      this.context = parent;\n    }\n    retCtx.parent = parent;\n    if (this.buildParseTrees && parent !== null) {\n      parent.addChild(retCtx);\n    }\n  }\n  getInvokingContext(ruleIndex) {\n    let ctx = this.context;\n    while (ctx !== null) {\n      if (ctx.ruleIndex === ruleIndex) {\n        return ctx;\n      }\n      ctx = ctx.parent;\n    }\n    return null;\n  }\n  precpred(_localctx, precedence) {\n    return precedence >= this.precedenceStack[this.precedenceStack.length - 1];\n  }\n  /**\n   * Checks whether or not `symbol` can follow the current state in the\n   * ATN. The behavior of this method is equivalent to the following, but is\n   * implemented such that the complete context-sensitive follow set does not\n   * need to be explicitly constructed.\n   *\n   * ```\n   * return getExpectedTokens().contains(symbol);\n   * ```\n   *\n   * @param symbol the symbol type to check\n   * @returns `true` if `symbol` can follow the current state in\n   * the ATN, otherwise `false`.\n   */\n  isExpectedToken(symbol) {\n    const atn = this.interpreter.atn;\n    let ctx = this.context;\n    const s = atn.states[this.state];\n    let following = atn.nextTokens(s);\n    if (following.contains(symbol)) {\n      return true;\n    }\n    if (!following.contains(Token.EPSILON)) {\n      return false;\n    }\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = atn.nextTokens(rt.followState);\n      if (following.contains(symbol)) {\n        return true;\n      }\n      ctx = ctx.parent;\n    }\n    if (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n  /**\n   * Computes the set of input symbols which could follow the current parser\n   * state and context, as given by {@link getState} and {@link getContext},\n   * respectively.\n   *\n   * {@link ATN.getExpectedTokens ATN.getExpectedTokens(int, RuleContext)}\n   */\n  getExpectedTokens() {\n    return this.interpreter.atn.getExpectedTokens(this.state, this.context);\n  }\n  getExpectedTokensWithinCurrentRule() {\n    const atn = this.interpreter.atn;\n    const s = atn.states[this.state];\n    return atn.nextTokens(s);\n  }\n  /** Get a rule's index (i.e., `RULE_ruleName` field) or -1 if not found. */\n  getRuleIndex(ruleName) {\n    return this.getRuleIndexMap().get(ruleName) ?? -1;\n  }\n  /**\n   * @returns an array of string of the rule names in your parser instance\n   * leading up to a call to the current rule. You could override if\n   * you want more details such as the file/line info of where\n   * in the ATN a rule is invoked.\n   *\n   * this is very useful for error messages.\n   */\n  getRuleInvocationStack(p) {\n    p = p ?? null;\n    if (p === null) {\n      p = this.context;\n    }\n    const stack = [];\n    while (p !== null) {\n      const ruleIndex = p.ruleIndex;\n      if (ruleIndex < 0) {\n        stack.push(\"n/a\");\n      } else {\n        stack.push(this.ruleNames[ruleIndex]);\n      }\n      p = p.parent;\n    }\n    return stack;\n  }\n  /**\n   * For debugging and other purposes.\n   *\n   * TODO: this differs from the Java version. Change it.\n   */\n  getDFAStrings() {\n    return this.interpreter.decisionToDFA.toString();\n  }\n  /** For debugging and other purposes. */\n  dumpDFA() {\n    let seenOne = false;\n    for (const dfa of this.interpreter.decisionToDFA) {\n      if (dfa.length > 0) {\n        if (seenOne) {\n          console.log();\n        }\n        if (this.printer) {\n          this.printer.println(\"Decision \" + dfa.decision + \":\");\n          this.printer.print(dfa.toString(this.vocabulary));\n        }\n        seenOne = true;\n      }\n    }\n  }\n  getSourceName() {\n    return this.inputStream.getSourceName();\n  }\n  getParseInfo() {\n    const interp = this.interpreter;\n    if (interp instanceof ProfilingATNSimulator) {\n      return new ParseInfo(interp);\n    }\n    return void 0;\n  }\n  setProfile(profile) {\n    const interp = this.interpreter;\n    const saveMode = interp.predictionMode;\n    if (profile) {\n      if (!(interp instanceof ProfilingATNSimulator)) {\n        this.interpreter = new ProfilingATNSimulator(this);\n      }\n    } else if (interp instanceof ProfilingATNSimulator) {\n      const sharedContextCache = interp.sharedContextCache;\n      if (sharedContextCache) {\n        const sim = new ParserATNSimulator(this, this.atn, interp.decisionToDFA, sharedContextCache);\n        this.interpreter = sim;\n      }\n    }\n    this.interpreter.predictionMode = saveMode;\n  }\n  /**\n   * During a parse is sometimes useful to listen in on the rule entry and exit\n   * events as well as token matches. this is for quick and dirty debugging.\n   */\n  setTrace(trace) {\n    if (!trace) {\n      this.removeParseListener(this.#tracer);\n      this.#tracer = null;\n    } else {\n      if (this.#tracer !== null) {\n        this.removeParseListener(this.#tracer);\n      }\n      this.#tracer = new TraceListener(this);\n      this.addParseListener(this.#tracer);\n    }\n  }\n  createTerminalNode(parent, t) {\n    return new TerminalNode(t);\n  }\n  createErrorNode(parent, t) {\n    return new ErrorNode(t);\n  }\n};\n\n// src/ParserInterpreter.ts\nvar ParserInterpreter = class extends Parser {\n  static {\n    __name(this, \"ParserInterpreter\");\n  }\n  rootContext;\n  overrideDecisionRoot = null;\n  parentContextStack = [];\n  #overrideDecision = -1;\n  #overrideDecisionInputIndex = -1;\n  #overrideDecisionAlt = -1;\n  #overrideDecisionReached = false;\n  #grammarFileName;\n  #atn;\n  #ruleNames;\n  #vocabulary;\n  #decisionToDFA;\n  #sharedContextCache = new PredictionContextCache();\n  #pushRecursionContextStates;\n  constructor(grammarFileName, vocabulary, ruleNames, atn, input) {\n    super(input);\n    this.#grammarFileName = grammarFileName;\n    this.#atn = atn;\n    this.#ruleNames = ruleNames.slice(0);\n    this.#vocabulary = vocabulary;\n    this.#pushRecursionContextStates = new BitSet();\n    for (const state of atn.states) {\n      if (state instanceof StarLoopEntryState && state.precedenceRuleDecision) {\n        this.#pushRecursionContextStates.set(state.stateNumber);\n      }\n    }\n    this.#decisionToDFA = atn.decisionToState.map((ds, i) => {\n      return new DFA(ds, i);\n    });\n    this.interpreter = new ParserATNSimulator(this, atn, this.#decisionToDFA, this.#sharedContextCache);\n  }\n  reset() {\n    super.reset();\n    this.#overrideDecisionReached = false;\n    this.overrideDecisionRoot = null;\n  }\n  get atn() {\n    return this.#atn;\n  }\n  get vocabulary() {\n    return this.#vocabulary;\n  }\n  get ruleNames() {\n    return this.#ruleNames;\n  }\n  get grammarFileName() {\n    return this.#grammarFileName;\n  }\n  get atnState() {\n    return this.#atn.states[this.state];\n  }\n  parse(startRuleIndex) {\n    const startRuleStartState = this.#atn.ruleToStartState[startRuleIndex];\n    this.rootContext = this.createInterpreterRuleContext(null, ATNState.INVALID_STATE_NUMBER, startRuleIndex);\n    if (startRuleStartState.isLeftRecursiveRule) {\n      this.enterRecursionRule(this.rootContext, startRuleStartState.stateNumber, startRuleIndex, 0);\n    } else {\n      this.enterRule(this.rootContext, startRuleStartState.stateNumber, startRuleIndex);\n    }\n    while (true) {\n      const p = this.atnState;\n      switch (p.constructor.stateType) {\n        case ATNState.RULE_STOP:\n          if (this.context?.isEmpty()) {\n            if (startRuleStartState.isLeftRecursiveRule) {\n              const result = this.context;\n              const parentContext = this.parentContextStack.pop();\n              this.unrollRecursionContexts(parentContext[0]);\n              return result;\n            } else {\n              this.exitRule();\n              return this.rootContext;\n            }\n          }\n          this.visitRuleStopState(p);\n          break;\n        default:\n          try {\n            this.visitState(p);\n          } catch (e) {\n            if (e instanceof RecognitionException) {\n              this.state = this.#atn.ruleToStopState[p.ruleIndex].stateNumber;\n              this.errorHandler.reportError(this, e);\n              this.recover(e);\n            } else {\n              throw e;\n            }\n          }\n          break;\n      }\n    }\n  }\n  addDecisionOverride(decision, tokenIndex, forcedAlt) {\n    this.#overrideDecision = decision;\n    this.#overrideDecisionInputIndex = tokenIndex;\n    this.#overrideDecisionAlt = forcedAlt;\n  }\n  get overrideDecision() {\n    return this.#overrideDecision;\n  }\n  get overrideDecisionInputIndex() {\n    return this.#overrideDecisionInputIndex;\n  }\n  enterRecursionRule(localctx, state, ruleIndex, precedence) {\n    this.parentContextStack.push([this.context, localctx.invokingState]);\n    super.enterRecursionRule(localctx, state, ruleIndex, precedence);\n  }\n  visitState(p) {\n    let predictedAlt = 1;\n    if (p instanceof DecisionState) {\n      predictedAlt = this.visitDecisionState(p);\n    }\n    const transition = p.transitions[predictedAlt - 1];\n    switch (transition.transitionType) {\n      case Transition.EPSILON:\n        if (this.#pushRecursionContextStates.get(p.stateNumber) && !(transition.target.constructor.stateType === ATNState.LOOP_END)) {\n          const parentContext = this.parentContextStack[this.parentContextStack.length - 1];\n          const localctx = this.createInterpreterRuleContext(parentContext[0], parentContext[1], this.context.ruleIndex);\n          this.pushNewRecursionContext(\n            localctx,\n            this.#atn.ruleToStartState[p.ruleIndex].stateNumber,\n            this.context.ruleIndex\n          );\n        }\n        break;\n      case Transition.ATOM:\n        this.match(transition.label.minElement);\n        break;\n      case Transition.RANGE:\n      case Transition.SET:\n      case Transition.NOT_SET:\n        if (!transition.matches(this.inputStream.LA(1), Token.MIN_USER_TOKEN_TYPE, 65535)) {\n          this.recoverInline();\n        }\n        this.matchWildcard();\n        break;\n      case Transition.WILDCARD:\n        this.matchWildcard();\n        break;\n      case Transition.RULE:\n        const ruleStartState = transition.target;\n        const ruleIndex = ruleStartState.ruleIndex;\n        const newContext = this.createInterpreterRuleContext(this.context, p.stateNumber, ruleIndex);\n        if (ruleStartState.isLeftRecursiveRule) {\n          this.enterRecursionRule(\n            newContext,\n            ruleStartState.stateNumber,\n            ruleIndex,\n            transition.precedence\n          );\n        } else {\n          this.enterRule(newContext, transition.target.stateNumber, ruleIndex);\n        }\n        break;\n      case Transition.PREDICATE:\n        const predicateTransition = transition;\n        if (!this.sempred(this.context, predicateTransition.ruleIndex, predicateTransition.predIndex)) {\n          throw new FailedPredicateException(this);\n        }\n        break;\n      case Transition.ACTION:\n        const actionTransition = transition;\n        this.action(this.context, actionTransition.ruleIndex, actionTransition.actionIndex);\n        break;\n      case Transition.PRECEDENCE:\n        if (!this.precpred(this.context, transition.precedence)) {\n          const precedence = transition.precedence;\n          throw new FailedPredicateException(this, `precpred(_ctx, ${precedence})`);\n        }\n        break;\n      default:\n        throw new Error(\"UnsupportedOperationException: Unrecognized ATN transition type.\");\n    }\n    this.state = transition.target.stateNumber;\n  }\n  visitDecisionState(p) {\n    let predictedAlt = 1;\n    if (p.transitions.length > 1) {\n      this.errorHandler.sync(this);\n      const decision = p.decision;\n      if (decision === this.#overrideDecision && this.inputStream.index === this.#overrideDecisionInputIndex && !this.#overrideDecisionReached) {\n        predictedAlt = this.#overrideDecisionAlt;\n        this.#overrideDecisionReached = true;\n      } else {\n        predictedAlt = this.interpreter.adaptivePredict(this.inputStream, decision, this.context);\n      }\n    }\n    return predictedAlt;\n  }\n  createInterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {\n    return new InterpreterRuleContext(ruleIndex, parent, invokingStateNumber);\n  }\n  visitRuleStopState(p) {\n    const ruleStartState = this.#atn.ruleToStartState[p.ruleIndex];\n    if (ruleStartState.isLeftRecursiveRule) {\n      const [parentContext, state] = this.parentContextStack.pop();\n      this.unrollRecursionContexts(parentContext);\n      this.state = state;\n    } else {\n      this.exitRule();\n    }\n    const ruleTransition = this.#atn.states[this.state].transitions[0];\n    this.state = ruleTransition.followState.stateNumber;\n  }\n  recover(e) {\n    const i = this.inputStream.index;\n    this.errorHandler.recover(this, e);\n    if (this.inputStream.index === i) {\n      const tok = e.offendingToken;\n      if (!tok) {\n        throw new Error(\"Expected exception to have an offending token\");\n      }\n      const source = tok.tokenSource;\n      const stream = source?.inputStream ?? null;\n      const sourcePair = [source, stream];\n      if (e instanceof InputMismatchException) {\n        const expectedTokens = e.getExpectedTokens();\n        if (!expectedTokens) {\n          throw new Error(\"Expected the exception to provide expected tokens\");\n        }\n        let expectedTokenType = Token.INVALID_TYPE;\n        if (expectedTokens.length !== 0) {\n          expectedTokenType = expectedTokens.minElement;\n        }\n        const errToken = this.getTokenFactory().create(\n          sourcePair,\n          expectedTokenType,\n          tok.text,\n          Token.DEFAULT_CHANNEL,\n          -1,\n          -1,\n          tok.line,\n          tok.column\n        );\n        this.context.addErrorNode(this.createErrorNode(this.context, errToken));\n      } else {\n        const errToken = this.getTokenFactory().create(\n          sourcePair,\n          Token.INVALID_TYPE,\n          tok.text,\n          Token.DEFAULT_CHANNEL,\n          -1,\n          -1,\n          tok.line,\n          tok.column\n        );\n        this.context.addErrorNode(this.createErrorNode(this.context, errToken));\n      }\n    }\n  }\n  recoverInline() {\n    return this.errorHandler.recoverInline(this);\n  }\n};\n\n// src/misc/MultiMap.ts\nvar MultiMap = class extends Map {\n  static {\n    __name(this, \"MultiMap\");\n  }\n  map(key, value) {\n    let elementsForKey = this.get(key);\n    if (!elementsForKey) {\n      elementsForKey = new Array();\n      this.set(key, elementsForKey);\n    }\n    elementsForKey.push(value);\n  }\n  getPairs() {\n    const pairs = new Array();\n    for (const key of this.keys()) {\n      const keys = this.get(key) ?? [];\n      for (const value of keys) {\n        pairs.push([key, value]);\n      }\n    }\n    return pairs;\n  }\n};\n\n// src/tree/pattern/CannotInvokeStartRuleError.ts\nvar CannotInvokeStartRuleError = class extends Error {\n  static {\n    __name(this, \"CannotInvokeStartRuleError\");\n  }\n  constructor(e) {\n    super();\n    this.cause = e;\n  }\n};\n\n// src/tree/pattern/RuleTagToken.ts\nvar RuleTagToken = class {\n  static {\n    __name(this, \"RuleTagToken\");\n  }\n  /** The name of the label associated with the rule tag. */\n  label;\n  /** The name of the parser rule associated with this rule tag. */\n  ruleName;\n  /**\n   * The token type for the current token. This is the token type assigned to\n   * the bypass alternative for the rule during ATN deserialization.\n   */\n  bypassTokenType;\n  constructor(ruleName, bypassTokenType, label) {\n    this.ruleName = ruleName;\n    this.bypassTokenType = bypassTokenType;\n    this.label = label;\n  }\n  /**\n   * Rule tag tokens are always placed on the {@link #DEFAULT_CHANNEL}.\n   */\n  get channel() {\n    return Token.DEFAULT_CHANNEL;\n  }\n  /**\n   * This method returns the rule tag formatted with `<` and `>`\n   * delimiters.\n   */\n  get text() {\n    if (this.label !== null) {\n      return \"<\" + this.label + \":\" + this.ruleName + \">\";\n    }\n    return \"<\" + this.ruleName + \">\";\n  }\n  /**\n   * Rule tag tokens have types assigned according to the rule bypass\n   * transitions created during ATN deserialization.\n   */\n  get type() {\n    return this.bypassTokenType;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns 0.\n   */\n  get line() {\n    return 0;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get column() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get tokenIndex() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get start() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get stop() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns `null`.\n   */\n  get tokenSource() {\n    return null;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns `null`.\n   */\n  get inputStream() {\n    return null;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} returns a string of the form\n   * `ruleName:bypassTokenType`.\n   */\n  toString() {\n    return this.ruleName + \":\" + this.bypassTokenType;\n  }\n};\n\n// src/tree/pattern/StartRuleDoesNotConsumeFullPatternError.ts\nvar StartRuleDoesNotConsumeFullPatternError = class extends Error {\n  static {\n    __name(this, \"StartRuleDoesNotConsumeFullPatternError\");\n  }\n};\n\n// src/tree/pattern/TagChunk.ts\nvar TagChunk = class extends Chunk {\n  static {\n    __name(this, \"TagChunk\");\n  }\n  tag;\n  label;\n  constructor(...args) {\n    let label;\n    let tag;\n    if (args.length === 1) {\n      tag = args[0];\n    } else {\n      label = args[0];\n      tag = args[1];\n    }\n    super();\n    if (!tag) {\n      throw new Error(\"tag cannot be null or empty\");\n    }\n    this.label = label;\n    this.tag = tag;\n  }\n  /**\n   * @returns a text representation of the tag chunk. Labeled tags\n   * are returned in the form `label:tag`, and unlabeled tags are\n   * returned as just the tag name.\n   */\n  toString() {\n    if (this.label !== null) {\n      return this.label + \":\" + this.tag;\n    }\n    return this.tag;\n  }\n};\n\n// src/tree/pattern/TextChunk.ts\nvar TextChunk = class extends Chunk {\n  static {\n    __name(this, \"TextChunk\");\n  }\n  text;\n  /**\n   * Constructs a new instance of {@link TextChunk} with the specified text.\n   *\n   * @param text The text of this chunk.\n   */\n  constructor(text) {\n    super();\n    this.text = text;\n  }\n  /**\n   * @returns the result of {@link #getText()} in single quotes.\n   */\n  toString() {\n    return \"'\" + this.text + \"'\";\n  }\n};\n\n// src/tree/pattern/TokenTagToken.ts\nvar TokenTagToken = class extends CommonToken {\n  static {\n    __name(this, \"TokenTagToken\");\n  }\n  tokenName;\n  /**\n   * The name of the label associated with the rule tag, or undefined if this is an unlabeled rule tag.\n   */\n  label;\n  constructor(tokenName, type, label) {\n    super({ type, source: CommonToken.EMPTY_SOURCE });\n    this.tokenName = tokenName;\n    this.label = label;\n  }\n  /**\n   *\n   * @returns the token tag formatted with `<` and `>` delimiters.\n   */\n  get text() {\n    if (this.label !== null) {\n      return \"<\" + this.label + \":\" + this.tokenName + \">\";\n    }\n    return \"<\" + this.tokenName + \">\";\n  }\n  /**\n   * @returns a string of the form `tokenName:type`.\n   */\n  toString() {\n    return this.tokenName + \":\" + this.type;\n  }\n};\n\n// src/tree/pattern/ParseTreePatternMatcher.ts\nvar ParseTreePatternMatcher = class {\n  static {\n    __name(this, \"ParseTreePatternMatcher\");\n  }\n  start = \"<\";\n  stop = \">\";\n  escape = \"\\\\\";\n  /**\n   * This is the backing field for {@link #getLexer()}.\n   */\n  lexer;\n  /**\n   * This is the backing field for {@link #getParser()}.\n   */\n  parser;\n  // e.g., \\< and \\> must escape BOTH!\n  /**\n   * Constructs a {@link ParseTreePatternMatcher} or from a {@link Lexer} and\n   * {@link Parser} object. The lexer input stream is altered for tokenizing\n   * the tree patterns. The parser is used as a convenient mechanism to get\n   * the grammar name, plus token, rule names.\n   */\n  constructor(lexer, parser) {\n    this.lexer = lexer;\n    this.parser = parser;\n  }\n  /**\n   * Set the delimiters used for marking rule and token tags within concrete\n   * syntax used by the tree pattern parser.\n   *\n   * @param start The start delimiter.\n   * @param stop The stop delimiter.\n   * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter.\n   *\n   * @throws Error if `start` is `null` or empty.\n   * @throws Error if `stop` is `null` or empty.\n   */\n  setDelimiters(start, stop, escapeLeft) {\n    if (start === null || start.length === 0) {\n      throw new Error(\"start cannot be null or empty\");\n    }\n    if (stop === null || stop.length === 0) {\n      throw new Error(\"stop cannot be null or empty\");\n    }\n    this.start = start;\n    this.stop = stop;\n    this.escape = escapeLeft;\n  }\n  matches(...args) {\n    switch (args.length) {\n      case 2: {\n        const [tree, pattern] = args;\n        const labels = new MultiMap();\n        const mismatchedNode = this.matchImpl(tree, pattern.getPatternTree(), labels);\n        return mismatchedNode === null;\n      }\n      case 3: {\n        const [tree, pattern, patternRuleIndex] = args;\n        const p = this.compile(pattern, patternRuleIndex);\n        return this.matches(tree, p);\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  match(...args) {\n    switch (args.length) {\n      case 2: {\n        const [tree, pattern] = args;\n        const labels = new MultiMap();\n        const mismatchedNode = this.matchImpl(tree, pattern.getPatternTree(), labels);\n        return new ParseTreeMatch(tree, pattern, labels, mismatchedNode);\n      }\n      case 3: {\n        const [tree, pattern, patternRuleIndex] = args;\n        const p = this.compile(pattern, patternRuleIndex);\n        return this.match(tree, p);\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  /**\n   * For repeated use of a tree pattern, compile it to a\n   * {@link ParseTreePattern} using this method.\n   */\n  compile(pattern, patternRuleIndex) {\n    const tokenList = this.tokenize(pattern);\n    const tokenSrc = new ListTokenSource(tokenList);\n    const tokens = new CommonTokenStream(tokenSrc);\n    const parserInterp = new ParserInterpreter(\n      this.parser.grammarFileName,\n      this.parser.vocabulary,\n      this.parser.ruleNames,\n      this.parser.getATNWithBypassAlts(),\n      tokens\n    );\n    let tree = null;\n    try {\n      parserInterp.errorHandler = new BailErrorStrategy();\n      tree = parserInterp.parse(patternRuleIndex);\n    } catch (eOrRe) {\n      if (eOrRe instanceof ParseCancellationException) {\n        const e = eOrRe;\n        throw e.cause;\n      } else if (eOrRe instanceof RecognitionException) {\n        throw eOrRe;\n      } else if (eOrRe instanceof Error) {\n        throw new CannotInvokeStartRuleError(eOrRe);\n      } else {\n        throw eOrRe;\n      }\n    }\n    if (tokens.LA(1) !== Token.EOF) {\n      throw new StartRuleDoesNotConsumeFullPatternError();\n    }\n    return new ParseTreePattern(this, pattern, patternRuleIndex, tree);\n  }\n  /**\n   * Used to convert the tree pattern string into a series of tokens. The\n   * input stream is reset.\n   */\n  getLexer() {\n    return this.lexer;\n  }\n  /**\n   * Used to collect to the grammar file name, token names, rule names for\n   * used to parse the pattern into a parse tree.\n   */\n  getParser() {\n    return this.parser;\n  }\n  // ---- SUPPORT CODE ----\n  tokenize(pattern) {\n    const chunks = this.split(pattern);\n    const tokens = new Array();\n    for (const chunk of chunks) {\n      if (chunk instanceof TagChunk) {\n        const tagChunk = chunk;\n        const char = tagChunk.tag[0];\n        if (char === char.toUpperCase()) {\n          const ttype = this.parser.getTokenType(tagChunk.tag);\n          if (ttype === Token.INVALID_TYPE) {\n            throw new Error(\"Unknown token \" + tagChunk.tag + \" in pattern: \" + pattern);\n          }\n          const t = new TokenTagToken(tagChunk.tag, ttype, tagChunk.label);\n          tokens.push(t);\n        } else {\n          if (char === char.toLowerCase()) {\n            const ruleIndex = this.parser.getRuleIndex(tagChunk.tag);\n            if (ruleIndex === -1) {\n              throw new Error(\"Unknown rule \" + tagChunk.tag + \" in pattern: \" + pattern);\n            }\n            const ruleImaginaryTokenType = this.parser.getATNWithBypassAlts().ruleToTokenType[ruleIndex];\n            tokens.push(new RuleTagToken(tagChunk.tag, ruleImaginaryTokenType, tagChunk.label));\n          } else {\n            throw new Error(\"invalid tag: \" + tagChunk.tag + \" in pattern: \" + pattern);\n          }\n        }\n      } else {\n        const textChunk = chunk;\n        const input = CharStream.fromString(textChunk.text);\n        this.lexer.inputStream = input;\n        let t = this.lexer.nextToken();\n        while (t.type !== Token.EOF) {\n          tokens.push(t);\n          t = this.lexer.nextToken();\n        }\n      }\n    }\n    return tokens;\n  }\n  /**\n   * Split `<ID> = <e:expr> ;` into 4 chunks for tokenizing by {@link #tokenize}.\n   */\n  split(pattern) {\n    let p = 0;\n    const n2 = pattern.length;\n    const chunks = new Array();\n    const starts = new Array();\n    const stops = new Array();\n    while (p < n2) {\n      if (p === pattern.indexOf(this.escape + this.start, p)) {\n        p += this.escape.length + this.start.length;\n      } else {\n        if (p === pattern.indexOf(this.escape + this.stop, p)) {\n          p += this.escape.length + this.stop.length;\n        } else {\n          if (p === pattern.indexOf(this.start, p)) {\n            starts.push(p);\n            p += this.start.length;\n          } else {\n            if (p === pattern.indexOf(this.stop, p)) {\n              stops.push(p);\n              p += this.stop.length;\n            } else {\n              p++;\n            }\n          }\n        }\n      }\n    }\n    if (starts.length > stops.length) {\n      throw new Error(\"unterminated tag in pattern: \" + pattern);\n    }\n    if (starts.length < stops.length) {\n      throw new Error(\"missing start tag in pattern: \" + pattern);\n    }\n    const tagCount = starts.length;\n    for (let i = 0; i < tagCount; i++) {\n      if (starts[i] >= stops[i]) {\n        throw new Error(\"tag delimiters out of order in pattern: \" + pattern);\n      }\n    }\n    if (tagCount === 0) {\n      const text = pattern.substring(0, n2);\n      chunks.push(new TextChunk(text));\n    }\n    if (tagCount > 0 && starts[0] > 0) {\n      const text = pattern.substring(0, starts[0]);\n      chunks.push(new TextChunk(text));\n    }\n    for (let i = 0; i < tagCount; i++) {\n      const tag = pattern.substring(starts[i] + this.start.length, stops[i]);\n      let ruleOrToken = tag;\n      let label;\n      const colon = tag.indexOf(\":\");\n      if (colon >= 0) {\n        label = tag.substring(0, colon);\n        ruleOrToken = tag.substring(colon + 1, tag.length);\n      }\n      chunks.push(new TagChunk(label, ruleOrToken));\n      if (i + 1 < tagCount) {\n        const text = pattern.substring(stops[i] + this.stop.length, starts[i + 1]);\n        chunks.push(new TextChunk(text));\n      }\n    }\n    if (tagCount > 0) {\n      const afterLastTag = stops[tagCount - 1] + this.stop.length;\n      if (afterLastTag < n2) {\n        const text = pattern.substring(afterLastTag, n2);\n        chunks.push(new TextChunk(text));\n      }\n    }\n    for (let i = 0; i < chunks.length; i++) {\n      const c = chunks[i];\n      if (c instanceof TextChunk) {\n        const tc = c;\n        const unescaped = tc.text.replace(this.escape, \"\");\n        if (unescaped.length < tc.text.length) {\n          chunks[i] = new TextChunk(unescaped);\n        }\n      }\n    }\n    return chunks;\n  }\n  /**\n   * Recursively walk `tree` against `patternTree`, filling\n   * `match.`{@link ParseTreeMatch#labels labels}.\n   *\n   * @returns the first node encountered in `tree` which does not match\n   * a corresponding node in `patternTree`, or `null` if the match\n   * was successful. The specific node returned depends on the matching\n   * algorithm used by the implementation, and may be overridden.\n   */\n  matchImpl(tree, patternTree, labels) {\n    if (tree instanceof TerminalNode && patternTree instanceof TerminalNode) {\n      const t1 = tree;\n      const t2 = patternTree;\n      let mismatchedNode;\n      if (t1.getSymbol().type === t2.getSymbol().type) {\n        if (t2.getSymbol() instanceof TokenTagToken) {\n          const tokenTagToken = t2.getSymbol();\n          labels.map(tokenTagToken.tokenName, tree);\n          if (tokenTagToken.label !== void 0) {\n            labels.map(tokenTagToken.label, tree);\n          }\n        } else {\n          if (t1.getText() === t2.getText()) {\n          } else {\n            if (!mismatchedNode) {\n              mismatchedNode = t1;\n            }\n          }\n        }\n      } else {\n        if (!mismatchedNode) {\n          mismatchedNode = t1;\n        }\n      }\n      return mismatchedNode;\n    }\n    if (tree instanceof ParserRuleContext && patternTree instanceof ParserRuleContext) {\n      let mismatchedNode;\n      const ruleTagToken = this.getRuleTagToken(patternTree);\n      if (ruleTagToken) {\n        if (tree.ruleIndex === patternTree.ruleIndex) {\n          labels.map(ruleTagToken.ruleName, tree);\n          if (ruleTagToken.label) {\n            labels.map(ruleTagToken.label, tree);\n          }\n        } else {\n          if (!mismatchedNode) {\n            mismatchedNode = tree;\n          }\n        }\n        return mismatchedNode;\n      }\n      if (tree.getChildCount() !== patternTree.getChildCount()) {\n        if (!mismatchedNode) {\n          mismatchedNode = tree;\n        }\n        return mismatchedNode;\n      }\n      const n2 = tree.getChildCount();\n      for (let i = 0; i < n2; i++) {\n        const childMatch = this.matchImpl(tree.getChild(i), patternTree.getChild(i), labels);\n        if (childMatch) {\n          return childMatch;\n        }\n      }\n      return mismatchedNode;\n    }\n    return tree;\n  }\n  /**\n   * Is `t` `(expr <expr>)` subtree?\n   */\n  getRuleTagToken(t) {\n    if (t instanceof ParserRuleContext) {\n      if (t.getChildCount() === 1 && t.getChild(0) instanceof TerminalNode) {\n        const c = t.getChild(0);\n        if (c.getSymbol() instanceof RuleTagToken) {\n          return c.getSymbol();\n        }\n      }\n    }\n    return void 0;\n  }\n};\n\n// src/DiagnosticErrorListener.ts\nvar DiagnosticErrorListener = class extends BaseErrorListener {\n  static {\n    __name(this, \"DiagnosticErrorListener\");\n  }\n  /**\n   * When `true`, only exactly known ambiguities are reported.\n   */\n  exactOnly;\n  constructor(exactOnly) {\n    super();\n    this.exactOnly = exactOnly ?? true;\n  }\n  reportAmbiguity = /* @__PURE__ */ __name((recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) => {\n    if (this.exactOnly && !exact) {\n      return;\n    }\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const conflictingAlts = this.getConflictingAlts(ambigAlts, configs);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportAmbiguity d=${decision}: ambigAlts=${conflictingAlts}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  }, \"reportAmbiguity\");\n  reportAttemptingFullContext = /* @__PURE__ */ __name((recognizer, dfa, startIndex, stopIndex, _conflictingAlts, _configs) => {\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportAttemptingFullContext d=${decision}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  }, \"reportAttemptingFullContext\");\n  reportContextSensitivity = /* @__PURE__ */ __name((recognizer, dfa, startIndex, stopIndex, _prediction, _configs) => {\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportContextSensitivity d=${decision}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  }, \"reportContextSensitivity\");\n  getDecisionDescription = /* @__PURE__ */ __name((recognizer, dfa) => {\n    const decision = dfa.decision;\n    const ruleIndex = dfa.atnStartState.ruleIndex;\n    const ruleNames = recognizer.ruleNames;\n    if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n      return decision.toString();\n    }\n    const ruleName = ruleNames[ruleIndex];\n    if (ruleName.length === 0) {\n      return decision.toString();\n    }\n    return `${decision} (${ruleName})`;\n  }, \"getDecisionDescription\");\n  /**\n   * Computes the set of conflicting or ambiguous alternatives from a\n   * configuration set, if that information was not already provided by the\n   * parser.\n   *\n   * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n   * reported by the parser.\n   * @param configs The conflicting or ambiguous configuration set.\n   * @returns Returns `reportedAlts` if it is not `null`, otherwise\n   * returns the set of alternatives represented in `configs`.\n   */\n  getConflictingAlts = /* @__PURE__ */ __name((reportedAlts, configs) => {\n    if (reportedAlts) {\n      return reportedAlts;\n    }\n    const result = new BitSet();\n    for (let i = 0; i < configs.configs.length; i++) {\n      result.set(configs.configs[i].alt);\n    }\n    return result;\n  }, \"getConflictingAlts\");\n};\n\n// src/LexerInterpreter.ts\nvar LexerInterpreter = class extends Lexer {\n  static {\n    __name(this, \"LexerInterpreter\");\n  }\n  #grammarFileName;\n  #atn;\n  #ruleNames;\n  #channelNames;\n  #modeNames;\n  #vocabulary;\n  #decisionToDFA;\n  #sharedContextCache = new PredictionContextCache();\n  constructor(grammarFileName, vocabulary, ruleNames, channelNames, modeNames, atn, input) {\n    super(input);\n    if (atn.grammarType !== ATN.LEXER) {\n      throw new Error(\"IllegalArgumentException: The ATN must be a lexer ATN.\");\n    }\n    this.#grammarFileName = grammarFileName;\n    this.#atn = atn;\n    this.#ruleNames = ruleNames.slice(0);\n    this.#channelNames = channelNames.slice(0);\n    this.#modeNames = modeNames.slice(0);\n    this.#vocabulary = vocabulary;\n    this.#decisionToDFA = atn.decisionToState.map((ds, i) => {\n      return new DFA(ds, i);\n    });\n    this.interpreter = new LexerATNSimulator(this, atn, this.#decisionToDFA, this.#sharedContextCache);\n  }\n  get atn() {\n    return this.#atn;\n  }\n  get grammarFileName() {\n    return this.#grammarFileName;\n  }\n  get ruleNames() {\n    return this.#ruleNames;\n  }\n  get channelNames() {\n    return this.#channelNames;\n  }\n  get modeNames() {\n    return this.#modeNames;\n  }\n  get vocabulary() {\n    return this.#vocabulary;\n  }\n};\n\n// src/RuntimeMetaData.ts\nvar RuntimeMetaData = class _RuntimeMetaData {\n  static {\n    __name(this, \"RuntimeMetaData\");\n  }\n  /**\n   * A compile-time constant containing the current version of the ANTLR 4\n   * runtime library.\n   *\n   * This compile-time constant value allows generated parsers and other\n   * libraries to include a literal reference to the version of the ANTLR 4\n   * runtime library the code was compiled against. At each release, we\n   * change this value.\n   *\n   * Version numbers are assumed to have the form\n   *\n   * major.minor.patch.revision-suffix,\n   *\n   * with the individual components defined as follows.\n   *\n   * - major is a required non-negative integer, and is equal to `4` for ANTLR 4.\n   * - minor is a required non-negative integer.\n   * - patch is an optional non-negative integer. When patch is omitted, the `.` (dot) appearing before it is\n   *   also omitted.\n   * - revision is an optional non-negative integer, and may only be included when patch is also included.\n   *   When revision is omitted, the `.` (dot) appearing before it is also omitted.\n   * - suffix is an optional string. When suffix is omitted, the `-` (hyphen-minus) appearing before it is also\n   *   omitted.\n   */\n  static VERSION = \"4.13.1\";\n  /**\n   * Gets the currently executing version of the ANTLR 4 runtime library.\n   *\n   * This method provides runtime access to the {@link VERSION} field, as\n   * opposed to directly referencing the field as a compile-time constant.\n   *\n   * @returns The currently executing version of the ANTLR 4 library\n   */\n  static getRuntimeVersion() {\n    return _RuntimeMetaData.VERSION;\n  }\n  /**\n   * This method provides the ability to detect mismatches between the version\n   * of ANTLR 4 used to generate a parser, the version of the ANTLR runtime a\n   * parser was compiled against, and the version of the ANTLR runtime which\n   * is currently executing.\n   *\n   * The version check is designed to detect the following two specific\n   * scenarios.\n   *\n   * - The ANTLR Tool version used for code generation does not match the\n   * currently executing runtime version.\n   * - The ANTLR Runtime version referenced at the time a parser was\n   * compiled does not match the currently executing runtime version.\n   *\n   *\n   * Starting with ANTLR 4.3, the code generator emits a call to this method\n   * using two constants in each generated lexer and parser: a hard-coded\n   * constant indicating the version of the tool used to generate the parser\n   * and a reference to the compile-time constant {@link VERSION}. At\n   * runtime, this method is called during the initialization of the generated\n   * parser to detect mismatched versions, and notify the registered listeners\n   * prior to creating instances of the parser.\n   *\n   *\n   * This method does not perform any detection or filtering of semantic\n   * changes between tool and runtime versions. It simply checks for a\n   * version match and emits an error to stderr if a difference\n   * is detected.\n   *\n   *\n   * Note that some breaking changes between releases could result in other\n   * types of runtime exceptions, such as a {@link LinkageError}, prior to\n   * calling this method. In these cases, the underlying version mismatch will\n   * not be reported here. This method is primarily intended to\n   * notify users of potential semantic changes between releases that do not\n   * result in binary compatibility problems which would be detected by the\n   * class loader. As with semantic changes, changes that break binary\n   * compatibility between releases are mentioned in the release notes\n   * accompanying the affected release.\n   *\n   *\n   * **Additional note for target developers:** The version check\n   * implemented by this class is designed to address specific compatibility\n   * concerns that may arise during the execution of Java applications. Other\n   * targets should consider the implementation of this method in the context\n   * of that target's known execution environment, which may or may not\n   * resemble the design provided for the Java target.\n   *\n   * @param generatingToolVersion The version of the tool used to generate a parser.\n   * This value may be null when called from user code that was not generated\n   * by, and does not reference, the ANTLR 4 Tool itself.\n   * @param compileTimeVersion The version of the runtime the parser was\n   * compiled against. This should always be passed using a direct reference\n   * to {@link VERSION}.\n   */\n  static checkVersion(generatingToolVersion, compileTimeVersion) {\n    const runtimeVersion = _RuntimeMetaData.VERSION;\n    let runtimeConflictsWithGeneratingTool = false;\n    let runtimeConflictsWithCompileTimeTool = false;\n    runtimeConflictsWithGeneratingTool = runtimeVersion !== generatingToolVersion && _RuntimeMetaData.getMajorMinorVersion(runtimeVersion) !== _RuntimeMetaData.getMajorMinorVersion(generatingToolVersion);\n    runtimeConflictsWithCompileTimeTool = runtimeVersion !== compileTimeVersion && _RuntimeMetaData.getMajorMinorVersion(runtimeVersion) !== _RuntimeMetaData.getMajorMinorVersion(compileTimeVersion);\n    if (runtimeConflictsWithGeneratingTool) {\n      console.error(`ANTLR Tool version ${generatingToolVersion} used for code generation does not match the current runtime version ${runtimeVersion}`);\n    }\n    if (runtimeConflictsWithCompileTimeTool) {\n      console.error(`ANTLR Runtime version ${compileTimeVersion} used for parser compilation does not match the current runtime version ${runtimeVersion}`);\n    }\n  }\n  /**\n   * Gets the major and minor version numbers from a version string. For\n   * details about the syntax of the input `version`.\n   * E.g., from x.y.z return x.y.\n   *\n   * @param version The complete version string.\n   * @returns A string of the form *major*.*minor* containing\n   * only the major and minor components of the version string.\n   */\n  static getMajorMinorVersion(version) {\n    const firstDot = version.indexOf(\".\");\n    const secondDot = firstDot >= 0 ? version.indexOf(\".\", firstDot + 1) : -1;\n    const firstDash = version.indexOf(\"-\");\n    let referenceLength = version.length;\n    if (secondDot >= 0) {\n      referenceLength = Math.min(referenceLength, secondDot);\n    }\n    if (firstDash >= 0) {\n      referenceLength = Math.min(referenceLength, firstDash);\n    }\n    return version.substring(0, referenceLength);\n  }\n};\n\n// src/TokenStreamRewriter.ts\nvar TokenStreamRewriter = class _TokenStreamRewriter {\n  static {\n    __name(this, \"TokenStreamRewriter\");\n  }\n  static DEFAULT_PROGRAM_NAME = \"default\";\n  static PROGRAM_INIT_SIZE = 100;\n  static MIN_TOKEN_INDEX = 0;\n  /** Our source stream */\n  tokens;\n  /**\n   * You may have multiple, named streams of rewrite operations.\n   *  I'm calling these things \"programs.\"\n   *  Maps String (name) -> rewrite (List)\n   */\n  programs = /* @__PURE__ */ new Map();\n  /** Map String (program name) -> Integer index */\n  lastRewriteTokenIndexes;\n  /**\n   * @param tokens The token stream to modify\n   */\n  constructor(tokens) {\n    this.tokens = tokens;\n  }\n  getTokenStream() {\n    return this.tokens;\n  }\n  /**\n   * Insert the supplied text after the specified token (or token index)\n   */\n  insertAfter(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let index;\n    if (typeof tokenOrIndex === \"number\") {\n      index = tokenOrIndex;\n    } else {\n      index = tokenOrIndex.tokenIndex;\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new InsertAfterOp(this.tokens, index, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Insert the supplied text before the specified token (or token index)\n   */\n  insertBefore(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let index;\n    if (typeof tokenOrIndex === \"number\") {\n      index = tokenOrIndex;\n    } else {\n      index = tokenOrIndex.tokenIndex;\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new InsertBeforeOp(this.tokens, index, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Replace the specified token with the supplied text\n   */\n  replaceSingle(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    this.replace(tokenOrIndex, tokenOrIndex, text, programName);\n  }\n  /**\n   * Replace the specified range of tokens with the supplied text.\n   */\n  replace(from, to, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    if (typeof from !== \"number\") {\n      from = from.tokenIndex;\n    }\n    if (typeof to !== \"number\") {\n      to = to.tokenIndex;\n    }\n    if (from > to || from < 0 || to < 0 || to >= this.tokens.size) {\n      throw new RangeError(`replace: range invalid: ${from}..${to}(size=${this.tokens.size})`);\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new ReplaceOp(this.tokens, from, to, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Delete the specified range of tokens\n   */\n  delete(from, to, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    if (to == null) {\n      to = from;\n    }\n    this.replace(from, to, null, programName);\n  }\n  getProgram(name) {\n    let is = this.programs.get(name);\n    if (is == null) {\n      is = this.initializeProgram(name);\n    }\n    return is;\n  }\n  initializeProgram(name) {\n    const is = [];\n    this.programs.set(name, is);\n    return is;\n  }\n  /**\n   * @returns the text from the original tokens altered per the instructions given to this rewriter\n   */\n  getText(intervalOrProgram, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let interval;\n    if (intervalOrProgram instanceof Interval) {\n      interval = intervalOrProgram;\n    } else {\n      interval = new Interval(0, this.tokens.size - 1);\n    }\n    if (typeof intervalOrProgram === \"string\") {\n      programName = intervalOrProgram;\n    }\n    const rewrites = this.programs.get(programName);\n    let start = interval.start;\n    let stop = interval.stop;\n    if (stop > this.tokens.size - 1) {\n      stop = this.tokens.size - 1;\n    }\n    if (start < 0) {\n      start = 0;\n    }\n    if (rewrites == null || rewrites.length === 0) {\n      return this.tokens.getTextFromInterval(new Interval(start, stop));\n    }\n    const buf = [];\n    const indexToOp = this.reduceToSingleOperationPerIndex(rewrites);\n    let i = start;\n    while (i <= stop && i < this.tokens.size) {\n      const op = indexToOp.get(i);\n      indexToOp.delete(i);\n      const t = this.tokens.get(i);\n      if (op == null) {\n        if (t.type !== Token.EOF) {\n          buf.push(String(t.text));\n        }\n        i++;\n      } else {\n        i = op.execute(buf);\n      }\n    }\n    if (stop === this.tokens.size - 1) {\n      for (const op of indexToOp.values()) {\n        if (op && op.index >= this.tokens.size - 1) {\n          buf.push(String(op.text));\n        }\n      }\n    }\n    return buf.join(\"\");\n  }\n  /**\n   * @returns a map from token index to operation\n   */\n  reduceToSingleOperationPerIndex(rewrites) {\n    for (let i = 0; i < rewrites.length; i++) {\n      const op = rewrites[i];\n      if (op == null) {\n        continue;\n      }\n      if (!(op instanceof ReplaceOp)) {\n        continue;\n      }\n      const rop = op;\n      const inserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n      for (const iop of inserts) {\n        if (iop.index === rop.index) {\n          rewrites[iop.instructionIndex] = null;\n          rop.text = String(iop.text) + (rop.text != null ? rop.text.toString() : \"\");\n        } else if (iop.index > rop.index && iop.index <= rop.lastIndex) {\n          rewrites[iop.instructionIndex] = null;\n        }\n      }\n      const prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n      for (const prevRop of prevReplaces) {\n        if (prevRop.index >= rop.index && prevRop.lastIndex <= rop.lastIndex) {\n          rewrites[prevRop.instructionIndex] = null;\n          continue;\n        }\n        const disjoint = prevRop.lastIndex < rop.index || prevRop.index > rop.lastIndex;\n        if (prevRop.text == null && rop.text == null && !disjoint) {\n          rewrites[prevRop.instructionIndex] = null;\n          rop.index = Math.min(prevRop.index, rop.index);\n          rop.lastIndex = Math.max(prevRop.lastIndex, rop.lastIndex);\n        } else if (!disjoint) {\n          throw new Error(`replace op boundaries of ${rop} overlap with previous ${prevRop}`);\n        }\n      }\n    }\n    for (let i = 0; i < rewrites.length; i++) {\n      const op = rewrites[i];\n      if (op == null) {\n        continue;\n      }\n      if (!(op instanceof InsertBeforeOp)) {\n        continue;\n      }\n      const iop = op;\n      const prevInserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n      for (const prevIop of prevInserts) {\n        if (prevIop.index === iop.index) {\n          if (prevIop instanceof InsertAfterOp) {\n            iop.text = this.catOpText(prevIop.text, iop.text);\n            rewrites[prevIop.instructionIndex] = null;\n          } else if (prevIop instanceof InsertBeforeOp) {\n            iop.text = this.catOpText(iop.text, prevIop.text);\n            rewrites[prevIop.instructionIndex] = null;\n          }\n        }\n      }\n      const prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n      for (const rop of prevReplaces) {\n        if (iop.index === rop.index) {\n          rop.text = this.catOpText(iop.text, rop.text);\n          rewrites[i] = null;\n          continue;\n        }\n        if (iop.index >= rop.index && iop.index <= rop.lastIndex) {\n          throw new Error(`insert op ${iop} within boundaries of previous ${rop}`);\n        }\n      }\n    }\n    const m2 = /* @__PURE__ */ new Map();\n    for (const op of rewrites) {\n      if (op == null) {\n        continue;\n      }\n      if (m2.get(op.index) != null) {\n        throw new Error(\"should only be one op per index\");\n      }\n      m2.set(op.index, op);\n    }\n    return m2;\n  }\n  catOpText(a, b) {\n    let x = \"\";\n    let y = \"\";\n    if (a != null) {\n      x = a.toString();\n    }\n    if (b != null) {\n      y = b.toString();\n    }\n    return x + y;\n  }\n  /**\n   * Get all operations before an index of a particular kind\n   */\n  getKindOfOps(rewrites, kind, before) {\n    return rewrites.slice(0, before).filter((op) => {\n      return op && op instanceof kind;\n    });\n  }\n};\nvar RewriteOperation = class {\n  static {\n    __name(this, \"RewriteOperation\");\n  }\n  /** What index into rewrites List are we? */\n  instructionIndex;\n  /** Token buffer index. */\n  index;\n  text;\n  tokens;\n  constructor(tokens, index, instructionIndex, text) {\n    this.tokens = tokens;\n    this.instructionIndex = instructionIndex;\n    this.index = index;\n    this.text = text === void 0 ? \"\" : text;\n  }\n  execute(_buf) {\n    return this.index;\n  }\n  toString() {\n    return \"<RewriteOperation@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar InsertBeforeOp = class extends RewriteOperation {\n  static {\n    __name(this, \"InsertBeforeOp\");\n  }\n  constructor(tokens, index, instructionIndex, text) {\n    super(tokens, index, instructionIndex, text);\n  }\n  /**\n   * @returns the index of the next token to operate on\n   */\n  execute(buf) {\n    if (this.text) {\n      buf.push(this.text.toString());\n    }\n    if (this.tokens.get(this.index).type !== Token.EOF) {\n      buf.push(String(this.tokens.get(this.index).text));\n    }\n    return this.index + 1;\n  }\n  toString() {\n    return \"<InsertBeforeOp@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar InsertAfterOp = class extends InsertBeforeOp {\n  static {\n    __name(this, \"InsertAfterOp\");\n  }\n  constructor(tokens, index, instructionIndex, text) {\n    super(tokens, index + 1, instructionIndex, text);\n  }\n  toString() {\n    return \"<InsertAfterOp@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar ReplaceOp = class extends RewriteOperation {\n  static {\n    __name(this, \"ReplaceOp\");\n  }\n  lastIndex;\n  constructor(tokens, from, to, instructionIndex, text) {\n    super(tokens, from, instructionIndex, text);\n    this.lastIndex = to;\n  }\n  /**\n   * @returns the index of the next token to operate on\n   */\n  execute(buf) {\n    if (this.text) {\n      buf.push(this.text.toString());\n    }\n    return this.lastIndex + 1;\n  }\n  toString() {\n    if (this.text == null) {\n      return \"<DeleteOp@\" + this.tokens.get(this.index) + \"..\" + this.tokens.get(this.lastIndex) + \">\";\n    }\n    return \"<ReplaceOp@\" + this.tokens.get(this.index) + \"..\" + this.tokens.get(this.lastIndex) + ':\"' + this.text + '\">';\n  }\n};\n\n// src/WritableToken.ts\nvar isWritableToken = /* @__PURE__ */ __name((candidate) => {\n  return candidate.setText !== void 0;\n}, \"isWritableToken\");\n\n// src/UnbufferedTokenStream.ts\nvar UnbufferedTokenStream = class {\n  static {\n    __name(this, \"UnbufferedTokenStream\");\n  }\n  tokenSource;\n  /**\n   * A moving window buffer of the data being scanned. While there's a marker,\n   * we keep adding to buffer. Otherwise, {@link #consume consume()} resets so\n   * we start filling at index 0 again.\n   */\n  tokens;\n  /**\n   * The number of tokens currently in {@link #tokens tokens}.\n   *\n   * This is not the buffer capacity, that's `tokens.length`.\n   */\n  n;\n  /**\n   * 0..n-1 index into {@link #tokens tokens} of next token.\n   *\n   * The `LT(1)` token is `tokens[p]`. If `p == n`, we are\n   * out of buffered tokens.\n   */\n  p = 0;\n  /**\n   * Count up with {@link #mark mark()} and down with\n   * {@link #release release()}. When we `release()` the last mark,\n   * `numMarkers` reaches 0 and we reset the buffer. Copy\n   * `tokens[p]..tokens[n-1]` to `tokens[0]..tokens[(n-1)-p]`.\n   */\n  numMarkers = 0;\n  /**\n   * This is the `LT(-1)` token for the current position.\n   */\n  lastToken;\n  /**\n   * When `numMarkers > 0`, this is the `LT(-1)` token for the\n   * first token in {@link #tokens}. Otherwise, this is `null`.\n   */\n  lastTokenBufferStart;\n  /**\n   * Absolute token index. It's the index of the token about to be read via\n   * `LT(1)`. Goes from 0 to the number of tokens in the entire stream,\n   * although the stream size is unknown before the end is reached.\n   *\n   * This value is used to set the token indexes if the stream provides tokens\n   * that implement {@link WritableToken}.\n   */\n  currentTokenIndex = 0;\n  constructor(tokenSource, bufferSize) {\n    this.tokenSource = tokenSource;\n    bufferSize = bufferSize ?? 256;\n    this.tokens = new Array(bufferSize);\n    this.n = 0;\n    this.fill(1);\n  }\n  get(i) {\n    const bufferStartIndex = this.getBufferStartIndex();\n    if (i < bufferStartIndex || i >= bufferStartIndex + this.n) {\n      throw new Error(\"get(\" + i + \") outside buffer: \" + bufferStartIndex + \"..\" + (bufferStartIndex + this.n));\n    }\n    return this.tokens[i - bufferStartIndex];\n  }\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  LT(i) {\n    if (i === -1) {\n      return this.lastToken;\n    }\n    this.sync(i);\n    const index = this.p + i - 1;\n    if (index < 0) {\n      throw new Error(\"LT(\" + i + \") gives negative index\");\n    }\n    if (index >= this.n) {\n      return this.tokens[this.n - 1];\n    }\n    return this.tokens[index];\n  }\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  LA(i) {\n    return this.LT(i).type;\n  }\n  getText() {\n    return \"\";\n  }\n  getTextFromContext(ctx) {\n    return this.getTextFromInterval(ctx.getSourceInterval());\n  }\n  getTextFromInterval(interval) {\n    const bufferStartIndex = this.getBufferStartIndex();\n    const bufferStopIndex = bufferStartIndex + this.tokens.length - 1;\n    const start = interval.start;\n    const stop = interval.stop;\n    if (start < bufferStartIndex || stop > bufferStopIndex) {\n      throw new Error(\"interval \" + interval + \" not in token buffer window: \" + bufferStartIndex + \"..\" + bufferStopIndex);\n    }\n    const a = start - bufferStartIndex;\n    const b = stop - bufferStartIndex;\n    let result = \"\";\n    for (let i = a; i <= b; i++) {\n      const t = this.tokens[i];\n      result += t.text;\n    }\n    return result;\n  }\n  getTextFromRange(start, stop) {\n    return this.getTextFromInterval(Interval.of(start.tokenIndex, stop.tokenIndex));\n  }\n  consume() {\n    if (this.LA(1) === Token.EOF) {\n      throw new Error(\"cannot consume EOF\");\n    }\n    this.lastToken = this.tokens[this.p];\n    if (this.p === this.n - 1 && this.numMarkers === 0) {\n      this.n = 0;\n      this.p = -1;\n      this.lastTokenBufferStart = this.lastToken;\n    }\n    this.p++;\n    this.currentTokenIndex++;\n    this.sync(1);\n  }\n  /**\n   * Return a marker that we can release later.\n   *\n   * The specific marker value used for this class allows for some level of\n   * protection against misuse where `seek()` is called on a mark or\n   * `release()` is called in the wrong order.\n   */\n  mark() {\n    if (this.numMarkers === 0) {\n      this.lastTokenBufferStart = this.lastToken;\n    }\n    const mark = -this.numMarkers - 1;\n    this.numMarkers++;\n    return mark;\n  }\n  release(marker) {\n    const expectedMark = -this.numMarkers;\n    if (marker !== expectedMark) {\n      throw new Error(\"release() called with an invalid marker.\");\n    }\n    this.numMarkers--;\n    if (this.numMarkers === 0) {\n      if (this.p > 0) {\n        this.tokens.copyWithin(0, this.p, this.n);\n        this.n = this.n - this.p;\n        this.p = 0;\n      }\n      this.lastTokenBufferStart = this.lastToken;\n    }\n  }\n  get index() {\n    return this.currentTokenIndex;\n  }\n  seek(index) {\n    if (index === this.currentTokenIndex) {\n      return;\n    }\n    if (index > this.currentTokenIndex) {\n      this.sync(index - this.currentTokenIndex);\n      index = Math.min(index, this.getBufferStartIndex() + this.n - 1);\n    }\n    const bufferStartIndex = this.getBufferStartIndex();\n    const i = index - bufferStartIndex;\n    if (i < 0) {\n      throw new Error(\"cannot seek to negative index \" + index);\n    } else {\n      if (i >= this.n) {\n        throw new Error(\"seek to index outside buffer: \" + index + \" not in \" + bufferStartIndex + \"..\" + (bufferStartIndex + this.n));\n      }\n    }\n    this.p = i;\n    this.currentTokenIndex = index;\n    if (this.p === 0) {\n      this.lastToken = this.lastTokenBufferStart;\n    } else {\n      this.lastToken = this.tokens[this.p - 1];\n    }\n  }\n  get size() {\n    throw new Error(\"Unbuffered stream cannot know its size\");\n  }\n  getSourceName() {\n    return this.tokenSource.sourceName;\n  }\n  /**\n   * Make sure we have 'need' elements from current position {@link #p p}. Last valid\n   * `p` index is `tokens.length-1`.  `p+need-1` is the tokens index 'need' elements\n   * ahead.  If we need 1 element, `(p+1-1)==p` must be less than `tokens.length`.\n   */\n  sync(want) {\n    const need = this.p + want - 1 - this.n + 1;\n    if (need > 0) {\n      this.fill(need);\n    }\n  }\n  /**\n   * Add `n` elements to the buffer. Returns the number of tokens\n   * actually added to the buffer. If the return value is less than `n`,\n   * then EOF was reached before `n` tokens could be added.\n   */\n  fill(n2) {\n    for (let i = 0; i < n2; i++) {\n      if (this.n > 0 && this.tokens[this.n - 1].type === Token.EOF) {\n        return i;\n      }\n      const t = this.tokenSource.nextToken();\n      this.add(t);\n    }\n    return n2;\n  }\n  add(t) {\n    if (this.n >= this.tokens.length) {\n      this.tokens.length = this.tokens.length * 2;\n    }\n    if (isWritableToken(t)) {\n      t.setTokenIndex(this.getBufferStartIndex() + this.n);\n    }\n    this.tokens[this.n++] = t;\n  }\n  getBufferStartIndex() {\n    return this.currentTokenIndex - this.p;\n  }\n};\n\n\n\n//# sourceURL=webpack://Modellus/./node_modules/antlr4ng/dist/index.mjs?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./index.ts");
/******/ 	Modellus = __webpack_exports__;
/******/ 	
/******/ })()
;